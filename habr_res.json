[
    {
        "publish_datetime": 1669968237.0,
        "author": "SberTeam",
        "title": "Нейронная сеть для распознавания образов с TensorFlow: как с ней работать",
        "title_image_url": "https://habrastorage.org/getpro/habr/upload_files/6da/e1c/953/6dae1c953aa19b55ff87bd9a06aff5f2.png",
        "raw_body": "<div xmlns=\"http://www.w3.org/1999/xhtml\"><p>Привет, Хабр! В сегодняшней статье хотим поделиться опытом, как можно начать использовать TensorFlow в целях распознавания образов. Напомним, что TensorFlow — открытая программная библиотека для машинного обучения, разработанная компанией Google для решения задач построения и тренировки нейронной сети с целью автоматического нахождения и классификации образов, достигающая качества человеческого восприятия.</p><p>Цель статьи — привлечь этот инструмент для распознавания боковых зубов (маляров) на рентгеновских снимках с использованием нейронной сети. Для того чтобы этого достичь, нужно выполнить несколько важных этапов, о чём и поговорим под катом. </p><figure class=\"full-width \"><img src=\"https://habrastorage.org/r/w1560/getpro/habr/upload_files/ca0/11a/872/ca011a872062def4fc73a033434ab73a.png\" width=\"1417\" height=\"744\" data-src=\"https://habrastorage.org/getpro/habr/upload_files/ca0/11a/872/ca011a872062def4fc73a033434ab73a.png\"/><figcaption></figcaption></figure><h2>Что это за этапы?</h2><p>Это  процесс настройки, обучения, тестирования нейронной сети с использованием TensorFlow. Сразу и приступим. </p><figure class=\"full-width \"><img src=\"https://habrastorage.org/r/w780q1/getpro/habr/upload_files/f99/6fa/4be/f996fa4bedc7847daff07b8fca8a7d09.jpg\" width=\"880\" height=\"488\" data-src=\"https://habrastorage.org/getpro/habr/upload_files/f99/6fa/4be/f996fa4bedc7847daff07b8fca8a7d09.jpg\" data-blurred=\"true\"/><figcaption></figcaption></figure><h3>Этап 1. Установка программного обеспечения</h3><p>Сразу понадобится установить Anaconda. Если вы собираетесь обучать нейронную сеть на GPU, то обязательно нужно установить cuDNN и CUDA — программно-аппаратный инструментарий, увеличивающий вычислительные мощности. </p><h3>Этап 2. Создание каталога проекта TensorFlow</h3><p>Для создания каталога проекта выполняем следующие шаги:</p><ol><li><p>Создаём папку в удобном месте (рекомендовано в C:), называем «tensorflow1». Каталог будет являться главным и включать в себя все модели и структуру. </p></li><li><p><a href=\"https://github.com/tensorflow/models\">Загружаем</a> и устанавливаем репозиторий TensowFlow в директорию ..\\tensorflow1\\models. В случае возникновения ошибок совместимости рекомендовано понизить версию TensorFlow. </p></li><li><p><a href=\"http://download.tensorflow.org/models/object_detection/faster_rcnn_inception_v2_coco_2018_01_28.tar.gz\">Загружаем</a> и устанавливаем модель Faster-RCNN-Inception в ..\\tensorflow1\\models\\research\\object_detection.  </p></li><li><p><a href=\"https://github.com/EdjeElectronics/TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10\">Загружаем</a> следующую пачку каталогов в ..\\tensorflow1\\models\\research\\object_detection. Данный репозиторий содержит тестовую обучающую выборку и основные функции для обучающих баз.</p></li><li><p>Если нужна собственная обучающая выборка, то необходимо удалить все файлы из ..\\ object_detection\\images\\train, ..\\ object_detection\\images\\test, ..\\ object_detection\\training, ..\\ object_detection\\inference_graph и «test_labels.csv», «train_labels.csv» в ..\\ object_detection\\images.</p></li></ol><h3>Этап 3. Создание среды и установка библиотек</h3><p>Когда структура создана, необходимо приступить к созданию виртуальной среды. Запускаем Anaconda и создаём venv с помощью следующих команд:</p><p><code>conda create -n tensorflow1 pip python </code></p><p><code>activate tensorflow1</code></p><p><code>python -m pip install --upgrade pip</code></p><p><code>pip install --ignore-installed --upgrade tensorflow</code></p><p> Установка библиотек:</p><p><code>conda install -c anaconda protobuf</code></p><p><code>pip install pillow</code></p><p><code>pip install lxml</code></p><p><code>pip install Cython</code></p><p><code>pip install contextlib2</code></p><p><code>pip install jupyter</code></p><p><code>pip install matplotlib</code></p><p><code>pip install pandas</code></p><p><code>pip install opencv-python</code></p><p> Установка переменной среды:</p><p><code>set PYTHONPATH=C:\\tensorflow1\\models; \\</code></p><p><code>C:\\tensorflow1\\models\\research;C:\\tensorflow1\\models\\research\\slim</code></p><p>В каталоге ..\\models\\research создаём файл name_pb2.py, состоящий из каждого файла name.proto в папке \\object_detection\\protos. Описание данного процесса производится с помощью следующей команды:</p><p><code>protoc --python_out=. .\\object_detection\\protos\\anchor_generator.proto .\\object_detection\\protos\\argmax_matcher.proto .\\object_detection\\protos\\bipartite_matcher.proto .\\object_detection\\protos\\box_coder.proto .\\object_detection\\protos\\box_predictor.proto .\\object_detection\\protos\\eval.proto .\\object_detection\\protos\\faster_rcnn.proto .\\object_detection\\protos\\faster_rcnn_box_coder.proto .\\object_detection\\protos\\grid_anchor_generator.proto .\\object_detection\\protos\\hyperparams.proto .\\object_detection\\protos\\image_resizer.proto .\\object_detection\\protos\\input_reader.proto .\\object_detection\\protos\\losses.proto .\\object_detection\\protos\\matcher.proto .\\object_detection\\protos\\mean_stddev_box_coder.proto .\\object_detection\\protos\\model.proto .\\object_detection\\protos\\optimizer.proto .\\object_detection\\protos\\pipeline.proto .\\object_detection\\protos\\post_processing.proto .\\object_detection\\protos\\preprocessor.proto .\\object_detection\\protos\\region_similarity_calculator.proto .\\object_detection\\protos\\square_box_coder.proto .\\object_detection\\protos\\ssd.proto .\\object_detection\\protos\\ssd_anchor_generator.proto .\\object_detection\\protos\\string_int_label_map.proto .\\object_detection\\protos\\train.proto .\\object_detection\\protos\\keypoint_box_coder.proto .\\object_detection\\protos\\multiscale_anchor_generator.proto .\\object_detection\\protos\\graph_rewriter.proto .\\object_detection\\protos\\calibration.proto .\\object_detection\\protos\\flexible_grid_anchor_generator.proto</code></p><h3>Этап 4. Формируем исполняющие файлы </h3><p> <code>Python setup.py build</code></p><p><code>Python setup.py install</code></p><p><code>jupyter notebook object_detection_tutorial.ipynb</code></p><p>В результате открывается окно Jupiter Notebook, где можно протестировать работу тестовой выборки. </p><figure class=\"full-width \"><img src=\"https://habrastorage.org/r/w1560/getpro/habr/upload_files/ada/6a9/4d7/ada6a94d75d1bb7593685a461b605b31.png\" width=\"928\" height=\"313\" data-src=\"https://habrastorage.org/getpro/habr/upload_files/ada/6a9/4d7/ada6a94d75d1bb7593685a461b605b31.png\"/><figcaption></figcaption></figure><p>Если весь код работает без ошибок, то результат выглядит так, как на скриншоте. В противном случае результат в виде картинки не будет выведен. Далее необходимо сформировать собственный датасет и обучить нейронную сеть.</p><p>В качестве обучающей выборки было использовано около 500 обучающих и 80 тестовых записей данных, основанных на медицинских изображениях, полученных на микроКТ. В приведённом примере весь датасет был создан вручную в виде графических файлов. В случае если нет времени на детальный подбор конкретных файлов, стоит использовать уже готовые сформированные датасеты. Весь материал распределяем по папкам test и train в каталоге ..\\research\\object_detection\\images.</p><p>Для разметки тестовых записей из датасета используем <a href=\"https://github.com/heartexlabs/labelImg\">labelImg</a>. Для разметки можно применять любой другой альтернативный софт. Для запуска утилиты labelImg используются следующие команды:</p><p><code>conda install pyqt=5</code></p><p><code>conda install -c anaconda lxml</code></p><p><code>pyrcc5 -o libs/resources.py resources.qrc</code></p><p><code>python labelImg.py</code></p><p>В ходе этого этапа в директории с файлами обучения для каждого отдельного файла картинки формируется xml-файл с обозначениями координат выбранной области.</p><h3>Этап 5. Обучение нейронной сети</h3><p>Ну а теперь нужно сформировать файлы со свойствами объектов. Данная команда создаст файлы train_labels.csv и test_labels.csv в папке ..\\object_detection\\images:</p><p><code>Python xml_to_csv.py</code></p><p>В этом же корневом каталоге открываем generate_tfrecord.py в текстовом редакторе. Начиная со строки 31 заменяем текст меток на свои собственные. В коде эти метки заключены в одинарные кавычки, а их количество должно быть эквивалентно тем, на основе которых проводим обучение.</p><p>Генерируем файлы tfrecord для обучения с помощью следующих команд:</p><p><code>python generate_tfrecord.py --csv_input=images\\train_labels.csv --image_dir=images\\train --output_path=train.record</code></p><p><code>python generate_tfrecord.py --csv_input=images\\test_labels.csv --image_dir=images\\test --output_path=test.record</code></p><p>Формируем карту меток в каталоге ..\\research\\object_detection\\training под названием labelmap.pbtxt. Открываем файл в текстовом редакторе и прописываем наши элементы в подобном формате:          </p><p>Копируем faster_rcnn_inception_v2.config из каталога ..\\research\\object_detection\\samples\\configs в ..\\research\\object_detection\\training. Открываем файл в текстовом редакторе и выполняем следующие действия:</p><ol><li><p>Строка 9. Изменяем num_classes на количество объектов обучения.</p></li><li><p>Строка 106. Изменяем fine_tune_checkpoint на C:/tensorflow1/models/research/object_detection/faster_rcnn_inception_v2_coco_2018_01-28/model.ckpt” или другой путь, в который вы установили tensorflow.</p></li><li><p>Строки 123 и 125. Изменяем в train_input_reader input_path на “ C:/tensorflow1/models/research/object_detection/test.record”, label_map_path на “C:/tensorflow1/models/research/object_detection/training/labelmap.pbtxt”.</p></li><li><p>Строка 130. Подставляем в num_examples в ..\\images\\test количество изображений.</p></li><li><p>Строки 135 и 137. Изменяем в eval_input_reader input_path на “ C:/tensorflow1/models/research/object_detection/test.record”, label_map_path на “C:/tensorflow1/models/research/object_detection/training/labelmap.pbtxt”.</p></li></ol><p>Если выполнение команд прошло без ошибок, приступаем к обучению:</p><p><code>python train.py --logtostderr --train_dir=training/ --pipeline_config_path=training/faster_rcnn_inception_v2.config</code></p><p>После выполнения команды нейронная сеть начнёт обучаться на основании датасета и размеченных данных. В это время на экран консоли выводятся значения ошибок распознавания. Необходимое среднее арифметическое значение ошибок, к которому необходимо стремиться, должно быть минимальным. В соответствии с этим качество конечного распознавания будет лучше.</p><p>После обучения экспортируем граф вывода с помощью команды, где XXXX — значение в model.ckpt-XXXX:</p><p><code>Python export_inference_graph.py –input_type image_tensor –pipeline_config_path training/faster_rcnn_inception_v2.config –trained_checkpoint_prefix training/model.ckpt-XXXX –output_directory inference_graph</code><em> </em></p><h3>Этап 6. Проверка результата</h3><p>Для тестирования полученных результатов перемещаем изображение, которое хотим протестировать, в ..\\object_detection. Меняем переменную имени файла IMAGE_NAME, а также количество классов NUM_CLASSES в Object_detection_image.py. </p><p>Для тестирования на основе видеофайла или картинки с камеры нужно открыть соответствующий файл с именами в названиях video или webcam. Для запуска тестирования активируем среду tensorflow1 в Anaconda и вводим команду idle.</p><p>Ниже приведены результаты тестирования программы после обучения её на основе заданной выборки. Нейронная сеть была обучена на распознавание зубов, а именно маляров. В первом случае были предоставлены снимки 2 зубов и челюсти в полном размере. Результат распознавания показывает, что данные объекты были верно распознаны с вероятностью 99%.</p><figure class=\"\"><img src=\"https://habrastorage.org/r/w1560/getpro/habr/upload_files/02b/024/aae/02b024aae659f68ada616fff05fe33e9.png\" width=\"495\" height=\"395\" data-src=\"https://habrastorage.org/getpro/habr/upload_files/02b/024/aae/02b024aae659f68ada616fff05fe33e9.png\"/><figcaption></figcaption></figure><figure class=\"full-width \"><img src=\"https://habrastorage.org/r/w1560/getpro/habr/upload_files/30d/ef4/77a/30def477a6114786de281435a730b7bd.png\" width=\"909\" height=\"379\" data-src=\"https://habrastorage.org/getpro/habr/upload_files/30d/ef4/77a/30def477a6114786de281435a730b7bd.png\"/><figcaption></figcaption></figure><h2>Что в итоге?</h2><p>В ходе работы удалось научить нейросеть распознавать боковые зубы (маляры) на рентгеновских снимках. Для реализации цели были решены следующие задачи:</p><ol><li><p>Установлено необходимое программное обеспечение.</p></li><li><p>Установлен репозиторий.</p></li><li><p>Загружен и установлен датасет.</p></li><li><p>Создана и установлена среда.</p></li><li><p>Установлены необходимые пакеты.</p></li><li><p>Произведена разметка изображений обучающего датасета.</p></li><li><p>Произведена настройка исполняющих файлов.</p></li><li><p>Обучена и протестирована нейронная сеть.</p></li></ol><p>И да, если у вас есть опыт работы с TensorFlow, появились вопросы или дополнения к статье — всё это можно обсудить в комментариях.</p><p></p></div>",
        "clean_body": "Привет, Хабр! В сегодняшней статье хотим поделиться опытом, как можно начать использовать TensorFlow в целях распознавания образов. Напомним, что TensorFlow — открытая программная библиотека для машинного обучения, разработанная компанией Google для решения задач построения и тренировки нейронной сети с целью автоматического нахождения и классификации образов, достигающая качества человеческого восприятия.Цель статьи — привлечь этот инструмент для распознавания боковых зубов (маляров) на рентгеновских снимках с использованием нейронной сети. Для того чтобы этого достичь, нужно выполнить несколько важных этапов, о чём и поговорим под катом. Что это за этапы?Это  процесс настройки, обучения, тестирования нейронной сети с использованием TensorFlow. Сразу и приступим. Этап 1. Установка программного обеспеченияСразу понадобится установить Anaconda. Если вы собираетесь обучать нейронную сеть на GPU, то обязательно нужно установить cuDNN и CUDA — программно-аппаратный инструментарий, увеличивающий вычислительные мощности. Этап 2. Создание каталога проекта TensorFlowДля создания каталога проекта выполняем следующие шаги:Создаём папку в удобном месте (рекомендовано в C:), называем «tensorflow1». Каталог будет являться главным и включать в себя все модели и структуру. Загружаем и устанавливаем репозиторий TensowFlow в директорию ..\\tensorflow1\\models. В случае возникновения ошибок совместимости рекомендовано понизить версию TensorFlow. Загружаем и устанавливаем модель Faster-RCNN-Inception в ..\\tensorflow1\\models\\research\\object_detection.  Загружаем следующую пачку каталогов в ..\\tensorflow1\\models\\research\\object_detection. Данный репозиторий содержит тестовую обучающую выборку и основные функции для обучающих баз.Если нужна собственная обучающая выборка, то необходимо удалить все файлы из ..\\ object_detection\\images\\train, ..\\ object_detection\\images\\test, ..\\ object_detection\\training, ..\\ object_detection\\inference_graph и «test_labels.csv», «train_labels.csv» в ..\\ object_detection\\images.Этап 3. Создание среды и установка библиотекКогда структура создана, необходимо приступить к созданию виртуальной среды. Запускаем Anaconda и создаём venv с помощью следующих команд:conda create -n tensorflow1 pip python activate tensorflow1python -m pip install --upgrade pippip install --ignore-installed --upgrade tensorflow Установка библиотек:conda install -c anaconda protobufpip install pillowpip install lxmlpip install Cythonpip install contextlib2pip install jupyterpip install matplotlibpip install pandaspip install opencv-python Установка переменной среды:set PYTHONPATH=C:\\tensorflow1\\models; \\C:\\tensorflow1\\models\\research;C:\\tensorflow1\\models\\research\\slimВ каталоге ..\\models\\research создаём файл name_pb2.py, состоящий из каждого файла name.proto в папке \\object_detection\\protos. Описание данного процесса производится с помощью следующей команды:protoc --python_out=. .\\object_detection\\protos\\anchor_generator.proto .\\object_detection\\protos\\argmax_matcher.proto .\\object_detection\\protos\\bipartite_matcher.proto .\\object_detection\\protos\\box_coder.proto .\\object_detection\\protos\\box_predictor.proto .\\object_detection\\protos\\eval.proto .\\object_detection\\protos\\faster_rcnn.proto .\\object_detection\\protos\\faster_rcnn_box_coder.proto .\\object_detection\\protos\\grid_anchor_generator.proto .\\object_detection\\protos\\hyperparams.proto .\\object_detection\\protos\\image_resizer.proto .\\object_detection\\protos\\input_reader.proto .\\object_detection\\protos\\losses.proto .\\object_detection\\protos\\matcher.proto .\\object_detection\\protos\\mean_stddev_box_coder.proto .\\object_detection\\protos\\model.proto .\\object_detection\\protos\\optimizer.proto .\\object_detection\\protos\\pipeline.proto .\\object_detection\\protos\\post_processing.proto .\\object_detection\\protos\\preprocessor.proto .\\object_detection\\protos\\region_similarity_calculator.proto .\\object_detection\\protos\\square_box_coder.proto .\\object_detection\\protos\\ssd.proto .\\object_detection\\protos\\ssd_anchor_generator.proto .\\object_detection\\protos\\string_int_label_map.proto .\\object_detection\\protos\\train.proto .\\object_detection\\protos\\keypoint_box_coder.proto .\\object_detection\\protos\\multiscale_anchor_generator.proto .\\object_detection\\protos\\graph_rewriter.proto .\\object_detection\\protos\\calibration.proto .\\object_detection\\protos\\flexible_grid_anchor_generator.protoЭтап 4. Формируем исполняющие файлы  Python setup.py buildPython setup.py installjupyter notebook object_detection_tutorial.ipynbВ результате открывается окно Jupiter Notebook, где можно протестировать работу тестовой выборки. Если весь код работает без ошибок, то результат выглядит так, как на скриншоте. В противном случае результат в виде картинки не будет выведен. Далее необходимо сформировать собственный датасет и обучить нейронную сеть.В качестве обучающей выборки было использовано около 500 обучающих и 80 тестовых записей данных, основанных на медицинских изображениях, полученных на микроКТ. В приведённом примере весь датасет был создан вручную в виде графических файлов. В случае если нет времени на детальный подбор конкретных файлов, стоит использовать уже готовые сформированные датасеты. Весь материал распределяем по папкам test и train в каталоге ..\\research\\object_detection\\images.Для разметки тестовых записей из датасета используем labelImg. Для разметки можно применять любой другой альтернативный софт. Для запуска утилиты labelImg используются следующие команды:conda install pyqt=5conda install -c anaconda lxmlpyrcc5 -o libs/resources.py resources.qrcpython labelImg.pyВ ходе этого этапа в директории с файлами обучения для каждого отдельного файла картинки формируется xml-файл с обозначениями координат выбранной области.Этап 5. Обучение нейронной сетиНу а теперь нужно сформировать файлы со свойствами объектов. Данная команда создаст файлы train_labels.csv и test_labels.csv в папке ..\\object_detection\\images:Python xml_to_csv.pyВ этом же корневом каталоге открываем generate_tfrecord.py в текстовом редакторе. Начиная со строки 31 заменяем текст меток на свои собственные. В коде эти метки заключены в одинарные кавычки, а их количество должно быть эквивалентно тем, на основе которых проводим обучение.Генерируем файлы tfrecord для обучения с помощью следующих команд:python generate_tfrecord.py --csv_input=images\\train_labels.csv --image_dir=images\\train --output_path=train.recordpython generate_tfrecord.py --csv_input=images\\test_labels.csv --image_dir=images\\test --output_path=test.recordФормируем карту меток в каталоге ..\\research\\object_detection\\training под названием labelmap.pbtxt. Открываем файл в текстовом редакторе и прописываем наши элементы в подобном формате:          Копируем faster_rcnn_inception_v2.config из каталога ..\\research\\object_detection\\samples\\configs в ..\\research\\object_detection\\training. Открываем файл в текстовом редакторе и выполняем следующие действия:Строка 9. Изменяем num_classes на количество объектов обучения.Строка 106. Изменяем fine_tune_checkpoint на C:/tensorflow1/models/research/object_detection/faster_rcnn_inception_v2_coco_2018_01-28/model.ckpt” или другой путь, в который вы установили tensorflow.Строки 123 и 125. Изменяем в train_input_reader input_path на “ C:/tensorflow1/models/research/object_detection/test.record”, label_map_path на “C:/tensorflow1/models/research/object_detection/training/labelmap.pbtxt”.Строка 130. Подставляем в num_examples в ..\\images\\test количество изображений.Строки 135 и 137. Изменяем в eval_input_reader input_path на “ C:/tensorflow1/models/research/object_detection/test.record”, label_map_path на “C:/tensorflow1/models/research/object_detection/training/labelmap.pbtxt”.Если выполнение команд прошло без ошибок, приступаем к обучению:python train.py --logtostderr --train_dir=training/ --pipeline_config_path=training/faster_rcnn_inception_v2.configПосле выполнения команды нейронная сеть начнёт обучаться на основании датасета и размеченных данных. В это время на экран консоли выводятся значения ошибок распознавания. Необходимое среднее арифметическое значение ошибок, к которому необходимо стремиться, должно быть минимальным. В соответствии с этим качество конечного распознавания будет лучше.После обучения экспортируем граф вывода с помощью команды, где XXXX — значение в model.ckpt-XXXX:Python export_inference_graph.py –input_type image_tensor –pipeline_config_path training/faster_rcnn_inception_v2.config –trained_checkpoint_prefix training/model.ckpt-XXXX –output_directory inference_graph Этап 6. Проверка результатаДля тестирования полученных результатов перемещаем изображение, которое хотим протестировать, в ..\\object_detection. Меняем переменную имени файла IMAGE_NAME, а также количество классов NUM_CLASSES в Object_detection_image.py. Для тестирования на основе видеофайла или картинки с камеры нужно открыть соответствующий файл с именами в названиях video или webcam. Для запуска тестирования активируем среду tensorflow1 в Anaconda и вводим команду idle.Ниже приведены результаты тестирования программы после обучения её на основе заданной выборки. Нейронная сеть была обучена на распознавание зубов, а именно маляров. В первом случае были предоставлены снимки 2 зубов и челюсти в полном размере. Результат распознавания показывает, что данные объекты были верно распознаны с вероятностью 99%.Что в итоге?В ходе работы удалось научить нейросеть распознавать боковые зубы (маляры) на рентгеновских снимках. Для реализации цели были решены следующие задачи:Установлено необходимое программное обеспечение.Установлен репозиторий.Загружен и установлен датасет.Создана и установлена среда.Установлены необходимые пакеты.Произведена разметка изображений обучающего датасета.Произведена настройка исполняющих файлов.Обучена и протестирована нейронная сеть.И да, если у вас есть опыт работы с TensorFlow, появились вопросы или дополнения к статье — всё это можно обсудить в комментариях.",
        "meta_tags": [
            "машинное обучение",
            "обучение",
            "искусственный интеллект",
            "python",
            "big data"
        ]
    },
    {
        "publish_datetime": 1669968640.0,
        "author": "Алексей Сергеев",
        "title": "Мысли о разумном Maintainability в этом несовершенном мире",
        "title_image_url": "https://habrastorage.org/getpro/habr/upload_files/193/a35/df0/193a35df016e005961e3095be21f3409.jpeg",
        "raw_body": "<div xmlns=\"http://www.w3.org/1999/xhtml\"><figure class=\"full-width \"><img src=\"https://habrastorage.org/r/w780q1/getpro/habr/upload_files/193/a35/df0/193a35df016e005961e3095be21f3409.jpeg\" width=\"1600\" height=\"902\" data-src=\"https://habrastorage.org/getpro/habr/upload_files/193/a35/df0/193a35df016e005961e3095be21f3409.jpeg\" data-blurred=\"true\"/><figcaption></figcaption></figure><p>Привет, Хабр! Сегодня мне хотелось бы поговорить о такой интересной метрике, как Maintainability - возможность вести доработки и улучшения при создании сложных систем. Ведь при развитии любого программного продукта возникает вопрос, сколько будет стоить его поддержка и развитие. Мы в Киберпротекте разрабатываем линейку продуктов для защиты данных и сегодня это — миллионы строк кода, требующие ощутимых затрат как на поддержку, так и на расширение возможностей или исправление найденных ошибок. В этой статье я делюсь своими мыслями о том, как оценить Maintainability, из чего она состоит, можно ли ее измерить, и как принимать правильные решения при работе с кодом.</p><p>В те моменты, когда программный продукт стабильно работает, большинству не интересно, как именно он написан. Но когда возникает потребность в модификации, все проблемы с качеством разработки сразу же вылезают наружу. Как только нужно что-то изменить, поправить, дополнить или доработать, мы вынуждены оценивать стоимость этих мероприятий. И далеко не всегда полученные результаты оказываются радостными.</p><h3>Проблемы неидеального кода</h3><p>Если с кодом сложно работать, команда разработчиков просто не имеет возможности развивать новые фичи быстро и в достаточном количестве. Стоимость внедрения новых функций оказывается выше, если каждый раз приходится разбираться с запутанным кодом, с которым нужно интегрировать что-то новое. </p><p>А если в техподдержку поступило сообщение об ошибке на стороне пользователя, ее нужно исправлять как можно быстрее. Но от качества кодовой базы напрямую зависит, как быстро специалисты разберутся, к какому компоненту относится проблема и кто может ее устранить. Далее нужно определить, сколько времени займет исправление, как быстро мы сможем провести тесты и убедиться, что все хорошо.</p><p>В случае с идеальным кодом, который встречается только в идеальном мире, все это делается быстро и просто. В реальном мире нужно распутывать массу сложностей, работать с плохо читаемым кодом, и даже саму оценку трудоемкости каких-либо изменений бывает очень сложно провести. </p><p>Кроме этого, чем хуже обстоят дела с Maintainability, тем хуже мотивация разработчиков. Это значит, что они могут дополнительно повышать сложность кода или просто уходить в другие проекты, где работать проще. Таким образом, в коде остаются плохо документированные и неавтоматизированные фрагменты, о которых знает только узкий круг людей. В таком случае уход всего 2-3 человек еще больше увеличивает стоимость поддержки кода. А при увольнении еще пары человек уже может быть риск для ведения бизнеса. Придется нанимать любых разработчиков с рынка, возможно втридорога, чтобы закрыть эту дыру.</p><p>Что делать в такой ситуации? Я не раз слышал призыв: “Давайте выкинем кодовую базу и перепишем ее с нуля”. Но, если честно, я не знаю, при каких условиях этот подход себя оправдает. Насколько показывает мой личный опыт, а также мнение моих коллег и экспертов, с которыми приходилось общаться — на практике это никогда не работает.</p><p>Старая кодовая база, как бы ужасна она не была, как бы дорого не стоило ее сопровождение, имеет один очень важный плюс: она работает и приносит деньги уже сегодня. Иначе вопрос maintenance cost вообще не стоял бы на повестке дня —  проект просто закрыли бы. Поэтому нужно взвешенно подойти к проблеме улучшения качества кода.</p><h3>Удалить это нельзя. Жить с этим невозможно. Что делать?</h3><p>Сначала нужно понять, насколько критическое состояние кода отдельных компонентов на сегодняшний день. Для этого существует ряд стандартов ISO, которые определяют Maintainability как совокупность множества факторов. Давайте пройдемся по ним немного подробнее.</p><p><strong>Modifiability </strong>(changeability) — характеристика, которая отражает, насколько легко (или сложно) поменять кодовую базу, вносить изменения, адаптировать код под новую окружающую реальность. И здесь речь не только о новом функционале, но и об изменениях внешней среды. Например, если изменился интерфейс ОС, набор библиотек, как сложно будет привести в соответствие к ним наш код?</p><p>Метрика Modifiability включает в себя оценку так называемого Coding Style. Если все написано в одном стиле, оставлены комментарии для будущих поколений, то дорабатывать код будет проще.  Точно также для улучшения Modifiability нужно стремится к низкой цикломатической (или структурной) сложности кода — то есть избегать большого количества ветвлений в рамках одного сегмента, а также к компактности (отсутствию \"портянок\" на несколько страниц), атомарности и простоте (речь идет в том числе про отсутствие смешивания разного функционала) единицы компиляции (функции, класса, методов класса). И это еще не все — в понятие Maintainability входит много других приемов улучшения читабельности кода.</p><p>Однако в реальном мире при стремлении к хорошему Modifiability нужно вовремя себя остановить. Как говорил Рид Хоффман \"Если вам не стыдно за первую версию вашего продукта, вы запустились слишком поздно\"? </p><p>Дело в том, что рынок не будет ждать, пока мы пишем свой идеальный код. К тому же никто не гарантирует, что через 2 года представление об идеале не изменится, и нам не придется заново его улучшать. А перегибание палки в вопросах качества кода может не только отнять много времени, но и демотивировать сотрудников.</p><p>Что касается креативности разработчика, тут тоже есть свои нюансы. С одной стороны, оригинальный подход — это хорошо. Но чем более креативно написан код, тем выше требования к креативности будущих читателей этого кода. Поэтому вместо использования семантически красивой конструкции, зачастую лучше использовать что-то простое, пусть даже с меньшей эффективностью (конечно, если она не критична). В этом случае можно пожертвовать даже компактностью кода, потому что “красивая” конструкция тоже не имеет смысла, если она будет не читаема. Так вы гарантируете, что потом его смогут прочитать больше людей без сверхнапряжения мозга. Да и на самом деле \"семантически красивая конструкция\" зачастую даже менее эффективна, чем \"простой\" код.</p><p><strong>Modularity</strong> — характеризует архитектурное качество кода. Здесь можно оценить, насколько легко вносить изменения в код, но уже не по отступам и комментариям, а на уровне модулей. В зависимости от того, насколько разные модули могут сопрягаться друг с другом, насколько они независимы, понятно ли разделение функциональности между ними, получается хорошая или плохая Modularity.</p><p>При хорошей Modularity большая часть изменений проходит локально, внутри одного модуля — микросервиса или библиотеки. Впрочем, даже в монолите, и в рамках одного модуля возможна хорошая Modularity. Чаще всего даже библиотека или микросервис не состоят из совсем уж атомарного функционала (утрируя, из одной функции или класса). В этом случае, как и для монолита, важна хорошая структурированность \"внутри\". Фактически Modularity важна на всех уровнях: макро-части продукта, модулей, единиц компиляции. При таком подходе изменения кодовой базы будут происходить быстрее и стоить дешевле.</p><p><strong>Testability </strong>— это простота проведения тестов. И хотя не работавшим с этой темой людям часто кажется, что написать тесты очень просто, на практике тестирование бывает чудовищно долгим и дорогим. </p><p>При этом нужно понимать, что важен каждый уровень тестирования: модульное, интеграционное, системное. Мало того, отсутствие одного из уровней серьезно усложняет разработку — чем \"выше\" уровень тестирования, тем более он чувствителен к ошибкам в любом звене, и тем сложнее диагностировать эти ошибки. </p><p>Поэтому нельзя обойтись только, например, одним только системным тестированием. Но с другой стороны, без него (и без приемочного тестирования) невозможно утверждать, что продукт работает правильно. </p><p>Чрезмерно увлекаться модульным тестированием тоже не стоит: я был свидетелем того, как пытались добиться полного покрытия всех ветвлений кода юнит-тестами. Привело это к чудовищному усложнению интерфейсов, при том, что покрытию все-равно было далеко до 100%. </p><p>Разумным выглядит начальное покрытие основных сценариев всеми или большей частью видов тестов из цепочки \"юнит-тесты -> функциональные  -> интеграционные -> системные\" и последующее дополнение этого набора по мере расширения множества сценариев, в том числе. из опыта тестирования более высокого уровня и эксплуатации продукта. </p><p>Наличие модульного тестирования, кроме того, облегчает исправление ошибок: выделяется минимальный сценарий, под него пишется тест, запусками которого контролируется исправление (т.е. частично применяется всем известный принцип TDD aka \"разработка через тестирование\").</p><p><strong>Supportability</strong> — это метрика, которая говорит о том, насколько службе поддержки легко работать с вашим продуктом. И тут есть очень важный нюанс, который стоит в стороне от самой кодовой базы. Ведь Support часто не имеет доступа к коду, а если даже имеет — далеко не всегда хочет туда смотреть. </p><p>По большому счету Supportability складывается из ответов на подобные вопросы:</p><ol><li><p>Может ли пользователь починить проблему самостоятельно или с подсказками службы поддержки и сводится ли проблема к предыдущим кейсам? <em>(впрочем, это возможно только при наличии достаточной документации, построенной на базе информации от разработчиков и тестировщиков)</em></p></li><li><p>Какая диагностическая информация нужна для разрешения ситуации, и удается ли ее собрать?</p></li><li><p>Можем ли мы сказать, в каком компоненте произошла ошибка?</p></li></ol><p>При хорошем Supportability время не тратится даром и каждый кейс сразу решается или передается ответственным разработчикам. При плохом уровне Supportability часто возникают подобные диалоги:</p><p><em>Support: Ваня, это твоя проблема?</em></p><p><em>Ваня: Не, вообще не моя. Спросите Валеру.</em></p><p><em>Support: Валера, это твоя проблема?</em></p><p><em>Валера: Нет, Васина. Я точно знаю</em></p><p><em>Support: Вася, посмотри, что там сломалось?</em></p><p><em>Вася: Ну ок, сейчас...</em></p><p>Вася, наконец, начинает изучать код и обнаруживает, что проблема — вовсе не на его стороне. Вопрос переходит к Валере. Валера, пока смотрел, обнаружил, что, все-таки виноват компонент Вани. После этого начинается реальная работа над багом. Хотя время пересылки и поиска проблем в чужих компонентов можно было бы потратить на что-то полезное.</p><p><strong>Debugability</strong> — это метрика, отражающая, насколько мы владеем диагностической информацией для обнаружения багов. Она во многом пересекается с Supportability и даже, можно сказать, является ее пререквизитом. В достаточно развитых (крупных) системах или продуктах отладка как таковая сильно затруднена. Поэтому качественная и подробная обработка ошибок и сбор информации являются более эффективным инструментом для решения проблем даже при \"внутреннем\" тестировании</p><p>Тут снова играет роль степень покрытия тестами (особенно когда мы говорим об автотестах и регрессивном тестировании), потому что без этого невозможно развитие кода (Modifiability, \"чистка мусора\" aka рефакторинг и т.д.). Я бы даже сказал, что изменение кода, предварительно не покрытого тестами, может быть успешным только случайно, если мы, конечно, говорим не про \"Hello, world\".</p><p>Да, важным источником данных об ошибках выступает служба поддержки. Но она получает ее от пользователей, хотя о потенциальных проблемах можно было бы узнать и раньше. А сделать это можно именно за счет покрытия тестами. </p><p>Тем временем вылавливать баги можно также за счет автоматизированной сборки репортов и диагностической информации (обязательно подробной). Если мы получаем отчеты от разных модулей, то имеем возможность настроить self healing или, по крайней мере, передать информацию специалистам, пока какие-то проблемы не превратились в реальный баг.</p><p>Диагностическая информация должна быть полной — то есть полностью покрывать все возможные случаи сбоев. А для успешного решения задачи нужно собирать такие метрики как:</p><ol><li><p>Падения системы</p></li><li><p>Зависания системы</p></li><li><p>Снижение производительности</p></li><li><p>Нештатное поведение системы</p></li></ol><p><strong>Так какой же уровень Maintainability нужен?</strong></p><p>Ответ на этот вопрос будет индивидуальным для каждой компании и для каждого продукта. Например, для определения степени Maintainability используются такие характеристики как скорость разработки новых маленьких и/или больших фич, скорость закрытия инцидентов на стороне пользователя, объем регресса при разработке нового функционала и так далее.</p><p>Интересное мнение по поводу оценки технического долга высказывает Мартин Фаулер, один из ведущих идеологов в этой сфере, почитать его можно <a href=\"https://martinfowler.com/bliki/TechnicalDebt.html\"><u>здесь</u></a>. Основная мысль заключается в том, что любой код содержит в себе “мусор”, и из-за этого разработка ведется медленнее. Но каждый раз нам нужно делать выбор, расчистить часть мусора, скажем, за один день, чтобы сократить время разработки дополнительного компонента на 2 дня или весь мусор за 4 дня, чтобы разработка велась быстрее на 3 дня. Как показывает практика, стремиться к идеальному коду и идеальному Maintainability не имеет смысла. Вместо этого нужно выбрать уровень Maintainability который обеспечивает максимальный вклад в сокращение стоимости поддержки и развития кода. </p><p>Часто Maintainability ассоциируют с техническим долгом. Но эта ассоциация не верна: улучшение Maintainability может быть частью долга, но синонимом не является. Конечно, в общем случае наличие практически любого технического долга замедляет разработку, что описано, например, в agile методологиях, говорящих о соотношении velocity с technical debt.</p><p>Что касается уровня Maintainability — нужно как минимум предпринимать действия к сохранению этого параметра на том же уровне, или постепенно двигаться к его сокращению, потому что “мусор” в коде имеет свойство плодиться и разрастаться, если его не контролировать. Мы в Киберпротекте придерживаемся основных правил сохранения оптимального уровня Maintainability, благодаря чему можем выкатывать несколько крупных обновлений в год для всей нашей линейки продуктов.</p><p>Кстати, интересно, а вы используете в своей практике какие-либо методы поддержания или улучшения Maintainability? Применяете методы или инструменты для его измерения и оценки? Поделитесь, пожалуйста, в комментариях, если у вас есть такой опыт.</p><p></p></div>",
        "clean_body": "Привет, Хабр! Сегодня мне хотелось бы поговорить о такой интересной метрике, как Maintainability - возможность вести доработки и улучшения при создании сложных систем. Ведь при развитии любого программного продукта возникает вопрос, сколько будет стоить его поддержка и развитие. Мы в Киберпротекте разрабатываем линейку продуктов для защиты данных и сегодня это — миллионы строк кода, требующие ощутимых затрат как на поддержку, так и на расширение возможностей или исправление найденных ошибок. В этой статье я делюсь своими мыслями о том, как оценить Maintainability, из чего она состоит, можно ли ее измерить, и как принимать правильные решения при работе с кодом.В те моменты, когда программный продукт стабильно работает, большинству не интересно, как именно он написан. Но когда возникает потребность в модификации, все проблемы с качеством разработки сразу же вылезают наружу. Как только нужно что-то изменить, поправить, дополнить или доработать, мы вынуждены оценивать стоимость этих мероприятий. И далеко не всегда полученные результаты оказываются радостными.Проблемы неидеального кодаЕсли с кодом сложно работать, команда разработчиков просто не имеет возможности развивать новые фичи быстро и в достаточном количестве. Стоимость внедрения новых функций оказывается выше, если каждый раз приходится разбираться с запутанным кодом, с которым нужно интегрировать что-то новое. А если в техподдержку поступило сообщение об ошибке на стороне пользователя, ее нужно исправлять как можно быстрее. Но от качества кодовой базы напрямую зависит, как быстро специалисты разберутся, к какому компоненту относится проблема и кто может ее устранить. Далее нужно определить, сколько времени займет исправление, как быстро мы сможем провести тесты и убедиться, что все хорошо.В случае с идеальным кодом, который встречается только в идеальном мире, все это делается быстро и просто. В реальном мире нужно распутывать массу сложностей, работать с плохо читаемым кодом, и даже саму оценку трудоемкости каких-либо изменений бывает очень сложно провести. Кроме этого, чем хуже обстоят дела с Maintainability, тем хуже мотивация разработчиков. Это значит, что они могут дополнительно повышать сложность кода или просто уходить в другие проекты, где работать проще. Таким образом, в коде остаются плохо документированные и неавтоматизированные фрагменты, о которых знает только узкий круг людей. В таком случае уход всего 2-3 человек еще больше увеличивает стоимость поддержки кода. А при увольнении еще пары человек уже может быть риск для ведения бизнеса. Придется нанимать любых разработчиков с рынка, возможно втридорога, чтобы закрыть эту дыру.Что делать в такой ситуации? Я не раз слышал призыв: “Давайте выкинем кодовую базу и перепишем ее с нуля”. Но, если честно, я не знаю, при каких условиях этот подход себя оправдает. Насколько показывает мой личный опыт, а также мнение моих коллег и экспертов, с которыми приходилось общаться — на практике это никогда не работает.Старая кодовая база, как бы ужасна она не была, как бы дорого не стоило ее сопровождение, имеет один очень важный плюс: она работает и приносит деньги уже сегодня. Иначе вопрос maintenance cost вообще не стоял бы на повестке дня —  проект просто закрыли бы. Поэтому нужно взвешенно подойти к проблеме улучшения качества кода.Удалить это нельзя. Жить с этим невозможно. Что делать?Сначала нужно понять, насколько критическое состояние кода отдельных компонентов на сегодняшний день. Для этого существует ряд стандартов ISO, которые определяют Maintainability как совокупность множества факторов. Давайте пройдемся по ним немного подробнее.Modifiability (changeability) — характеристика, которая отражает, насколько легко (или сложно) поменять кодовую базу, вносить изменения, адаптировать код под новую окружающую реальность. И здесь речь не только о новом функционале, но и об изменениях внешней среды. Например, если изменился интерфейс ОС, набор библиотек, как сложно будет привести в соответствие к ним наш код?Метрика Modifiability включает в себя оценку так называемого Coding Style. Если все написано в одном стиле, оставлены комментарии для будущих поколений, то дорабатывать код будет проще.  Точно также для улучшения Modifiability нужно стремится к низкой цикломатической (или структурной) сложности кода — то есть избегать большого количества ветвлений в рамках одного сегмента, а также к компактности (отсутствию \"портянок\" на несколько страниц), атомарности и простоте (речь идет в том числе про отсутствие смешивания разного функционала) единицы компиляции (функции, класса, методов класса). И это еще не все — в понятие Maintainability входит много других приемов улучшения читабельности кода.Однако в реальном мире при стремлении к хорошему Modifiability нужно вовремя себя остановить. Как говорил Рид Хоффман \"Если вам не стыдно за первую версию вашего продукта, вы запустились слишком поздно\"? Дело в том, что рынок не будет ждать, пока мы пишем свой идеальный код. К тому же никто не гарантирует, что через 2 года представление об идеале не изменится, и нам не придется заново его улучшать. А перегибание палки в вопросах качества кода может не только отнять много времени, но и демотивировать сотрудников.Что касается креативности разработчика, тут тоже есть свои нюансы. С одной стороны, оригинальный подход — это хорошо. Но чем более креативно написан код, тем выше требования к креативности будущих читателей этого кода. Поэтому вместо использования семантически красивой конструкции, зачастую лучше использовать что-то простое, пусть даже с меньшей эффективностью (конечно, если она не критична). В этом случае можно пожертвовать даже компактностью кода, потому что “красивая” конструкция тоже не имеет смысла, если она будет не читаема. Так вы гарантируете, что потом его смогут прочитать больше людей без сверхнапряжения мозга. Да и на самом деле \"семантически красивая конструкция\" зачастую даже менее эффективна, чем \"простой\" код.Modularity — характеризует архитектурное качество кода. Здесь можно оценить, насколько легко вносить изменения в код, но уже не по отступам и комментариям, а на уровне модулей. В зависимости от того, насколько разные модули могут сопрягаться друг с другом, насколько они независимы, понятно ли разделение функциональности между ними, получается хорошая или плохая Modularity.При хорошей Modularity большая часть изменений проходит локально, внутри одного модуля — микросервиса или библиотеки. Впрочем, даже в монолите, и в рамках одного модуля возможна хорошая Modularity. Чаще всего даже библиотека или микросервис не состоят из совсем уж атомарного функционала (утрируя, из одной функции или класса). В этом случае, как и для монолита, важна хорошая структурированность \"внутри\". Фактически Modularity важна на всех уровнях: макро-части продукта, модулей, единиц компиляции. При таком подходе изменения кодовой базы будут происходить быстрее и стоить дешевле.Testability — это простота проведения тестов. И хотя не работавшим с этой темой людям часто кажется, что написать тесты очень просто, на практике тестирование бывает чудовищно долгим и дорогим. При этом нужно понимать, что важен каждый уровень тестирования: модульное, интеграционное, системное. Мало того, отсутствие одного из уровней серьезно усложняет разработку — чем \"выше\" уровень тестирования, тем более он чувствителен к ошибкам в любом звене, и тем сложнее диагностировать эти ошибки. Поэтому нельзя обойтись только, например, одним только системным тестированием. Но с другой стороны, без него (и без приемочного тестирования) невозможно утверждать, что продукт работает правильно. Чрезмерно увлекаться модульным тестированием тоже не стоит: я был свидетелем того, как пытались добиться полного покрытия всех ветвлений кода юнит-тестами. Привело это к чудовищному усложнению интерфейсов, при том, что покрытию все-равно было далеко до 100%. Разумным выглядит начальное покрытие основных сценариев всеми или большей частью видов тестов из цепочки \"юнит-тесты -> функциональные  -> интеграционные -> системные\" и последующее дополнение этого набора по мере расширения множества сценариев, в том числе. из опыта тестирования более высокого уровня и эксплуатации продукта. Наличие модульного тестирования, кроме того, облегчает исправление ошибок: выделяется минимальный сценарий, под него пишется тест, запусками которого контролируется исправление (т.е. частично применяется всем известный принцип TDD aka \"разработка через тестирование\").Supportability — это метрика, которая говорит о том, насколько службе поддержки легко работать с вашим продуктом. И тут есть очень важный нюанс, который стоит в стороне от самой кодовой базы. Ведь Support часто не имеет доступа к коду, а если даже имеет — далеко не всегда хочет туда смотреть. По большому счету Supportability складывается из ответов на подобные вопросы:Может ли пользователь починить проблему самостоятельно или с подсказками службы поддержки и сводится ли проблема к предыдущим кейсам? (впрочем, это возможно только при наличии достаточной документации, построенной на базе информации от разработчиков и тестировщиков)Какая диагностическая информация нужна для разрешения ситуации, и удается ли ее собрать?Можем ли мы сказать, в каком компоненте произошла ошибка?При хорошем Supportability время не тратится даром и каждый кейс сразу решается или передается ответственным разработчикам. При плохом уровне Supportability часто возникают подобные диалоги:Support: Ваня, это твоя проблема?Ваня: Не, вообще не моя. Спросите Валеру.Support: Валера, это твоя проблема?Валера: Нет, Васина. Я точно знаюSupport: Вася, посмотри, что там сломалось?Вася: Ну ок, сейчас...Вася, наконец, начинает изучать код и обнаруживает, что проблема — вовсе не на его стороне. Вопрос переходит к Валере. Валера, пока смотрел, обнаружил, что, все-таки виноват компонент Вани. После этого начинается реальная работа над багом. Хотя время пересылки и поиска проблем в чужих компонентов можно было бы потратить на что-то полезное.Debugability — это метрика, отражающая, насколько мы владеем диагностической информацией для обнаружения багов. Она во многом пересекается с Supportability и даже, можно сказать, является ее пререквизитом. В достаточно развитых (крупных) системах или продуктах отладка как таковая сильно затруднена. Поэтому качественная и подробная обработка ошибок и сбор информации являются более эффективным инструментом для решения проблем даже при \"внутреннем\" тестированииТут снова играет роль степень покрытия тестами (особенно когда мы говорим об автотестах и регрессивном тестировании), потому что без этого невозможно развитие кода (Modifiability, \"чистка мусора\" aka рефакторинг и т.д.). Я бы даже сказал, что изменение кода, предварительно не покрытого тестами, может быть успешным только случайно, если мы, конечно, говорим не про \"Hello, world\".Да, важным источником данных об ошибках выступает служба поддержки. Но она получает ее от пользователей, хотя о потенциальных проблемах можно было бы узнать и раньше. А сделать это можно именно за счет покрытия тестами. Тем временем вылавливать баги можно также за счет автоматизированной сборки репортов и диагностической информации (обязательно подробной). Если мы получаем отчеты от разных модулей, то имеем возможность настроить self healing или, по крайней мере, передать информацию специалистам, пока какие-то проблемы не превратились в реальный баг.Диагностическая информация должна быть полной — то есть полностью покрывать все возможные случаи сбоев. А для успешного решения задачи нужно собирать такие метрики как:Падения системыЗависания системыСнижение производительностиНештатное поведение системыТак какой же уровень Maintainability нужен?Ответ на этот вопрос будет индивидуальным для каждой компании и для каждого продукта. Например, для определения степени Maintainability используются такие характеристики как скорость разработки новых маленьких и/или больших фич, скорость закрытия инцидентов на стороне пользователя, объем регресса при разработке нового функционала и так далее.Интересное мнение по поводу оценки технического долга высказывает Мартин Фаулер, один из ведущих идеологов в этой сфере, почитать его можно здесь. Основная мысль заключается в том, что любой код содержит в себе “мусор”, и из-за этого разработка ведется медленнее. Но каждый раз нам нужно делать выбор, расчистить часть мусора, скажем, за один день, чтобы сократить время разработки дополнительного компонента на 2 дня или весь мусор за 4 дня, чтобы разработка велась быстрее на 3 дня. Как показывает практика, стремиться к идеальному коду и идеальному Maintainability не имеет смысла. Вместо этого нужно выбрать уровень Maintainability который обеспечивает максимальный вклад в сокращение стоимости поддержки и развития кода. Часто Maintainability ассоциируют с техническим долгом. Но эта ассоциация не верна: улучшение Maintainability может быть частью долга, но синонимом не является. Конечно, в общем случае наличие практически любого технического долга замедляет разработку, что описано, например, в agile методологиях, говорящих о соотношении velocity с technical debt.Что касается уровня Maintainability — нужно как минимум предпринимать действия к сохранению этого параметра на том же уровне, или постепенно двигаться к его сокращению, потому что “мусор” в коде имеет свойство плодиться и разрастаться, если его не контролировать. Мы в Киберпротекте придерживаемся основных правил сохранения оптимального уровня Maintainability, благодаря чему можем выкатывать несколько крупных обновлений в год для всей нашей линейки продуктов.Кстати, интересно, а вы используете в своей практике какие-либо методы поддержания или улучшения Maintainability? Применяете методы или инструменты для его измерения и оценки? Поделитесь, пожалуйста, в комментариях, если у вас есть такой опыт.",
        "meta_tags": [
            "идеальный код",
            "разработка",
            "mantainability",
            "Киберпротект",
            "модификация кода"
        ]
    },
    {
        "publish_datetime": 1669969379.0,
        "author": null,
        "title": "Основные метрики бесперебойности облачных IT-систем",
        "title_image_url": "https://habrastorage.org/getpro/habr/upload_files/009/d06/26f/009d0626fa1a70b7215862353fccb079.jpg",
        "raw_body": "<div xmlns=\"http://www.w3.org/1999/xhtml\"><figure class=\"full-width \"><img src=\"https://habrastorage.org/r/w780q1/getpro/habr/upload_files/009/d06/26f/009d0626fa1a70b7215862353fccb079.jpg\" width=\"1200\" height=\"600\" data-src=\"https://habrastorage.org/getpro/habr/upload_files/009/d06/26f/009d0626fa1a70b7215862353fccb079.jpg\" data-blurred=\"true\"/><figcaption></figcaption></figure><p><em>Привет, Хабр!</em></p><p><em>Меня зовут Сергей, я отвечаю за инфобезопасность в MANGO OFFICE. Сегодня хочу осветить тему отказоустойчивости облачных ИТ-систем и рассказать, как мы в компании решаем эти вопросы.</em> </p><h3>Основные уязвимости облачных IT-систем </h3><p>Тут Америку не откроем. Есть два типа уязвимостей:</p><ul><li><p>Возможность несанкционированного доступа к данным клиента со стороны провайдера облачного сервиса. Этим и опасно хранение чувствительных данных в публичных хранилищах. Наша компания также выступает как провайдер хранилищ, но мы в нашем продукте — Гибридной АТС, сочетающей функции облака и железной АТС — решили проблему доступа тем, что внутренний медиатрафик остается внутри сети клиента, к нам попадает только сигнальный трафик. В будущем планируем реализовать проект, где сигнальный трафик у нас тоже храниться не будет. </p></li><li><p>Вторая главная уязвимость — потеря доступности системы. Если одним словом: нет интернета, значит, нет возможности работать с облаком, в то время как On-Premise-решения работают даже без доступа к сети. </p></li></ul><p>Если говорить об уязвимостях, появившихся в последнее время, то, в первую очередь, они обусловлены тем, что в большинстве случаев облачные сервисы использовали иностранные средства защиты. Уход иностранных вендоров, отсутствие возможности продлевать и докупать лицензии оставили ИТ-инфраструктуры без должной защиты до перехода на решения российских вендоров. К примеру, у нас в компании было облачное решение для исследования уязвимостей Tenable I.O. Купили мы его 1 февраля 2022 года, а уже 27 февраля нас отключили от обслуживания (без возврата денег). В итоге мы перешли на российское решение.</p><p>Ответ на резонный вопрос: “Почему пользовались иностранными средствами защиты?”, — прост. Долгое время российские решения уступали зарубежным. Да, в последние три года немалая часть отечественных поставщиков сделала большой скачок в развитии. Однако сфера инфобезопасности довольно консервативна при всей своей изменчивости: люди обучены и привыкли работать с зарубежными вендорами и системами, а переход для всех очень болезненный. Смена требует инвестиций в том числе в обучение персонала и выстраивания перехода так, чтобы процессы не пострадали. Но к сегодняшнему дню все больше компаний обращает внимание на российские решения. </p><h3>Как измеряется продукт с точки зрения безопасности</h3><p>Продукт можно измерять с точки зрения безопасности следующим образом:</p><ul><li><p>RTO (Recovery Time Objective) — целевое время восстановления системы после сбоя. </p></li><li><p>RPO (Recovery Point Objective) — целевая точка восстановления на шкале времени относительно сбоя, до которой требуется сохранить данные.</p></li><li><p>SLA (Service Level Agreement) — соглашение об уровне предоставления услуг. Это обязательство об уровне сервиса продукта/услуги, взятое компанией перед клиентом. Очень важна гарантированная доступность сервиса в течение года: сколько раз могут случаться сбои и какое время может быть недоступна система. Есть компании, заявляющие доступность 99,99%, то есть в год система может не быть доступна 0,01%.</p></li><li><p>Гарантия конфиденциальности данных. При анализе рисков конкретного продукта нужно смотреть, какую гарантию по производительности дает производитель. Никто не гарантирует 100 %, но конфиденциальность — тоже метрика, ее можно оценить (сколько было случаев потери данных у продукта). Если больше одного–двух, доверия к продуктам нет. </p></li><li><p>Целостность данных. Юзер пользуется данными, например, создавая подборку на стриминговом сервисе, а при следующем визите подборка слетает. Это показатель того, что данные повреждены. Если таких случаев не было, значит, с компания надежно их хранит.</p></li></ul><h3>Как SSDLC помогает предотвращать угрозы на уровне разработки продукта</h3><p>SSDLS — это процесс безопасной разработки, при котором на всех этапах жизненного цикла разработки ПО учитываются риски инфобезопасности, выявляются и устраняются уязвимости в программном коде, чтобы в релиз выпускался продукт безопасный как с точки зрения кода, так и с точки зрения архитектуры логики работы.</p><p>Вот так он выглядит в нашей компании: </p><figure class=\"full-width \"><img src=\"https://habrastorage.org/r/w780q1/getpro/habr/upload_files/840/870/f79/840870f7926f28d952dd68c8d5489e37.jpg\" width=\"1200\" height=\"675\" data-src=\"https://habrastorage.org/getpro/habr/upload_files/840/870/f79/840870f7926f28d952dd68c8d5489e37.jpg\" data-blurred=\"true\"/><figcaption></figcaption></figure><p>Основные метрики, применяемые в нашем SSDLC-процессе: </p><ul><li><p>Количество выявленных и подтвержденных уязвимостей в процессе эксплуатации кода в текущих релизах продуктов. В идеале они должны стремиться к нулю. На практике, конечно, определенная уязвимость есть всегда, но если над кодом работает сильная команда и в компании есть application security, то есть человек, отвечающий за безопасность приложения, — продукты выпускаются зрелыми. </p></li><li><p>Зрелость процесса безопасной разработки по SAMM v2.0. Вычисляется для текущих исследуемых команд  на основе собственных исследований.\t</p></li><li><p>Доля автоматизации. Показатель применения автоматизированных средств анализа инфобезопасности в проектах команд в CICD-процессах.  </p></li><li><p>Доля покрытия команд процессом безопасной разработки. Метрика показывает соотношение команд, которые участвуют в процессе безопасной разработки, ко всем командам (участием считается взаимодействие с командой, использование автоматизации, исправление и обсуждение вопросов).</p></li></ul><h3>Защита продукта во время эксплуатации</h3><p>Во время эксплуатации продукта надо использовать комплекс средств защиты, которые должны защищать его на: сетевом уровне, уровне баз данных и уровне взаимодействия пользователя с системой (если речь о веб-приложении). </p><p>Для защиты продукта нужно разработать модель угроз для данного продукта, оценить вероятность их возникновения и, исходя из актуальных угроз для продукта, реализовать набор мер по его защите (технических и организационных).</p><p>Инструменты применяются различные, в зависимости от актуальной угрозы: межсетевые экраны, регулярные сканирования на уязвимости, системы мониторинга событий информационной безопасности, обнаружения сетевых атак внутри сети и во внешнем контуре, контроля и разграничения прав данных, шифрование, системы контроля утечек данных, выявления вредоносного кода, выявления атак нулевого дня (Zero day). </p><blockquote><p><em>Атаки Zero Day — угрозы, которые только что появилось, и никто еще не знает, как от них защититься. Но есть решения, которые, используя машинную логику, выявляют такого рода атаки.</em>  </p></blockquote><p>Мы в  процессе безопасной разработки используем отечественное решение — статический анализатор кода, выявляющий уязвимости в коде. В следующем году наш вендор собирается предложить динамический анализатор кода, выявляющий уязвимости в ходе эксплуатации продукта. Для управления уязвимостями компонентов ИТ-инфраструктуры продуктов используются автоматизированные решения управления  уязвимостями.</p><h3>К чему мы стремимся </h3><p>Нет предела совершенству, и мы (как и все, вероятно) стремимся к ближайшему к 100 % показателю отказоустойчивости систем. Но на практике редкие компании могут подтвердить бесперебойность 99,999 % (а это означает, что система может быть недоступна 5 минут 15 секунд в год) и только для узких наборов сервисов. Обычно это касается, к примеру, систем электропитания, которые находятся в ЦОД. Сейчас по рынку эталон — 99,95 %. В процент доступности должны входить: восстановление в случае сбоя и плановые работы. У нас в компании по некоторым услугам уровень отказоустойчивости 99,99 %, подтвержденный исторически. </p><blockquote><p><em>Здесь нужно учитывать параметр, в котором кроется сложность: в течение какого времени мы будем восстанавливаться в случае сбоя. Система может отлично работать и падать очень редко, но когда упадет — восстанавливается час–два. И именно из-за этого некоторые компании могут проигрывать в конечных показателях доступности.</em>  </p></blockquote><p>Не в последнюю очередь на повышение показателей доступности влияют микросервисы. Когда приложение монолитное, выход из строя какого-либо компонента приводит к его падению полностью. Выход из строя компонента в микросервисе приводит к падению конкретного микросервиса, остальное будет работать. Конечно, все зависит от программистов, архитекторов: нужно не допускать ситуаций, когда несколько микросервисов одновременно прекращает работу.</p><p>Если говорить о ближайшем будущем инфобезопасности, то, как уже упоминалось, на сегодняшний день основная тенденция — переход к отечественным решениям. Даже если зарубежные вендоры будут возвращаться, доля российских поставщиков будет расти, так как созданный прецедент заставил задуматься многие компании. Мы, как раньше, так и сейчас, отдаем предпочтение отечественным разработкам. </p><hr/><p><em>Подписывайтесь на наши соцсети:</em></p><p><strong>Аккаунты Mango Office</strong></p><ul><li><p>ВКонтакте: <a href=\"https://vk.com/mangotelecom\"><u>https://vk.com/mangotelecom</u></a></p></li><li><p>Телеграм: <a href=\"https://t.me/mango_office\"><u>https://t.me/mango_office</u></a></p></li></ul><p></p></div>",
        "clean_body": "Привет, Хабр!Меня зовут Сергей, я отвечаю за инфобезопасность в MANGO OFFICE. Сегодня хочу осветить тему отказоустойчивости облачных ИТ-систем и рассказать, как мы в компании решаем эти вопросы. Основные уязвимости облачных IT-систем Тут Америку не откроем. Есть два типа уязвимостей:Возможность несанкционированного доступа к данным клиента со стороны провайдера облачного сервиса. Этим и опасно хранение чувствительных данных в публичных хранилищах. Наша компания также выступает как провайдер хранилищ, но мы в нашем продукте — Гибридной АТС, сочетающей функции облака и железной АТС — решили проблему доступа тем, что внутренний медиатрафик остается внутри сети клиента, к нам попадает только сигнальный трафик. В будущем планируем реализовать проект, где сигнальный трафик у нас тоже храниться не будет. Вторая главная уязвимость — потеря доступности системы. Если одним словом: нет интернета, значит, нет возможности работать с облаком, в то время как On-Premise-решения работают даже без доступа к сети. Если говорить об уязвимостях, появившихся в последнее время, то, в первую очередь, они обусловлены тем, что в большинстве случаев облачные сервисы использовали иностранные средства защиты. Уход иностранных вендоров, отсутствие возможности продлевать и докупать лицензии оставили ИТ-инфраструктуры без должной защиты до перехода на решения российских вендоров. К примеру, у нас в компании было облачное решение для исследования уязвимостей Tenable I.O. Купили мы его 1 февраля 2022 года, а уже 27 февраля нас отключили от обслуживания (без возврата денег). В итоге мы перешли на российское решение.Ответ на резонный вопрос: “Почему пользовались иностранными средствами защиты?”, — прост. Долгое время российские решения уступали зарубежным. Да, в последние три года немалая часть отечественных поставщиков сделала большой скачок в развитии. Однако сфера инфобезопасности довольно консервативна при всей своей изменчивости: люди обучены и привыкли работать с зарубежными вендорами и системами, а переход для всех очень болезненный. Смена требует инвестиций в том числе в обучение персонала и выстраивания перехода так, чтобы процессы не пострадали. Но к сегодняшнему дню все больше компаний обращает внимание на российские решения. Как измеряется продукт с точки зрения безопасностиПродукт можно измерять с точки зрения безопасности следующим образом:RTO (Recovery Time Objective) — целевое время восстановления системы после сбоя. RPO (Recovery Point Objective) — целевая точка восстановления на шкале времени относительно сбоя, до которой требуется сохранить данные.SLA (Service Level Agreement) — соглашение об уровне предоставления услуг. Это обязательство об уровне сервиса продукта/услуги, взятое компанией перед клиентом. Очень важна гарантированная доступность сервиса в течение года: сколько раз могут случаться сбои и какое время может быть недоступна система. Есть компании, заявляющие доступность 99,99%, то есть в год система может не быть доступна 0,01%.Гарантия конфиденциальности данных. При анализе рисков конкретного продукта нужно смотреть, какую гарантию по производительности дает производитель. Никто не гарантирует 100 %, но конфиденциальность — тоже метрика, ее можно оценить (сколько было случаев потери данных у продукта). Если больше одного–двух, доверия к продуктам нет. Целостность данных. Юзер пользуется данными, например, создавая подборку на стриминговом сервисе, а при следующем визите подборка слетает. Это показатель того, что данные повреждены. Если таких случаев не было, значит, с компания надежно их хранит.Как SSDLC помогает предотвращать угрозы на уровне разработки продуктаSSDLS — это процесс безопасной разработки, при котором на всех этапах жизненного цикла разработки ПО учитываются риски инфобезопасности, выявляются и устраняются уязвимости в программном коде, чтобы в релиз выпускался продукт безопасный как с точки зрения кода, так и с точки зрения архитектуры логики работы.Вот так он выглядит в нашей компании: Основные метрики, применяемые в нашем SSDLC-процессе: Количество выявленных и подтвержденных уязвимостей в процессе эксплуатации кода в текущих релизах продуктов. В идеале они должны стремиться к нулю. На практике, конечно, определенная уязвимость есть всегда, но если над кодом работает сильная команда и в компании есть application security, то есть человек, отвечающий за безопасность приложения, — продукты выпускаются зрелыми. Зрелость процесса безопасной разработки по SAMM v2.0. Вычисляется для текущих исследуемых команд  на основе собственных исследований.\tДоля автоматизации. Показатель применения автоматизированных средств анализа инфобезопасности в проектах команд в CICD-процессах.  Доля покрытия команд процессом безопасной разработки. Метрика показывает соотношение команд, которые участвуют в процессе безопасной разработки, ко всем командам (участием считается взаимодействие с командой, использование автоматизации, исправление и обсуждение вопросов).Защита продукта во время эксплуатацииВо время эксплуатации продукта надо использовать комплекс средств защиты, которые должны защищать его на: сетевом уровне, уровне баз данных и уровне взаимодействия пользователя с системой (если речь о веб-приложении). Для защиты продукта нужно разработать модель угроз для данного продукта, оценить вероятность их возникновения и, исходя из актуальных угроз для продукта, реализовать набор мер по его защите (технических и организационных).Инструменты применяются различные, в зависимости от актуальной угрозы: межсетевые экраны, регулярные сканирования на уязвимости, системы мониторинга событий информационной безопасности, обнаружения сетевых атак внутри сети и во внешнем контуре, контроля и разграничения прав данных, шифрование, системы контроля утечек данных, выявления вредоносного кода, выявления атак нулевого дня (Zero day). Атаки Zero Day — угрозы, которые только что появилось, и никто еще не знает, как от них защититься. Но есть решения, которые, используя машинную логику, выявляют такого рода атаки. Мы в  процессе безопасной разработки используем отечественное решение — статический анализатор кода, выявляющий уязвимости в коде. В следующем году наш вендор собирается предложить динамический анализатор кода, выявляющий уязвимости в ходе эксплуатации продукта. Для управления уязвимостями компонентов ИТ-инфраструктуры продуктов используются автоматизированные решения управления  уязвимостями.К чему мы стремимся Нет предела совершенству, и мы (как и все, вероятно) стремимся к ближайшему к 100 % показателю отказоустойчивости систем. Но на практике редкие компании могут подтвердить бесперебойность 99,999 % (а это означает, что система может быть недоступна 5 минут 15 секунд в год) и только для узких наборов сервисов. Обычно это касается, к примеру, систем электропитания, которые находятся в ЦОД. Сейчас по рынку эталон — 99,95 %. В процент доступности должны входить: восстановление в случае сбоя и плановые работы. У нас в компании по некоторым услугам уровень отказоустойчивости 99,99 %, подтвержденный исторически. Здесь нужно учитывать параметр, в котором кроется сложность: в течение какого времени мы будем восстанавливаться в случае сбоя. Система может отлично работать и падать очень редко, но когда упадет — восстанавливается час–два. И именно из-за этого некоторые компании могут проигрывать в конечных показателях доступности. Не в последнюю очередь на повышение показателей доступности влияют микросервисы. Когда приложение монолитное, выход из строя какого-либо компонента приводит к его падению полностью. Выход из строя компонента в микросервисе приводит к падению конкретного микросервиса, остальное будет работать. Конечно, все зависит от программистов, архитекторов: нужно не допускать ситуаций, когда несколько микросервисов одновременно прекращает работу.Если говорить о ближайшем будущем инфобезопасности, то, как уже упоминалось, на сегодняшний день основная тенденция — переход к отечественным решениям. Даже если зарубежные вендоры будут возвращаться, доля российских поставщиков будет расти, так как созданный прецедент заставил задуматься многие компании. Мы, как раньше, так и сейчас, отдаем предпочтение отечественным разработкам. Подписывайтесь на наши соцсети:Аккаунты Mango OfficeВКонтакте: https://vk.com/mangotelecomТелеграм: https://t.me/mango_office",
        "meta_tags": [
            "отказоустойчивость",
            "бесперебойность",
            "информационная безопасность",
            "ssdlc"
        ]
    },
    {
        "publish_datetime": 1669969790.0,
        "author": "Михаил Кабищев",
        "title": "Приглашаем на Ozon Tech Community Platform Meetup",
        "title_image_url": "https://habrastorage.org/getpro/habr/upload_files/35c/f29/2b9/35cf292b9660bd75d0098abd15f31bf8.jpg",
        "raw_body": "<div xmlns=\"http://www.w3.org/1999/xhtml\"><p>Привет, Хабр! Меня зовут Миша Кабищев, я руковожу направлением базовых сервисов в платформе Ozon.</p><figure class=\"full-width \"><img src=\"https://habrastorage.org/r/w1560/getpro/habr/upload_files/22b/2d4/704/22b2d4704208099185f9d60e0cc2f381.png\" width=\"1920\" height=\"1080\" data-src=\"https://habrastorage.org/getpro/habr/upload_files/22b/2d4/704/22b2d4704208099185f9d60e0cc2f381.png\"/><figcaption></figcaption></figure><p>Платформа – это разработка для разработки, мы снабжаем инженеров библиотеками, фреймворками и подходами, которые решают их повседневные проблемы – быстрый старт нового сервиса, работа с очередями и базами данных, балансировка нагрузки, рейт лимитинг, circuit-breaking и многое другое.</p><p>Наша работа начинается с организации и эксплуатации базовой инфраструктуры: 3 ЦОДа, тысячи серверов, петабайты дискового пространства, которые используются для работы всех наших систем.</p><p>Создаем технологические продукты, цель которых — обеспечение автономности при использовании их разработчиками без привлечения системных администраторов и других специалистов: базы данных, хранилища, шины обмена данных, аналитические инструменты, телеметрия. </p><p>И ещё многое другое, о чём мы расскажем на митапе. Одним словом, мы упрощаем жизнь коллег, чтобы Time to market сокращался и пользователи получали больше новых фич без потери качества.</p><p>Приглашаю в гости на открытый <a href=\"http://bit.ly/3VmxzN9\">Ozon Tech Community Platform Meetup</a>, 8 декабря в 18:00 в Алматы. Онлайн формат тоже будет.<br/></p><h3>В программе:</h3><div class=\"persona\" persona=\"true\"><img persona=\"true\" class=\"image persona__image\" src=\"https://habrastorage.org/r/w1560/getpro/habr/upload_files/185/421/0c0/1854210c0a60c87e285f57d3b7865abc.png\" data-src=\"https://habrastorage.org/getpro/habr/upload_files/185/421/0c0/1854210c0a60c87e285f57d3b7865abc.png\"/><h5 class=\"persona__heading\" persona=\"true\">Михаил Кабищев</h5><p>Руководитель направления базовых сервисов</p></div><blockquote><p>Расскажу о технологической революции в Ozon, когда на замену нескольким огромным монолитам пришли тысячи микросервисов, написанные на разных языках. А также о создании набора строительных кубиков, правил и процессов, на основе которых производятся все системы и продукты в компании.</p></blockquote><div class=\"persona\" persona=\"true\"><img persona=\"true\" class=\"image persona__image\" src=\"https://habrastorage.org/getpro/habr/upload_files/9ea/52a/7d1/9ea52a7d1c443119299c057434f417eb.JPG\"/><h5 class=\"persona__heading\" persona=\"true\">Виктор Корейша</h5><p>Руководитель отдела Message Bus</p></div><blockquote><p>Вспомним основные принципы работы с Kafka и разберём 7 ошибок, которые чаще всего встречаются в работе c программой.</p></blockquote><div class=\"persona\" persona=\"true\"><img persona=\"true\" class=\"image persona__image\" src=\"https://habrastorage.org/r/w780q1/getpro/habr/upload_files/360/c0b/71d/360c0b71d98a3d6adf1267b8ded1fe76.jpeg\" data-src=\"https://habrastorage.org/getpro/habr/upload_files/360/c0b/71d/360c0b71d98a3d6adf1267b8ded1fe76.jpeg\" data-blurred=\"true\"/><h5 class=\"persona__heading\" persona=\"true\">Денис Дубовицкий</h5><p>Старший разработчик</p></div><blockquote><p>Расскажем о том, как раздавать большие файлы без бутылочных горлышек.<br/>Рассмотрим передачу больших файлов в кластере Kubernetes, обсудим, почему это не так просто, и сконцентрируем внимание на нашем пути реализации. </p></blockquote><p>А в конце устроим небольшое афтепати. Встречаемся в Алматы в лофте Smart Point, Байзакова, 280. Сбор гостей в 17:30 по местному времени.</p><p>Для участия в событии офлайн, <a href=\"http://bit.ly/3VmxzN9\"><u>регистрируйтесь</u></a> и ждите подтверждения в письме. Также будет трансляция на нашем <a href=\"https://www.youtube.com/channel/UCCqNFXg3NRbRA6qNKFRecdw\"><u>Youtube</u></a> канале и в <a href=\"https://vk.com/techozon\"><u>Vk</u></a>, пройдите регистрацию, чтобы получить ссылку.</p><p>Количество мест в зале ограниченно. Не забудьте взять с собой паспорт или водительское удостоверение.</p><p></p></div>",
        "clean_body": "Привет, Хабр! Меня зовут Миша Кабищев, я руковожу направлением базовых сервисов в платформе Ozon.Платформа – это разработка для разработки, мы снабжаем инженеров библиотеками, фреймворками и подходами, которые решают их повседневные проблемы – быстрый старт нового сервиса, работа с очередями и базами данных, балансировка нагрузки, рейт лимитинг, circuit-breaking и многое другое.Наша работа начинается с организации и эксплуатации базовой инфраструктуры: 3 ЦОДа, тысячи серверов, петабайты дискового пространства, которые используются для работы всех наших систем.Создаем технологические продукты, цель которых — обеспечение автономности при использовании их разработчиками без привлечения системных администраторов и других специалистов: базы данных, хранилища, шины обмена данных, аналитические инструменты, телеметрия. И ещё многое другое, о чём мы расскажем на митапе. Одним словом, мы упрощаем жизнь коллег, чтобы Time to market сокращался и пользователи получали больше новых фич без потери качества.Приглашаю в гости на открытый Ozon Tech Community Platform Meetup, 8 декабря в 18:00 в Алматы. Онлайн формат тоже будет.В программе:Михаил КабищевРуководитель направления базовых сервисовРасскажу о технологической революции в Ozon, когда на замену нескольким огромным монолитам пришли тысячи микросервисов, написанные на разных языках. А также о создании набора строительных кубиков, правил и процессов, на основе которых производятся все системы и продукты в компании.Виктор КорейшаРуководитель отдела Message BusВспомним основные принципы работы с Kafka и разберём 7 ошибок, которые чаще всего встречаются в работе c программой.Денис ДубовицкийСтарший разработчикРасскажем о том, как раздавать большие файлы без бутылочных горлышек.Рассмотрим передачу больших файлов в кластере Kubernetes, обсудим, почему это не так просто, и сконцентрируем внимание на нашем пути реализации. А в конце устроим небольшое афтепати. Встречаемся в Алматы в лофте Smart Point, Байзакова, 280. Сбор гостей в 17:30 по местному времени.Для участия в событии офлайн, регистрируйтесь и ждите подтверждения в письме. Также будет трансляция на нашем Youtube канале и в Vk, пройдите регистрацию, чтобы получить ссылку.Количество мест в зале ограниченно. Не забудьте взять с собой паспорт или водительское удостоверение.",
        "meta_tags": [
            "платформа",
            "ozon tech",
            "kafka",
            "meetup",
            "go",
            "kubernetes"
        ]
    },
    {
        "publish_datetime": 1669970801.0,
        "author": "Михаил Долгих",
        "title": "Трюк, которого не было — 2",
        "title_image_url": "https://habrastorage.org/getpro/habr/upload_files/1fe/033/f0d/1fe033f0d800d0a85f244dbaa4312813.png",
        "raw_body": "<div xmlns=\"http://www.w3.org/1999/xhtml\"><figure class=\"full-width \"><img src=\"https://habrastorage.org/r/w1560/getpro/habr/upload_files/1fe/033/f0d/1fe033f0d800d0a85f244dbaa4312813.png\" width=\"1557\" height=\"830\" data-src=\"https://habrastorage.org/getpro/habr/upload_files/1fe/033/f0d/1fe033f0d800d0a85f244dbaa4312813.png\"/><figcaption></figcaption></figure><p>Привет, Хабр! Моя <a href=\"https://habr.com/ru/post/701360/\" rel=\"noopener noreferrer nofollow\">прошлая статья</a> была встречена сообществом очень хорошо. В обсуждение зашел даже <a class=\"mention\" href=\"/users/kompas_3d\">@kompas_3d</a> чем я по-настоящему горжусь. Я решил написать небольшое продолжение.</p><p>Основной проблемой, поднимаемой в комментариях была полная бесполезность построенного мной объекта. Люди искренно пытались помочь, предлагали различные варианты... Но все тщетно. Результатом всех дискуссий стала абсолютная ясность, что пользы от этого чуть меньше чем никакой.</p><p>На этот раз я попробую реабилитироваться и построить что-то более пригодное. Хотя, если честно, здесь тоже большие сомнения. Все, кому я это показывал, сначала долго смотрели в экран, потом долго смотрели на меня, крутили пальцем у виска и отходили на безопасное расстояние...</p><h2>Сейф-пряжка на ремень</h2><p>Однажды я ехал в поезде, полном народу с довольно большой суммой наличных денег. Ночью хотелось поспать, но сердце было не на месте - вдруг с деньгами что-то случится. Результатом этой бессонной ночи и стала эта странная конструкция.</p><figure class=\"full-width \"><img src=\"https://habrastorage.org/r/w1560/getpro/habr/upload_files/0ce/e0a/f49/0cee0af49b4b0fe70727739cc876acac.png\" width=\"1260\" height=\"871\" data-src=\"https://habrastorage.org/getpro/habr/upload_files/0ce/e0a/f49/0cee0af49b4b0fe70727739cc876acac.png\"/><figcaption></figcaption></figure><p>Это металлический объект, напоминающий по форме пряжку. Он сделан путем гнутья из не очень толстой стали. Размеры позволяют запихнуть в него кредитные карты, сложенные купюры, возможно сим-карты, и прочие мелкие, но важные вещи. К данному изделию прилагается плоская крышка. Она вставляется в пазы, попадает в выемки и защелкивается за счет естественной упругости. Когда сквозь проушины в эту конструкцию вдевается ремень, проникнуть внутрь защищаемого объема не представляется никакой возможности (разумеется, если каким-то образом не повредить и не ослабить ремень).</p><figure class=\"full-width \"><img src=\"https://habrastorage.org/r/w1560/getpro/habr/upload_files/c38/121/094/c3812109450b40e7c8967693a7e07caf.png\" width=\"1338\" height=\"865\" data-src=\"https://habrastorage.org/getpro/habr/upload_files/c38/121/094/c3812109450b40e7c8967693a7e07caf.png\"/><figcaption></figcaption></figure><p>Конструкция скруглена по форме тела, кроме того обладает некоторой свободой - может подстраиваться для наилучшего сидения на теле и на ремне. Если предполагается проходить сквозь болота, пустыни, пыльную местность - защищаемые вещи могут быть упакованы в герметичный мешочек. На передней стороне может быть нанесена некоторая гравировка, которая может перенести статус этого изделия в разряд мужских сувениров. Возможно эта вещь может понравиться различным неформалам, байкерам, музыкантам, путешественникам.</p><figure class=\"full-width \"><img src=\"https://habrastorage.org/r/w1560/getpro/habr/upload_files/d73/3fd/a07/d733fda07c54a2fee52640e384d79f94.png\" width=\"1409\" height=\"784\" data-src=\"https://habrastorage.org/getpro/habr/upload_files/d73/3fd/a07/d733fda07c54a2fee52640e384d79f94.png\"/><figcaption></figcaption></figure><p>Вот наверное и все что можно сказать по функционалу объекта, и теперь можно перейти непосредственно к геометрическим построениям.</p><h2>Преимущества параметрического построения</h2><p>Если объект из предыдущей статьи я вообще не представлял, как можно построить без программирования (с учетом предполагаемой анимации), то данный объект вполне мог быть построен традиционными конструкторскими инструментами. Но я, конечно, все-равно выбрал параметрическое построение в OpenScad.</p><ul><li><p>В основном, конечно, потому что мне это нравится. Как вы уже поняли я от всего этого тащусь.</p></li><li><p>Мне еще не до конца была ясна форма и размеры - ремни бывают разной ширины, оптимальная толщина должна с одной стороны обеспечивать нужный защищаемый объем, с другой стороны изделие не должно слишком выделятся и мешать, ну и хотелось вообще подобрать благоприятные глазу форму и пропорции.</p></li><li><p>Стало очевидно, что чертить придется две формы - объект в разогнутом виде, чтобы сделать развертку и изготовить прототип, и в полностью согнутом, чтобы проверить замыкание размеров.</p></li><li><p>Вследствие этого возникла идея - если ввести параметр согнутость от 0 до 1, то можно практически бесплатно получить и промежуточные состояния объекта и анимацию</p></li></ul><p>Дальше я примерно опишу логику построений, и в русле общего названия статей буду называть это трюками, хотя конечно это больше обычные решения, принимаемые при генерации различных геометрических форм.</p><h2>Трюк 1. Базовая трапеция</h2><p>Примерно оценив геометрию, я понял, что всю конструкцию можно представить в виде сочетания трапеций, поэтому практически сразу написал код генерирующий трапецию с необходимыми параметрами. Все остальное, что теперь придется делать - строить эти трапеции и нужным образом соединять. Этот шаг привел к некоторому эффекту, о котором я в последствии расскажу.</p><figure class=\"full-width \"><img src=\"https://habrastorage.org/r/w1560/getpro/habr/upload_files/19e/79b/68e/19e79b68ecd396e9c11628199a3ea636.png\" width=\"536\" height=\"295\" data-src=\"https://habrastorage.org/getpro/habr/upload_files/19e/79b/68e/19e79b68ecd396e9c11628199a3ea636.png\"/><figcaption></figcaption></figure><p>Если отойти немного в философию программирования - когда вы выделяете некоторый объект, как прародитель всех остальных объектов, будьте готовы к различным сюрпризам - как к приятным, так и не очень.</p><h2>Трюк 2. Симметрия</h2><p>Еще одним очевидным свойством данного объекта является симметрия, как горизонтальная, так и вертикальная. Поэтому мы смело можем строить только четверть объекта, а все остальное получить отражением. Этот вид мухлежа широко распространен в мире САПР.</p><figure class=\"full-width \"><img src=\"https://habrastorage.org/r/w1560/getpro/habr/upload_files/6a5/c0f/4f4/6a5c0f4f40c85642fba35a7205b13919.png\" width=\"772\" height=\"484\" data-src=\"https://habrastorage.org/getpro/habr/upload_files/6a5/c0f/4f4/6a5c0f4f40c85642fba35a7205b13919.png\"/><figcaption></figcaption></figure><p>Если бы портной делал только четверть костюма и пытался его продать как целый - его бы конечно посадили в тюрьму на длительный срок. А у компьютерных проектировщиков это проходит на ура.</p><h2>Трюк 3. Обратная логика построений</h2><p>Это решение неочевидно и идет в разрез с интуицией. Логично начинать строить с центральных элементов и заканчивать краевыми. Но когда я так стал делать, пытаясь учесть сгибы - оказалось, что это все порождает очень большой объем кода - и чем дальше отходишь от центральной базы - тем хуже.</p><figure class=\"full-width \"><img src=\"https://habrastorage.org/r/w1560/getpro/habr/upload_files/aba/332/204/aba3322043244b0559dbdf866942c791.png\" width=\"1043\" height=\"624\" data-src=\"https://habrastorage.org/getpro/habr/upload_files/aba/332/204/aba3322043244b0559dbdf866942c791.png\"/><figcaption></figcaption></figure><blockquote><p><strong>Анекдот:</strong> работника попросили нанести краской разметку на проезжую часть. За первый день он разметил 500 метров дороги, на второй день - 100 метров, на третий - всего 10. Когда начальник спросил почему падает выработка он ответил: Ну так я все дальше и дальше от банки с краской ухожу.*</p></blockquote><p>Когда, поступаешь наоборот, строишь снаружи к центру - вычисления становятся более естественными. Банка с краской становится к тебе ближе.</p><h2>Трюк, которого не было</h2><p>Я уже завершил построения, полюбовался анимацией, поиграл различными размерами. Настала пора сделать развертку. Мне не понравилось, что на развертке некоторые линии не прорисовались. Причина этого понятна - все эти синусы, косинусы, повороты и прочие округления приводят к микронеточностям. На форму это абсолютно не влияет, но когда геометрическому ядру надо принять решение - прорисовывать линию между объектами или нет, эти неточности уже начинают сказываться. Я понял, что OpenSCADу нужно немного помочь и слегка развести края объектов на некую ничтожную величину. Без всякой задней мысли я обозначил эту микро величину как параметр. Хищно оглядел код, думая, куда бы внести нужные инъекции. Мой взгляд вдруг упал на код базовых трапеций. Всего несколько точных вставок - и цель была достигнута - все нужные прямые прорисовались. Правда прорисовались и не совсем нужные, но кашу маслом не испортишь.</p><figure class=\"full-width \"><img src=\"https://habrastorage.org/r/w1560/getpro/habr/upload_files/36c/b90/f2d/36cb90f2d1df3b656bc7e4a4e39e7d81.png\" width=\"1029\" height=\"683\" data-src=\"https://habrastorage.org/getpro/habr/upload_files/36c/b90/f2d/36cb90f2d1df3b656bc7e4a4e39e7d81.png\"/><figcaption></figcaption></figure><p>Но вот какое дело - в модели появился новый параметр. Хоть он носит и технический характер, но параметром он быть не перестает. А значит им можно побаловаться. Я начал присваивать ему уже не микро, а вполне макро значения.</p><figure class=\"full-width \"><img src=\"https://habrastorage.org/r/w1560/getpro/habr/upload_files/967/798/c1f/967798c1fabe350ae350d0afed93433f.png\" width=\"1082\" height=\"676\" data-src=\"https://habrastorage.org/getpro/habr/upload_files/967/798/c1f/967798c1fabe350ae350d0afed93433f.png\"/><figcaption></figcaption></figure><p>На моих глазах моя пряжка начала квазисимметрично и эквидистантно растворятся в воздухе. Эффект был очень красивый, и конечно при желании его можно анимировать. Вот уж точно не знаешь, где найдешь, где потеряешь.</p><p>Надеюсь мне снова удалось вас немного развлечь. Код проекта доступен на GitHub</p><ul><li><p><a href=\"https://headfire.github.io/p3/projects/safe/safe.scad\" rel=\"noopener noreferrer nofollow\">Параметрическая модель (SCAD)</a></p></li></ul><h2>Некоторые мысли в заключение</h2><p>Мне нравится программировать, особенно когда это связано с геометрическими построениями в объеме. При взаимодействии трехмерной геометрии и программирования рождается некоторая своя красота и особое пространство смыслов. И я желаю всем конструкторам быть ближе к программированию, так как это может значительно облегчить их жизнь. Но как было сказано в комментариях к предыдущей статье - требовать от конструкторов знания программирования нелепо и антипродуктивно - у них и своих конструкторских проблем выше крыши, незачем им добавлять еще и программистские, с которыми даже программисты еще не совсем научились справляться. Разрешить это противоречие очень трудно. У меня есть некоторые мысли и я обязательно хочу об этом написать.</p><p>Эту же статью я хочу закончить на несколько другой ноте: <strong>программистам тоже есть чему поучится у конструкторов</strong>. Если бы меня спросили какой важный принцип нужно перенести из конструирования в программирование - я бы сказал открытость, понятность и законченность конструкции. </p><p>Конструирование - это игра в открытую. Все что хотел сказать конструктор - присутствует на чертеже. У чертежа нет скрытых слоев, тайных закладок, то работающих, то не работающих кэшей. Чертеж нельзя скомпилировать в какую-то непонятную ерунду, которая вроде работает, но как - ни за что не понять. На чертеж нельзя сделать DDOS-атаку. Конечно, в конструкциях есть много смыслов и хитростей - но это все присутствует в максимально явном виде. Кстати, этот принцип перенял язык Питон - первым делом в нем провозглашено - явное лучше неявного - и мы видим, что Питон сейчас один из самых успешных языков.</p><figure class=\"full-width \"><img src=\"https://habrastorage.org/r/w1560/getpro/habr/upload_files/ad7/1d6/7ca/ad71d67cae9f78c832989197ed9d31e5.png\" width=\"668\" height=\"401\" data-src=\"https://habrastorage.org/getpro/habr/upload_files/ad7/1d6/7ca/ad71d67cae9f78c832989197ed9d31e5.png\"/><figcaption></figcaption></figure><p>Я уже говорил, что мой отец - авиационный инженер. Несмотря на возраст, он старается идти в ногу со временем. На его столе - вполне современный компьютер, которым он вполне хорошо пользуется. Но иногда он мне задает вопросы, на которые я не могу ответить, а только краснею. Почему в каждой новой версии Windows все меняется и ничего не найти на прежних местах. Почему файлы в папках отображаются по-разному и этим совершенно невозможно управлять. Почему в папке \"Мои документы\" документы лучше не хранить. Почему, чтобы отправить письмо, нужно посмотреть тонну рекламы. Почему при поиске ответа на достаточно определенный вопрос Интернет выдает 300 000 сайтов с одинаковой информацией, которая одинаково бесполезна. Почему в Скайпе нет нормального списка контактов и отовсюду лезут эмодзи и странно работают статусы. И масса других вопросов, включая стандартные - почему все тормозит и глючит. Если вы читали книгу \"Психбольница в руках у пациентов\", то вам станет примерно понятно содержание наших разговоров.</p><p>Хотя прямых ответов у меня нет, но у меня есть некоторые соображения на этот счет.</p><p>Какое-то время я работал на заводе. И однажды спросил у отца, почему в авиационном двигателе некоторые детали делают на головном предприятии, а некоторые изготавливают в филиалах. По какому принципу делается разделение? Наверное некоторые детали особо ответственные, а некоторые не очень. Он мне ответил без пафоса, как-то буднично, без стремления донести какую-то сверх истину. Но эти слова сильно врезались мне в память. Он сказал: \"Понимаешь, Миша, в авиационном двигателе неответственных деталей не бывает.\"</p><p>Думаю, когда ИТ-индустрия будет также относится к тому, что она делает - все встанет на свои места.</p><p></p></div>",
        "clean_body": "Привет, Хабр! Моя прошлая статья была встречена сообществом очень хорошо. В обсуждение зашел даже @kompas_3d чем я по-настоящему горжусь. Я решил написать небольшое продолжение.Основной проблемой, поднимаемой в комментариях была полная бесполезность построенного мной объекта. Люди искренно пытались помочь, предлагали различные варианты... Но все тщетно. Результатом всех дискуссий стала абсолютная ясность, что пользы от этого чуть меньше чем никакой.На этот раз я попробую реабилитироваться и построить что-то более пригодное. Хотя, если честно, здесь тоже большие сомнения. Все, кому я это показывал, сначала долго смотрели в экран, потом долго смотрели на меня, крутили пальцем у виска и отходили на безопасное расстояние...Сейф-пряжка на ременьОднажды я ехал в поезде, полном народу с довольно большой суммой наличных денег. Ночью хотелось поспать, но сердце было не на месте - вдруг с деньгами что-то случится. Результатом этой бессонной ночи и стала эта странная конструкция.Это металлический объект, напоминающий по форме пряжку. Он сделан путем гнутья из не очень толстой стали. Размеры позволяют запихнуть в него кредитные карты, сложенные купюры, возможно сим-карты, и прочие мелкие, но важные вещи. К данному изделию прилагается плоская крышка. Она вставляется в пазы, попадает в выемки и защелкивается за счет естественной упругости. Когда сквозь проушины в эту конструкцию вдевается ремень, проникнуть внутрь защищаемого объема не представляется никакой возможности (разумеется, если каким-то образом не повредить и не ослабить ремень).Конструкция скруглена по форме тела, кроме того обладает некоторой свободой - может подстраиваться для наилучшего сидения на теле и на ремне. Если предполагается проходить сквозь болота, пустыни, пыльную местность - защищаемые вещи могут быть упакованы в герметичный мешочек. На передней стороне может быть нанесена некоторая гравировка, которая может перенести статус этого изделия в разряд мужских сувениров. Возможно эта вещь может понравиться различным неформалам, байкерам, музыкантам, путешественникам.Вот наверное и все что можно сказать по функционалу объекта, и теперь можно перейти непосредственно к геометрическим построениям.Преимущества параметрического построенияЕсли объект из предыдущей статьи я вообще не представлял, как можно построить без программирования (с учетом предполагаемой анимации), то данный объект вполне мог быть построен традиционными конструкторскими инструментами. Но я, конечно, все-равно выбрал параметрическое построение в OpenScad.В основном, конечно, потому что мне это нравится. Как вы уже поняли я от всего этого тащусь.Мне еще не до конца была ясна форма и размеры - ремни бывают разной ширины, оптимальная толщина должна с одной стороны обеспечивать нужный защищаемый объем, с другой стороны изделие не должно слишком выделятся и мешать, ну и хотелось вообще подобрать благоприятные глазу форму и пропорции.Стало очевидно, что чертить придется две формы - объект в разогнутом виде, чтобы сделать развертку и изготовить прототип, и в полностью согнутом, чтобы проверить замыкание размеров.Вследствие этого возникла идея - если ввести параметр согнутость от 0 до 1, то можно практически бесплатно получить и промежуточные состояния объекта и анимациюДальше я примерно опишу логику построений, и в русле общего названия статей буду называть это трюками, хотя конечно это больше обычные решения, принимаемые при генерации различных геометрических форм.Трюк 1. Базовая трапецияПримерно оценив геометрию, я понял, что всю конструкцию можно представить в виде сочетания трапеций, поэтому практически сразу написал код генерирующий трапецию с необходимыми параметрами. Все остальное, что теперь придется делать - строить эти трапеции и нужным образом соединять. Этот шаг привел к некоторому эффекту, о котором я в последствии расскажу.Если отойти немного в философию программирования - когда вы выделяете некоторый объект, как прародитель всех остальных объектов, будьте готовы к различным сюрпризам - как к приятным, так и не очень.Трюк 2. СимметрияЕще одним очевидным свойством данного объекта является симметрия, как горизонтальная, так и вертикальная. Поэтому мы смело можем строить только четверть объекта, а все остальное получить отражением. Этот вид мухлежа широко распространен в мире САПР.Если бы портной делал только четверть костюма и пытался его продать как целый - его бы конечно посадили в тюрьму на длительный срок. А у компьютерных проектировщиков это проходит на ура.Трюк 3. Обратная логика построенийЭто решение неочевидно и идет в разрез с интуицией. Логично начинать строить с центральных элементов и заканчивать краевыми. Но когда я так стал делать, пытаясь учесть сгибы - оказалось, что это все порождает очень большой объем кода - и чем дальше отходишь от центральной базы - тем хуже.Анекдот: работника попросили нанести краской разметку на проезжую часть. За первый день он разметил 500 метров дороги, на второй день - 100 метров, на третий - всего 10. Когда начальник спросил почему падает выработка он ответил: Ну так я все дальше и дальше от банки с краской ухожу.*Когда, поступаешь наоборот, строишь снаружи к центру - вычисления становятся более естественными. Банка с краской становится к тебе ближе.Трюк, которого не былоЯ уже завершил построения, полюбовался анимацией, поиграл различными размерами. Настала пора сделать развертку. Мне не понравилось, что на развертке некоторые линии не прорисовались. Причина этого понятна - все эти синусы, косинусы, повороты и прочие округления приводят к микронеточностям. На форму это абсолютно не влияет, но когда геометрическому ядру надо принять решение - прорисовывать линию между объектами или нет, эти неточности уже начинают сказываться. Я понял, что OpenSCADу нужно немного помочь и слегка развести края объектов на некую ничтожную величину. Без всякой задней мысли я обозначил эту микро величину как параметр. Хищно оглядел код, думая, куда бы внести нужные инъекции. Мой взгляд вдруг упал на код базовых трапеций. Всего несколько точных вставок - и цель была достигнута - все нужные прямые прорисовались. Правда прорисовались и не совсем нужные, но кашу маслом не испортишь.Но вот какое дело - в модели появился новый параметр. Хоть он носит и технический характер, но параметром он быть не перестает. А значит им можно побаловаться. Я начал присваивать ему уже не микро, а вполне макро значения.На моих глазах моя пряжка начала квазисимметрично и эквидистантно растворятся в воздухе. Эффект был очень красивый, и конечно при желании его можно анимировать. Вот уж точно не знаешь, где найдешь, где потеряешь.Надеюсь мне снова удалось вас немного развлечь. Код проекта доступен на GitHubПараметрическая модель (SCAD)Некоторые мысли в заключениеМне нравится программировать, особенно когда это связано с геометрическими построениями в объеме. При взаимодействии трехмерной геометрии и программирования рождается некоторая своя красота и особое пространство смыслов. И я желаю всем конструкторам быть ближе к программированию, так как это может значительно облегчить их жизнь. Но как было сказано в комментариях к предыдущей статье - требовать от конструкторов знания программирования нелепо и антипродуктивно - у них и своих конструкторских проблем выше крыши, незачем им добавлять еще и программистские, с которыми даже программисты еще не совсем научились справляться. Разрешить это противоречие очень трудно. У меня есть некоторые мысли и я обязательно хочу об этом написать.Эту же статью я хочу закончить на несколько другой ноте: программистам тоже есть чему поучится у конструкторов. Если бы меня спросили какой важный принцип нужно перенести из конструирования в программирование - я бы сказал открытость, понятность и законченность конструкции. Конструирование - это игра в открытую. Все что хотел сказать конструктор - присутствует на чертеже. У чертежа нет скрытых слоев, тайных закладок, то работающих, то не работающих кэшей. Чертеж нельзя скомпилировать в какую-то непонятную ерунду, которая вроде работает, но как - ни за что не понять. На чертеж нельзя сделать DDOS-атаку. Конечно, в конструкциях есть много смыслов и хитростей - но это все присутствует в максимально явном виде. Кстати, этот принцип перенял язык Питон - первым делом в нем провозглашено - явное лучше неявного - и мы видим, что Питон сейчас один из самых успешных языков.Я уже говорил, что мой отец - авиационный инженер. Несмотря на возраст, он старается идти в ногу со временем. На его столе - вполне современный компьютер, которым он вполне хорошо пользуется. Но иногда он мне задает вопросы, на которые я не могу ответить, а только краснею. Почему в каждой новой версии Windows все меняется и ничего не найти на прежних местах. Почему файлы в папках отображаются по-разному и этим совершенно невозможно управлять. Почему в папке \"Мои документы\" документы лучше не хранить. Почему, чтобы отправить письмо, нужно посмотреть тонну рекламы. Почему при поиске ответа на достаточно определенный вопрос Интернет выдает 300 000 сайтов с одинаковой информацией, которая одинаково бесполезна. Почему в Скайпе нет нормального списка контактов и отовсюду лезут эмодзи и странно работают статусы. И масса других вопросов, включая стандартные - почему все тормозит и глючит. Если вы читали книгу \"Психбольница в руках у пациентов\", то вам станет примерно понятно содержание наших разговоров.Хотя прямых ответов у меня нет, но у меня есть некоторые соображения на этот счет.Какое-то время я работал на заводе. И однажды спросил у отца, почему в авиационном двигателе некоторые детали делают на головном предприятии, а некоторые изготавливают в филиалах. По какому принципу делается разделение? Наверное некоторые детали особо ответственные, а некоторые не очень. Он мне ответил без пафоса, как-то буднично, без стремления донести какую-то сверх истину. Но эти слова сильно врезались мне в память. Он сказал: \"Понимаешь, Миша, в авиационном двигателе неответственных деталей не бывает.\"Думаю, когда ИТ-индустрия будет также относится к тому, что она делает - все встанет на свои места.",
        "meta_tags": [
            "Сейф-пряжка",
            "Сувенир",
            "Лазерная резка"
        ]
    },
    {
        "publish_datetime": 1669971792.0,
        "author": "Ксения Мосеенкова",
        "title": "Как провести эффективное тестирование мобильных приложений? Стратегия пятиуровневой пирамиды тестов",
        "title_image_url": "https://habrastorage.org/getpro/habr/upload_files/235/2cd/250/2352cd25086d85a4f27fe7b40f8ae83b.png",
        "raw_body": "<div xmlns=\"http://www.w3.org/1999/xhtml\"><p>Никто не спорит с тем фактом, что в процессе разработки необходимо проводить качественное тестирование, которое обеспечит достаточное тестовое покрытие. Но какова область и цель тестов? В какой среде их нужно проводить и как быть с зависимостями?</p><p>В статье мы постарались ответить на эти вопросы, рассматривая стратегию тестирования мобильных приложений.</p><h4>Работа с контекстом и зависимостями</h4><p>Первым делом необходимо четко определить область и среду для ваших тестов. Представьте, что вы вручную тестируете приложение интернет-магазина. Вы собираетесь протестировать процесс заказа, включая этап оплаты, который предоставляется сторонней компанией? Или вы хотите сосредоточиться только на коде, написанном вашей командой, не затрагивая платежный сервис?</p><p>Здесь нет единственного правильного ответа. Но эти два теста нельзя проводить одновременно, и они точно потребуют разных затрат с точки зрения реализации и удобства сопровождения.</p><p>Взяв за основу <a href=\"https://martinfowler.com/articles/practical-test-pyramid.html\"><u>тестовую пирамид</u></a>у Мартина Фаулера, мы создали свой вариант пирамиды, состоящей из 5 уровней:</p><figure class=\"full-width \"><img src=\"https://habrastorage.org/r/w1560/getpro/habr/upload_files/e89/f3c/21e/e89f3c21ea9ac88cffac884f7fa8b0f0.png\" width=\"556\" height=\"540\" data-src=\"https://habrastorage.org/getpro/habr/upload_files/e89/f3c/21e/e89f3c21ea9ac88cffac884f7fa8b0f0.png\"/><figcaption></figcaption></figure><p>Для каждого уровня мы определили:</p><ul><li><p>Цели тестирования: какие компоненты тестируются и в чем состоит цель тестирования?</p></li><li><p>Область тестирования: будет увеличиваться на каждом этапе пирамиды, что делает тесты более зависимыми от локальных и внешних зависимостей.</p></li><li><p>Типы тестов: техника реализации тестов.</p></li></ul><p>На каждом уровне тестирования свои сложности. В этом разделе рассмотрим подробнее каждый уровень пирамиды, начиная с нижнего.</p><h3>Юнит-тесты (Unit Tests)</h3><p>Юнит-тесты проверяют функциональность самых маленьких фрагментов кода. Область применения — тестируемый класс и сама функция.</p><p>Здесь необходимо проверить большинство специфических сценариев и пограничных случаев, которые не обязательно будут проверены на более верхних уровнях.</p><p>Внешние зависимости приложения, такие как REST-клиент, должны быть заменены моками.</p><p>Локальные зависимости класса, такие как репозиторий, также должны быть заменены моками.</p><p>Все современные языки предоставляют фреймворки для юнит-тестирования, такие как <a href=\"https://developer.apple.com/documentation/xctest\"><u>XCTest</u></a> для iOS и <a href=\"https://junit.org/junit5/\"><u>JUnit </u></a>для Android.</p><p>Независимо от того, используется ли методология <a href=\"https://blog.cleancoder.com/uncle-bob/2014/12/17/TheCyclesOfTDD.html\"><u>TDD</u></a> или нет, модульные тесты должны быть частью критериев готовности и быть написаны во время реализации фичи.</p><h3>Интеграционные тесты (Integration Tests)</h3><p>С помощью интеграционных тестов проверяют взаимодействие и интеграцию небольших модулей и интерфейсов в рамках одного компонента.</p><p>Внешние зависимости приложения, такие как REST-клиент, должны быть сымитированы.</p><p>Локальные зависимости внутри тестируемого компонента могут быть использованы по-настоящему, в зависимости от цели теста. Локальные же зависимости <em>вне </em>компонента должны быть заменены моками.</p><p>Те же методы, фреймворки и правила повторно используются в юнит-тестах.</p><h3>Тесты приложения (Application Tests)</h3><p>Такие тесты фокусируются на приложении целиком, когда можно пройтись по всем уровням тестируемого приложения. Проведение этих тестов гарантирует, что <em>без влияния</em> внешних неблагоприятных воздействий приложение работает так, как ожидается. Это дает уверенность в том, что по крайней мере работает логика внутри приложения.</p><p>Внешние зависимости продолжают заменяться моками. Это означает, что в полностью искусственной среде приложение должно работать.</p><p>Из-за высокой стоимости внедрения и поддержания таких тестов (обратите внимание на flaky-тесты), тест-кейсы нужно определить тщательно. С этого уровня мы рекомендуем тестировать только те сценарии, которые невозможно проверить с помощью юнит- или интеграционных тестов.</p><p>Внедряются чаще всего UI-тесты (<a href=\"https://developer.apple.com/documentation/xctest/user_interface_tests\"><u>XCUITest</u></a>, <a href=\"https://developer.android.com/training/testing/espresso\"><u>Espresso</u></a> or <a href=\"https://appium.io/\"><u>appium</u></a> для кроссплатформенности и стратегии черного ящика) или <a href=\"https://blog.bitrise.io/post/snapshot-testing-in-ios-testing-the-ui-and-beyond\"><u>Snapshot</u></a>-тесты.</p><p>Начиная с этого момента и до самых верхних уровней пирамиды, внедрение новых тест-кейсов требует распределения задач. Внедрение новых тест-кейсов должно рассматриваться как отдельная функция.</p><h3>Системные тесты (System Tests)</h3><p>Мы почти на вершине нашей пирамиды!</p><p>С этого момента можно использовать некоторые внешние зависимости, такие как бэкенд приложения.</p><figure class=\"\"><img src=\"https://habrastorage.org/r/w1560/getpro/habr/upload_files/9d2/b7c/529/9d2b7c5296786d7bc6cdb3cbc846f46a.png\" alt=\"https://www.monkeyuser.com/2018/happy-flow/\" title=\"https://www.monkeyuser.com/2018/happy-flow/\" width=\"500\" height=\"544\" data-src=\"https://habrastorage.org/getpro/habr/upload_files/9d2/b7c/529/9d2b7c5296786d7bc6cdb3cbc846f46a.png\"/><figcaption>https://www.monkeyuser.com/2018/happy-flow/</figcaption></figure><p>Любые подсистемы, которые не являются непосредственной частью конфигурации, например, внешний платежный сервис, нужно заменить моками.</p><p>Вам придется решить, запускать ли тесты в выделенной тестовой среде или непосредственно в промежуточной среде. Оба варианта имеют свои плюсы и минусы, сейчас мы их обсуждать не будем.</p><p>Вероятно, наиболее используемыми техниками для реализации тестирования на этом уровне являются UI-тесты и Unit-тесты. Но, учитывая вышеприведенный вопрос о среде, их будет сложнее настроить и поддерживать, чем тесты более низких уровней.</p><p>Третий вариант — это <a href=\"https://pactflow.io/what-is-consumer-driven-contract-testing/\"><u>Consumer Driver Contract Testing</u></a> (CDCT). Это отличная техника, с помощью которой можно быстро обнаружить любые регрессии между фронтендом и серверной частью. Более подробную информацию можно найти в <a href=\"https://docs.pact.io/\"><u>документации pact.io</u></a>.</p><h3>Тестирование системной интеграции (System Integration Tests, SIT)</h3><p>Наконец, вот и все! Теперь можно полностью использовать любые зависимости нашего приложения с помощью тестов системной интеграции.</p><p>Подождите, не расслабляйтесь пока... <em>С большой силой приходит большая ответственность</em>. Вам предстоит узнать цену зависимости от внешних сервисов для тестов. Некоторые из них предоставят вам доступ к выделенной тестовой среде. Если у стороннего сервиса есть доступ только к промежуточной среде или, что еще хуже, только к продуктивной среде, выполнение тестов системной интеграции может стать невозможным.</p><p>Несмотря на свою сложность, тестами системной интеграции не стоит пренебрегать. Особенно, если ваш первоначальный план состоял в том, чтобы сократить количество ручных тестов.</p><p>Наиболее предпочтительными методами является тестирование пользовательского интерфейса и ориентированные на пользователя контрактные тесты (CDC-тесты).</p><p>Главное правило — четко определить, какие сценарии вы хотите протестировать, в каком контексте и в какой среде.</p><figure class=\"full-width \"><img src=\"https://habrastorage.org/r/w1560/getpro/habr/upload_files/208/c1c/56b/208c1c56b9f7a425e9c2a0dc51ef4e07.png\" alt=\"Покрытие областей\" title=\"Покрытие областей\" width=\"721\" height=\"377\" data-src=\"https://habrastorage.org/getpro/habr/upload_files/208/c1c/56b/208c1c56b9f7a425e9c2a0dc51ef4e07.png\"/><figcaption>Покрытие областей</figcaption></figure><h3>Что принесла нам эта стратегия?</h3><p>В отделе разработки мобильных приложений Федерального управления информационных технологий, систем и телекоммуникаций (FOITT) мы решили сосредоточиться на задачах в пределах нашей зоны контроля: на нижних уровнях, вплоть до тестирования приложения.</p><p>Мы стараемся поддерживать высокий уровень покрытия кода и писать релевантные юнит- и интеграционные тесты — это ответственность команды разработчиков. Эти тесты выполняются в нашем CI-пайплайне при каждом пулл-реквесте.</p><p>Фреймворки остаются как можно ближе к технологиям разработки, используемым разработчиками, поскольку это не должно служить ограничением для написания тестов.</p><p>Решения касательно сценариев тестирования приложений принимаются всей командой, так как они оказывают большее влияние на нашу работу в целом. Для их выполнения требуется много времени. Поэтому они запускаются в рамках стратегии ночной сборки на облачной платформе, состоящей из реальных устройств. Это дает нам больше уверенности в том, что за предыдущий день не было изменений, приводящих к регрессиям. Также бывало так, что большинство сбоев, о которых QA сообщали во время ручного тестирования, можно было обнаружить в искусственной среде еще на ранней стадии.</p><p>Для системных тестов и тестов системной интеграции мы хотели бы в будущем использовать <a href=\"https://pact.io/\"><u>pact.io</u></a>, поскольку мы его уже применяем в качестве веб-инструментария. Мы также хотели бы избежать необходимости содержать специальную тестовую среду и использовать промежуточную среду напрямую, со всеми вытекающими ограничениями.</p><figure class=\"\"><img src=\"https://habrastorage.org/r/w1560/getpro/habr/upload_files/8cb/f84/bac/8cbf84baced8ceb0ee2bfad2d7ceb178.png\" alt=\"Уровни тестирования: гарантия функциональности против затрат\" title=\"Уровни тестирования: гарантия функциональности против затрат\" width=\"416\" height=\"363\" data-src=\"https://habrastorage.org/getpro/habr/upload_files/8cb/f84/bac/8cbf84baced8ceb0ee2bfad2d7ceb178.png\"/><figcaption>Уровни тестирования: гарантия функциональности против затрат</figcaption></figure><p>Мы продолжаем проводить большое количество ручных тестов и хотели бы их сократить, но заменять все ручные тесты автоматизированными мы не планируем. Предпочитаем увеличить уровень покрытия и количество тест-кейсов на нижних уровнях. Оставляем тесты системной интеграции, системные тесты и даже тесты приложений для типичных критических сценариев нашего приложения.</p><p>Рекомендуем ознакомиться с <a href=\"https://github.com/MobileNativeFoundation/discussions/discussions/6#discussioncomment-1654557\"><u>этим тредом</u></a> на Github, где собрано множество кейсов крупнейших технологических компаний.</p><hr/><p>Приглашаем всех желающих на открытое занятие «Test IT комбайн для тестировщика». На занятии вы познакомитесь с перспективной отечественной системой для ведения тестовой документации и научитесь создавать кейсы, которые легко поддерживать. Регистрация открыта <a href=\"https://otus.pw/S1io/\">по ссылке. </a></p><p></p></div>",
        "clean_body": "Никто не спорит с тем фактом, что в процессе разработки необходимо проводить качественное тестирование, которое обеспечит достаточное тестовое покрытие. Но какова область и цель тестов? В какой среде их нужно проводить и как быть с зависимостями?В статье мы постарались ответить на эти вопросы, рассматривая стратегию тестирования мобильных приложений.Работа с контекстом и зависимостямиПервым делом необходимо четко определить область и среду для ваших тестов. Представьте, что вы вручную тестируете приложение интернет-магазина. Вы собираетесь протестировать процесс заказа, включая этап оплаты, который предоставляется сторонней компанией? Или вы хотите сосредоточиться только на коде, написанном вашей командой, не затрагивая платежный сервис?Здесь нет единственного правильного ответа. Но эти два теста нельзя проводить одновременно, и они точно потребуют разных затрат с точки зрения реализации и удобства сопровождения.Взяв за основу тестовую пирамиду Мартина Фаулера, мы создали свой вариант пирамиды, состоящей из 5 уровней:Для каждого уровня мы определили:Цели тестирования: какие компоненты тестируются и в чем состоит цель тестирования?Область тестирования: будет увеличиваться на каждом этапе пирамиды, что делает тесты более зависимыми от локальных и внешних зависимостей.Типы тестов: техника реализации тестов.На каждом уровне тестирования свои сложности. В этом разделе рассмотрим подробнее каждый уровень пирамиды, начиная с нижнего.Юнит-тесты (Unit Tests)Юнит-тесты проверяют функциональность самых маленьких фрагментов кода. Область применения — тестируемый класс и сама функция.Здесь необходимо проверить большинство специфических сценариев и пограничных случаев, которые не обязательно будут проверены на более верхних уровнях.Внешние зависимости приложения, такие как REST-клиент, должны быть заменены моками.Локальные зависимости класса, такие как репозиторий, также должны быть заменены моками.Все современные языки предоставляют фреймворки для юнит-тестирования, такие как XCTest для iOS и JUnit для Android.Независимо от того, используется ли методология TDD или нет, модульные тесты должны быть частью критериев готовности и быть написаны во время реализации фичи.Интеграционные тесты (Integration Tests)С помощью интеграционных тестов проверяют взаимодействие и интеграцию небольших модулей и интерфейсов в рамках одного компонента.Внешние зависимости приложения, такие как REST-клиент, должны быть сымитированы.Локальные зависимости внутри тестируемого компонента могут быть использованы по-настоящему, в зависимости от цели теста. Локальные же зависимости вне компонента должны быть заменены моками.Те же методы, фреймворки и правила повторно используются в юнит-тестах.Тесты приложения (Application Tests)Такие тесты фокусируются на приложении целиком, когда можно пройтись по всем уровням тестируемого приложения. Проведение этих тестов гарантирует, что без влияния внешних неблагоприятных воздействий приложение работает так, как ожидается. Это дает уверенность в том, что по крайней мере работает логика внутри приложения.Внешние зависимости продолжают заменяться моками. Это означает, что в полностью искусственной среде приложение должно работать.Из-за высокой стоимости внедрения и поддержания таких тестов (обратите внимание на flaky-тесты), тест-кейсы нужно определить тщательно. С этого уровня мы рекомендуем тестировать только те сценарии, которые невозможно проверить с помощью юнит- или интеграционных тестов.Внедряются чаще всего UI-тесты (XCUITest, Espresso or appium для кроссплатформенности и стратегии черного ящика) или Snapshot-тесты.Начиная с этого момента и до самых верхних уровней пирамиды, внедрение новых тест-кейсов требует распределения задач. Внедрение новых тест-кейсов должно рассматриваться как отдельная функция.Системные тесты (System Tests)Мы почти на вершине нашей пирамиды!С этого момента можно использовать некоторые внешние зависимости, такие как бэкенд приложения.https://www.monkeyuser.com/2018/happy-flow/Любые подсистемы, которые не являются непосредственной частью конфигурации, например, внешний платежный сервис, нужно заменить моками.Вам придется решить, запускать ли тесты в выделенной тестовой среде или непосредственно в промежуточной среде. Оба варианта имеют свои плюсы и минусы, сейчас мы их обсуждать не будем.Вероятно, наиболее используемыми техниками для реализации тестирования на этом уровне являются UI-тесты и Unit-тесты. Но, учитывая вышеприведенный вопрос о среде, их будет сложнее настроить и поддерживать, чем тесты более низких уровней.Третий вариант — это Consumer Driver Contract Testing (CDCT). Это отличная техника, с помощью которой можно быстро обнаружить любые регрессии между фронтендом и серверной частью. Более подробную информацию можно найти в документации pact.io.Тестирование системной интеграции (System Integration Tests, SIT)Наконец, вот и все! Теперь можно полностью использовать любые зависимости нашего приложения с помощью тестов системной интеграции.Подождите, не расслабляйтесь пока... С большой силой приходит большая ответственность. Вам предстоит узнать цену зависимости от внешних сервисов для тестов. Некоторые из них предоставят вам доступ к выделенной тестовой среде. Если у стороннего сервиса есть доступ только к промежуточной среде или, что еще хуже, только к продуктивной среде, выполнение тестов системной интеграции может стать невозможным.Несмотря на свою сложность, тестами системной интеграции не стоит пренебрегать. Особенно, если ваш первоначальный план состоял в том, чтобы сократить количество ручных тестов.Наиболее предпочтительными методами является тестирование пользовательского интерфейса и ориентированные на пользователя контрактные тесты (CDC-тесты).Главное правило — четко определить, какие сценарии вы хотите протестировать, в каком контексте и в какой среде.Покрытие областейЧто принесла нам эта стратегия?В отделе разработки мобильных приложений Федерального управления информационных технологий, систем и телекоммуникаций (FOITT) мы решили сосредоточиться на задачах в пределах нашей зоны контроля: на нижних уровнях, вплоть до тестирования приложения.Мы стараемся поддерживать высокий уровень покрытия кода и писать релевантные юнит- и интеграционные тесты — это ответственность команды разработчиков. Эти тесты выполняются в нашем CI-пайплайне при каждом пулл-реквесте.Фреймворки остаются как можно ближе к технологиям разработки, используемым разработчиками, поскольку это не должно служить ограничением для написания тестов.Решения касательно сценариев тестирования приложений принимаются всей командой, так как они оказывают большее влияние на нашу работу в целом. Для их выполнения требуется много времени. Поэтому они запускаются в рамках стратегии ночной сборки на облачной платформе, состоящей из реальных устройств. Это дает нам больше уверенности в том, что за предыдущий день не было изменений, приводящих к регрессиям. Также бывало так, что большинство сбоев, о которых QA сообщали во время ручного тестирования, можно было обнаружить в искусственной среде еще на ранней стадии.Для системных тестов и тестов системной интеграции мы хотели бы в будущем использовать pact.io, поскольку мы его уже применяем в качестве веб-инструментария. Мы также хотели бы избежать необходимости содержать специальную тестовую среду и использовать промежуточную среду напрямую, со всеми вытекающими ограничениями.Уровни тестирования: гарантия функциональности против затратМы продолжаем проводить большое количество ручных тестов и хотели бы их сократить, но заменять все ручные тесты автоматизированными мы не планируем. Предпочитаем увеличить уровень покрытия и количество тест-кейсов на нижних уровнях. Оставляем тесты системной интеграции, системные тесты и даже тесты приложений для типичных критических сценариев нашего приложения.Рекомендуем ознакомиться с этим тредом на Github, где собрано множество кейсов крупнейших технологических компаний.Приглашаем всех желающих на открытое занятие «Test IT комбайн для тестировщика». На занятии вы познакомитесь с перспективной отечественной системой для ведения тестовой документации и научитесь создавать кейсы, которые легко поддерживать. Регистрация открыта по ссылке. ",
        "meta_tags": [
            "тестирование",
            "автоматизация тестирования",
            "auto qa",
            "тестовая документация",
            "уровни тестирования"
        ]
    },
    {
        "publish_datetime": 1669975202.0,
        "author": "Дмитрий Брайт",
        "title": "Работа с поверхностными и глубокими копиями в Python",
        "title_image_url": null,
        "raw_body": "<div xmlns=\"http://www.w3.org/1999/xhtml\"><a href=\"https://habr.com/ru/company/ruvds/blog/702486/\"><div style=\"text-align:center;\"><img src=\"https://habrastorage.org/r/w1560/webt/_l/1s/nq/_l1snq2lxtw_novmguqsq0wnvu8.png\" data-src=\"https://habrastorage.org/webt/_l/1s/nq/_l1snq2lxtw_novmguqsq0wnvu8.png\"/></div></a><br/>\r\nВ этой статье объясняется, как делать копии списков Python, массивов NumPy и датафреймов Pandas при помощи операций получения срезов, списочного индексирования (fancy indexing) и логического (boolean indexing). Эти операции очень часто используются при анализе данных и должны рассматриваться всерьёз, поскольку ошибочные предположения могут привести к падению быстродействия или неожиданным результатам.<br/>\r\n<br/>\r\nPython кажется простым, но всякий раз, возвращаясь к его азам, ты находишь новые для освоения вещи. Здесь на ум приходит известное изречение Эйнштейна:<br/>\r\n<br/>\r\n<blockquote>«Чем больше я узнаю, тем больше понимаю, как много я ещё не знаю».</blockquote><a name=\"habracut\"></a><br/>\r\n<h2><font color=\"#3AC1EF\">Вступление</font></h2><br/>\r\nЯ часто задаюсь вопросом, действительно ли я знаю тот или иной предмет в совершенстве. Получив кандидатскую степень и проработав часть жизни исследователем, я могу с уверенностью сказать, что утвердительного ответа на этот вопрос не бывает. Я уже давно работаю с Python и осознаю ценность этого инструмента для анализа данных. С его помощью я создавал множество эффективных решений для реальных задач. И всё же каждый раз, возвращаясь к основам этого языка, я нахожу в нём нечто новое для освоения или вижу иной ракурс для восприятия уже привычных вещей.<br/>\r\n<br/>\r\nЭто осознание зачастую возникает во время чтения вводной части книги, которая намеренно содержит простой материал, подготавливая читателя к основной сути. Приведённая фраза Эйнштейна звучит у меня в сознании, когда в очередной раз после использования интерпретатора Python, я задумываюсь, почему столь простые вещи открываются для меня только сейчас?<br/>\r\n<br/>\r\nИ текущая статья появилась вслед за одним из таких случаев. В ней я хочу объяснить, как списки Python, массивы NumPy и датафреймы Pandas создают представления или полноценные копии данных при получении срезов, а также множественном и логическом индексировании. В этой теме возникает некоторая путаница, поскольку термины «поверхностная копия» и «глубокая копия» не всегда означают одно и то же, а также неясно, когда дополнительная информация вроде метаданных массива NumPy и индексов Pandas копируется полноценно, а когда поверхностно.<br/>\r\n<br/>\r\nЭта статья может не дать всех исчерпывающих ответов, но она обеспечит основу, которая позволит в случае сомнений дополнить инструкции из документации собственными вычислительными экспериментами.<br/>\r\n<br/>\r\nВсе примеры кода были подготовлены с использованием Python v3.8.10, Pandas v1.5.1 и NumPy v1.23.4.<br/>\r\n<br/>\r\n<h2><font color=\"#3AC1EF\">Списки Python</font></h2><br/>\r\nВ этом разделе мы проведём ряд экспериментов, чтобы понять принцип создания копий списков Python. Если вы будете проделывать аналогичные действия, то помните, что Python кэширует небольшие целые числа и строки, чтобы иметь возможность обращаться к уже имеющимся объектам, а не создавать каждый раз новые. Это так называемое интернирование является одной из оптимизаций CPython, которая при написании статьи использовалась в стандартном Python. Для избежания путаницы при поиске адресов объектов рекомендуется использовать разные строки и целые числа.<br/>\r\n<br/>\r\nНекоторые читатели могут подумать, что списки в Python являются простой темой. Как бы не так. Давайте создадим такой список, который будет содержать целое число, другой список и вложенный список. Вдобавок к этому мы создадим вспомогательную функцию для вывода адресов различных элементов списка, которая, в целях сокращения, будет показывать только четыре последние цифры адреса.<br/>\r\n<br/>\r\n<pre><code class=\"python\">def show_address(title, a, offset=0):\n    trim_ad = lambda ad: str(id(ad))[-4:]\n    print(f\"{title.ljust(20, ' ')}: {trim_ad(a)} | {trim_ad(a[offset+0])} |  \"\n          f\"{trim_ad(a[offset+1])} {trim_ad(a[offset+1][0])} | \"\n          f\"{trim_ad(a[offset+2])} {trim_ad(a[offset+2][0])} {trim_ad(a[offset+2][0][0])}\")\n\n# original list\na = ['1', ['2','3'], [['4','5'],['6','7']]]\nshow_address('a', a)</code></pre><br/>\r\nВывод:<br/>\r\n<br/>\r\n<pre><code class=\"bash\">a                   : 4160 | 7728 |  9888 3376 | 3232 0848 2480</code></pre><br/>\r\nОчевидно, что при каждом выполнении адреса будут отличаться. В связи с этим мы сделаем так, чтобы массив <code>a</code> далее не изменялся. Ниже мы попробуем реплицировать этот массив разными способами, а именно с помощью простого присваивания другой переменной и глубокого копирования:<br/>\r\n<br/>\r\n<pre><code class=\"python\">from copy import copy, deepcopy\n\n\nattempts = {'new binding': a,\n            'shallow copy I': a[:],\n            'shallow copy II': list(a),\n            'shallow copy III': a.copy(),\n            'shallow copy IV': copy(a),\n            'deep copy': deepcopy(a)\n            }\nfor title, b in attempts.items():\n    show_address(title, b)</code></pre><br/>\r\nВывод:<br/>\r\n<br/>\r\n<pre><code class=\"bash\">new binding         : 4160 | 7728 |  9888 3376 | 3232 0848 2480\nshallow copy I      : 7072 | 7728 |  9888 3376 | 3232 0848 2480\nshallow copy II     : 9312 | 7728 |  9888 3376 | 3232 0848 2480\nshallow copy III    : 1488 | 7728 |  9888 3376 | 3232 0848 2480\nshallow copy IV     : 8128 | 7728 |  9888 3376 | 3232 0848 2480\ndeep copy           : 0528 | 7728 |  6848 3376 | 0816 2960 2480</code></pre><br/>\r\nПервым делом нужно обратить внимание, что адрес списка (первый численный столбец) изменяется при каждой попытке, за исключением первой операции изменения привязки. Это говорит о том, что в ходе неё была сделана копия. Данный код реализует четыре разных способа создания поверхностной копии, подразумевающей изменение списка, при котором его элементы остаются прежними объектами. Если попробовать изменить немутабельный элемент такой неполной копии списка, исходный список останется нетронутым. При изменении же мутабельного элемента оригинальный список также меняется. Например:<br/>\r\n<br/>\r\n<pre><code class=\"python\">a_demo = ['d1', ['d2', 'd3']]\nprint('a_demo (before)     ->', a_demo)\na_demo_shallow_copy = a_demo[:]\na_demo_shallow_copy[0] = 'D1'\na_demo_shallow_copy[1][0] = 'D2'\nprint('a_demo (after)      ->', a_demo)\nprint('a_demo_shallow_copy ->', a_demo_shallow_copy)</code></pre><br/>\r\nВывод:<br/>\r\n<br/>\r\n<pre><code class=\"bash\">a_demo (before)     -> ['d1', ['d2', 'd3']]\na_demo (after)      -> ['d1', ['D2', 'd3']]\na_demo_shallow_copy -> ['D1', ['D2', 'd3']]</code></pre><br/>\r\nЭто означает, что поверхностные копии могут привести к появлению побочных эффектов при наличии вложенных списков, а также при использовании других мутабельных элементов. В случае же глубокого копирования риск побочных проявлений отсутствует, что демонстрируется следующим кодом:<br/>\r\n<br/>\r\n<pre><code class=\"python\">a_demo = ['d1', ['d2', 'd3']]\nprint('a_demo (before)     ->', a_demo)\na_demo_deep_copy = deepcopy(a_demo)\na_demo_deep_copy[0] = 'D1'\na_demo_deep_copy[1][0] = 'D2'\nprint('a_demo (after)      ->', a_demo)\nprint('a_demo_deep_copy ->', a_demo_deep_copy)</code></pre><br/>\r\nВывод:<br/>\r\n<br/>\r\n<pre><code class=\"bash\">a_demo (before)  -> ['d1', ['d2', 'd3']]\na_demo (after)   -> ['d1', ['d2', 'd3']]\na_demo_deep_copy -> ['D1', ['D2', 'd3']]</code></pre><br/>\r\nПоказанный пример несложно обобщить. Любой способ получения среза списка в Python, например, <code>a[:]</code>, <code>a[1:4]</code>, <code>a[:5]</code> или <code>a[::-1]</code>, приводит к созданию поверхностной копии извлекаемой части списка. А что происходит при конкатенировании или умножении списков? Сможете спрогнозировать исход операций ниже?<br/>\r\n<br/>\r\n<pre><code class=\"python\">b = a + a\nshow_address('a', a)\nshow_address('b (first part)', b, 0)\nshow_address('b (second part)', b, 3)\n\nb = a*3\nshow_address('\\na', a)\nshow_address('b (first part)', b, 0)\nshow_address('b (second part)', b, 3)\nshow_address('b (third part)', b, 6)</code></pre><br/>\r\nВывод:<br/>\r\n<br/>\r\n<pre><code class=\"bash\">a                   : 4160 | 7728 |  9888 3376 | 3232 0848 2480\nb (first part)      : 5712 | 7728 |  9888 3376 | 3232 0848 2480\nb (second part)     : 5712 | 7728 |  9888 3376 | 3232 0848 2480\n\na                   : 4160 | 7728 |  9888 3376 | 3232 0848 2480\nb (first part)      : 5648 | 7728 |  9888 3376 | 3232 0848 2480\nb (second part)     : 5648 | 7728 |  9888 3376 | 3232 0848 2480\nb (third part)      : 5648 | 7728 |  9888 3376 | 3232 0848 2480</code></pre><br/>\r\nЗдесь видно, что мы создаём дополнительные ссылки (привязки) элементов списка, то есть это подобно поверхностному копированию. Такой подход может вести к неожиданным побочным эффектам. Вот пример:<br/>\r\n<br/>\r\n<pre><code class=\"python\">a_demo = ['d1', ['d2', 'd3']]\nprint('a_demo (before) ->', a_demo)\nb = a_demo + a_demo\nb[0] = 'D1'\nb[1][0] = 'D2'\nprint('b               ->', b)\nprint('a_demo (after)  ->', a_demo)</code></pre><br/>\r\nВывод:<br/>\r\n<br/>\r\n<pre><code class=\"bash\">a_demo (before) -> ['d1', ['d2', 'd3']]\nb               -> ['D1', ['D2', 'd3'], 'd1', ['D2', 'd3']]\na_demo (after)  -> ['d1', ['D2', 'd3']]</code></pre><br/>\r\nЕщё раз призываю вас самостоятельно поэкспериментировать с подобными примерами. Простота синтаксиса и его лаконичность делают Python отличным языком для экспериментов.<br/>\r\n<br/>\r\n<h2><font color=\"#3AC1EF\">Массивы NumPy</font></h2><br/>\r\nПо аналогии со списками Python массивы NumPy также можно копировать или раскрывать через их представление. Чтобы продемонстрировать эту функциональность, мы создадим массив из случайных целых чисел в диапазоне от 0 до 9 включительно.<br/>\r\n<br/>\r\n<pre><code class=\"python\">import numpy as np\nimport sys\n\n\ndef show_details(a_np):\n    print('array is\\n', a_np)\n    print(f'\\ndatatype is {a_np.dtype}')\n    print(f'number of bytes is {a_np.nbytes} bytes ({a_np.size} x 8 bytes)')\n    print(f'size is {sys.getsizeof(a_np)} bytes')\n    print(f'owndata is {a_np.flags.owndata}')\n    print(f'base is {a_np.base}')\n\na_np = np.random.randint(0, 10, (5,5), dtype='int64')\nshow_details(a_np)</code></pre><br/>\r\nПри этом мы попутно определили вспомогательную функцию для отображения элементов массива, общего количества занятых ими <a href=\"https://numpy.org/doc/stable/reference/generated/numpy.ndarray.nbytes.html\">байтов</a>, <a href=\"https://docs.python.org/3/library/sys.html#sys.getsizeof\">общего размера</a> массива в памяти, а также логического значения, которое указывает,<a href=\"https://numpy.org/doc/stable/reference/generated/numpy.ndarray.flags.html\"> владеет ли массив используемой памятью</a>, или же он её одалживает у <a href=\"https://numpy.org/doc/stable/reference/generated/numpy.ndarray.base.html\">базового объекта</a>, который в этом случае тоже выводится.<br/>\r\n<br/>\r\nВывод кода выше:<br/>\r\n<br/>\r\n<pre><code class=\"bash\">[[8 2 8 8 1]\n [7 4 2 8 8]\n [3 3 2 3 3]\n [0 0 7 6 8]\n [2 7 3 4 6]]\n\ndatatype is int64\nnumber of bytes is 200 bytes (25 x 8 bytes)\nsize is 328 bytes\nowndata is True\nbase is None</code></pre><br/>\r\nТип данных этого массива явно установлен как <code>int64</code>, значит, каждый его элемент потребляет 8 байт. Все 25 элементов массива занимают 200 байт, но общий его размер в памяти составляет 328 байт ввиду присутствия метаданных, отражающих тип данных, размер шагов (stride) и прочую важную информацию, помогающую с этим массивом работать. Мы видим, что наш массив содержит собственные данные (<code>owndata is True</code>), в связи с чем его <code>base</code> установлена как <code>None</code>.<br/>\r\n<br/>\r\nПосмотрим, что произойдёт при создании представления:<br/>\r\n<br/>\r\n<pre><code class=\"python\">a_np_view = a_np.view()\nshow_details(a_np_view)</code></pre><br/>\r\nВывод:<br/>\r\n<br/>\r\n<pre><code class=\"bash\">[[8 2 8 8 1]\n [7 4 2 8 8]\n [3 3 2 3 3]\n [0 0 7 6 8]\n [2 7 3 4 6]]\n\ndatatype is int64\nnumber of bytes is 200 bytes (25 x 8 bytes)\nsize is 128 bytes\nowndata is False\nbase is [[8 2 8 8 1]\n [7 4 2 8 8]\n [3 3 2 3 3]\n [0 0 7 6 8]\n [2 7 3 4 6]]</code></pre><br/>\r\nСодержимое массива осталось неизменным. Не изменился и тип данных, а также количество байт, занимаемых его элементами. Остальные же атрибуты теперь иные. Размер массива сократился до 128 байт (то есть 328 – 200), поскольку его представление потребляет память для хранения атрибутов. Элементы массива не копировались, на них были созданы ссылки. Об этом говорит изменившееся значение атрибута <code>base</code>. На языке NumPy представление содержит тот же буфер данных (фактические данные), но при этом имеет собственные метаданные. Изменение элемента представления приведёт к изменению исходного массива.<br/>\r\n<br/>\r\nПосмотрим, что произойдёт при создании копии:<br/>\r\n<br/>\r\n<pre><code class=\"python\">a_np_copy = a_np.copy()\nshow_details(a_np_copy)</code></pre><br/>\r\nВывод:<br/>\r\n<br/>\r\n<pre><code class=\"bash\">[[8 2 8 8 1]\n [7 4 2 8 8]\n [3 3 2 3 3]\n [0 0 7 6 8]\n [2 7 3 4 6]]\n\ndatatype is int64\nnumber of bytes is 200 bytes (25 x 8 bytes)\nsize is 328 bytes\nowndata is True\nbase is None</code></pre><br/>\r\nВывод выглядит идентично выводу исходного массива. Изменение элемента копии не ведёт к изменению оригинала.<br/>\r\n<br/>\r\nМожно поэкспериментировать с изменением формы, получением срезов и индексированием, чтобы понять, когда создаётся копия, а когда представление.<br/>\r\n<br/>\r\n<pre><code class=\"python\">attempts = {'reshape': a_np.reshape(1, 25),\n            'transpose/reshape': a_np.T.reshape(1, 25),\n            'ravel': a_np.ravel(),\n            'transpose/ravel': a_np.T.ravel(),\n            'transpose/ravel (F-order)': a_np.T.ravel(order='F'),\n            'flatten': a_np.flatten(),\n            'transpose/flatten': a_np.T.flatten(),\n            'slicing': a_np[1:2:5],\n            'advanced indexing': a_np[[1, 3, 4]],\n            'combined indexing and slicing': a_np[[0, 2, 4], 1:3],\n            'Boolean indexing': a_np[[True, False, True, False, False]]\n            }\nfor title, b in attempts.items():\n    if b.base is None:\n        print(f'{title} produces a copy')\n    else:\n        print(f'{title} produces a view')</code></pre><br/>\r\nВывод:<br/>\r\n<br/>\r\n<pre><code class=\"bash\">reshape produces a view\ntranspose/reshape produces a view\nravel produces a view\ntranspose/ravel produces a copy\ntranspose/ravel (F-order) produces a view\nflatten produces a copy\ntranspose/flatten produces a copy\nslicing produces a view\nadvanced indexing produces a copy\ncombined indexing and slicing produces a copy\nBoolean indexing produces a copy</code></pre><br/>\r\nПоведение некоторых функций не всегда одинаково. К примеру, <code><a href=\"https://numpy.org/doc/stable/reference/generated/numpy.ravel.html\">numpy.ravel</a></code> возвращает непрерывный уплощённый массив в качестве копии только при необходимости. И напротив, <code><a href=\"http://numpy.ndarray.flatten/\">numpy.ndarray.flatten</a></code> всегда возвращает копию массива, свёрнутую до одного измерения. Поведение <code><a href=\"https://numpy.org/doc/stable/reference/generated/numpy.reshape.html\">numpy.reshape</a></code> несколько запутанней, так что лучше почитать о ней в официальной документации.<br/>\r\n<br/>\r\nОсновной смысл здесь в том, что NumPy создаёт представления, в которых элементы адресуются по смещениям и шагам в исходном массиве, например, при базовом индексировании и получении среза. Такое поведение отличается от поведения списков Python. С другой стороны, при <a href=\"https://numpy.org/doc/stable/user/basics.indexing.html#advanced-indexing\">продвинутом индексировании</a> всегда создаются копии. Операции изменения формы более сложны, и возвращение копии либо представления определяется контекстом.<br/>\r\n<br/>\r\nКопии, созданные в результате продвинутого индексирования, как и копии, полученные через <code><a href=\"https://numpy.org/doc/stable/reference/generated/numpy.copy.html\">numpy.copy</a></code>, не подразумевают глубокого копирования мутабельных элементов внутри массивов. Как и поверхностные копии списков Python, копия массива NumPy содержит тот же самый объект, что может привести к неожиданностям, если этот объект допускает изменение (то есть мутабелен):<br/>\r\n<br/>\r\n<pre><code class=\"python\">\nprint('Numpy shallow copy')\na_np_demo = np.array([1, 2, [3, 4]], dtype=object)\nprint('a_np_demo (before) -> ', a_np_demo)\nb = np.copy(a_np_demo)\nb[0] = -1\nb[2][0] = -3\nprint('b                  -> ', b)\nprint('a_np_demo (after)  -> ', a_np_demo)\n\nfrom copy import deepcopy\nprint('\\nPython deep copy')\na_np_demo = np.array([1, 2, [3, 4]], dtype=object)\nprint('a_np_demo (before) -> ', a_np_demo)\nb2 = deepcopy(a_np_demo)\nb2[0] = -1\nb2[2][0] = -3\nprint('b2                 -> ', b2)\nprint('a_np_demo (after)  -> ', a_np_demo)</code></pre><br/>\r\nВывод:<br/>\r\n<br/>\r\n<pre><code class=\"bash\">Numpy shallow copy\na_np_demo (before) ->  [1 2 list([3, 4])]\nb                  ->  [-1 2 list([-3, 4])]\na_np_demo (after)  ->  [1 2 list([-3, 4])]\n\nPython deep copy\na_np_demo (before) ->  [1 2 list([3, 4])]\nb2                 ->  [-1 2 list([-3, 4])]\na_np_demo (after)  ->  [1 2 list([3, 4])]</code></pre><br/>\r\nХотя это больше теоретический аспект, поскольку массивы NumPy обычно для хранения мутабельных объектов не используются. Но всё же будет нелишним знать, что <code>copy.deepcopy()</code> здесь тоже работает.<br/>\r\n<br/>\r\n<h2><font color=\"#3AC1EF\">Датафреймы pandas</font></h2><br/>\r\nПо уже налаженной схеме мы определим датафрейм и вспомогательную функцию для вывода его описания.<br/>\r\n<br/>\r\n<pre><code class=\"python\">import pandas as pd\nimport numpy as np\nimport sys\n\n\ndef show_details(a_df):\n    print('dataframe is\\n', a_df)\n    print(f'\\ndatatypes are {a_df.dtypes.unique()}')\n    print(f'number of bytes is {a_df.to_numpy().nbytes} bytes ({a_df.size} x 8 bytes)')\n    print(f'size is {sys.getsizeof(a_df)} bytes')\n    print(f\"pointer to data area {a_df.to_numpy().__array_interface__['data'][0]}\")\n\na_df = pd.DataFrame(np.random.randint(0, 10, (5,5), dtype='int64'),\n                    index = [f'r{i}' for i in range(5)],\n                    columns = [f'c{i}' for i in range(5)])\nshow_details(a_df)</code></pre><br/>\r\nСтруктура этих данных совпадает со структурой массива NumPy, то есть в датафрейме присутствует 5х5 элементов <code>int64</code>, но вдобавок к ним мы определили индексы и имена столбцов. Вспомогательная функция была изменена. Датафреймы Pandas могут содержать в разных столбцах разные типы данных, поэтому мы возвращаем уникальные при помощи <code>a_df.dtypes.unique()</code>. Чтобы увидеть, когда содержащиеся данные копируются, а когда на них лишь даётся ссылка, мы сначала через <code>a_df.to_numpy()</code> получим внутренний массив NumPy, а затем используем <a href=\"https://numpy.org/doc/stable/reference/arrays.interface.html\">интерфейс массива</a> для получения указателя на первый элемент его данных.<br/>\r\n<br/>\r\nВывод:<br/>\r\n<br/>\r\n<pre><code class=\"bash\">ddataframe is\n     c0  c1  c2  c3  c4\nr0   5   2   8   6   6\nr1   1   9   1   1   1\nr2   0   7   6   3   7\nr3   7   4   9   5   2\nr4   5   8   3   7   1\n\ndatatypes are [dtype('int64')]\nnumber of bytes is 200 bytes (25 x 8 bytes)\nsize is 511 bytes\npointer to data area 2893487649296</code></pre><br/>\r\nТеперь у нас есть всё необходимое для экспериментов с копиями и представлениями.<br/>\r\n<br/>\r\nГлядя на интерфейс API, можно найти функцию <a href=\"https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.copy.html\">копирования</a> датафрейма, получающую логический аргумент <code>deep</code>. Если он <code>True</code> (по умолчанию), создаётся новый объект с копией данных вызывающего объекта и индексами (это не глубокая копия в смысле <code>copy.deepcopy()</code> стандартной библиотеки; см. ниже). Эти данные и индексы можно изменить, не затронув исходный датафрейм. Если же <code>deep = False</code>, новый объект создаётся без копирования данных или индексов вызывающего объекта, то есть генерируются только ссылки на них. В таком случае любые изменения в данных оригинального датафрейма будут отражаться в его копии.<br/>\r\n<br/>\r\nПоэкспериментируем с представлением:<br/>\r\n<br/>\r\n<pre><code class=\"python\">a_df_copy = a_df.copy(deep=False)\nshow_details(a_df_copy)\nprint(f'Same base: {a_df.to_numpy().base is a_df_copy.to_numpy().base}')\nprint(f'Same row index: {a_df.index is a_df_copy.index}')\nprint(f'Same column index: {a_df.columns is a_df_copy.columns}')</code></pre><br/>\r\nВывод:<br/>\r\n<br/>\r\n<pre><code class=\"bash\">dataframe is\n     c0  c1  c2  c3  c4\nr0   5   2   8   6   6\nr1   1   9   1   1   1\nr2   0   7   6   3   7\nr3   7   4   9   5   2\nr4   5   8   3   7   1\n\ndatatypes are [dtype('int64')]\nnumber of bytes is 200 bytes (25 x 8 bytes)\nsize is 511 bytes\npointer to data area 2893487649296\nSame base: True\nSame row index: True\nSame column index: True</code></pre><br/>\r\nЗдесь видно, что область данных указывает на тот же адрес памяти, основой массива выступает тот же объект, и два указанных индекса представляют те же объекты.<br/>\r\n<br/>\r\nТеперь создадим копию (<code>deep=True</code> используется по умолчанию, но я включаю его для большей ясности).<br/>\r\n<br/>\r\n<pre><code class=\"python\">a_df_copy = a_df.copy(deep=True)\nshow_details(a_df_copy)\nprint(f'Same base: {a_df.to_numpy().base is a_df_copy.to_numpy().base}')\nprint(f'Same row index: {a_df.index is a_df_copy.index}')\nprint(f'Same column index: {a_df.columns is a_df_copy.columns}')</code></pre><br/>\r\nВывод:<br/>\r\n<br/>\r\n<pre><code class=\"bash\">dataframe is\n     c0  c1  c2  c3  c4\nr0   5   2   8   6   6\nr1   1   9   1   1   1\nr2   0   7   6   3   7\nr3   7   4   9   5   2\nr4   5   8   3   7   1\n\ndatatypes are [dtype('int64')]\nnumber of bytes is 200 bytes (25 x 8 bytes)\nsize is 511 bytes\npointer to data area 2893487655536\nSame base: False\nSame row index: False\nSame column index: False</code></pre><br/>\r\nЗдесь у копии уже используется иная основа, что также отражено в изменённом указателе на область данных. Помимо этого, мы создали новые объекты для двух индексов. Ещё раз напомню, что аналогично массивам NumPy при нахождении в датафрейме мутабельных элементов их изменение в копии приведёт к изменению оригинального датафрейма, как это показано ниже:<br/>\r\n<br/>\r\n<pre><code class=\"python\">import re\n\n\na_df_demo = pd.DataFrame({'c1': [1, 2], 'c2': [3, {'key1': 'v', 'key2': 'v'}]})\nprint('a_df_demo (before) ->', re.sub(r'\\s+', ' ', str(a_df_demo)))\n# make a copy\nb = a_df_demo.copy(deep=True)\n# remove one key-value pair from the dicitionary at iloc position (1, 1)\ndel b.iloc[1,1]['key2']\nprint('b                  ->', re.sub(r'\\s+', ' ', str(b)))\nprint('a_df_demo (after)  ->', re.sub(r'\\s+', ' ', str(b)))</code></pre><br/>\r\nВывод:<br/>\r\n<br/>\r\n<pre><code class=\"bash\">a_df_demo (before) ->  c1 c2 0 1 3 1 2 {'key1': 'v', 'key2': 'v'}\nb                  ->  c1 c2 0 1 3 1 2 {'key1': 'v'}\na_df_demo (after)  ->  c1 c2 0 1 3 1 2 {'key1': 'v'}</code></pre><br/>\r\nЭто не очень частый вариант использования датафреймов Pandas, но его всё же стоит иметь в виду. К сожалению, в Pandas невозможно сделать истинную глубокую копию, используя функцию <code>copy.deepcopy()</code> из стандартной библиотеки, поскольку разработчики этой библиотеки <a href=\"https://github.com/pandas-dev/pandas/issues/17406\">реализовали</a> <code>pd.DataFrame.__deepcopy__()</code> как <code>pd.DataFrame.copy(deep=True)</code>. Не уверен, изменится ли это в будущем, но в любом случае данный приём считается антипаттерном. Pandas в этом плане отличается от NumPy.<br/>\r\n<br/>\r\nТеперь можно рассмотреть разные способы выбора строк и столбцов с помощью Pandas.<br/>\r\n<br/>\r\n<pre><code class=\"python\">attempts = {'select one column': a_df['c1'],\n            'select one column using []': a_df[['c1']],\n            'select one column with loc': a_df.loc[:, 'c1'],\n            'select columns with loc and slicing': a_df.loc[:, 'c1':'c3'],\n            'select columns with loc and fancy indexing': a_df.loc[:, ['c1', 'c2', 'c3']],\n            'select rows using loc and a Boolean mask': a_df.loc[a_df['c1']>5],\n            'select rows with loc and slicing': a_df.loc['r1': 'r3'],\n            'chained indexing': a_df.loc['r1': 'r3']['c1'],\n            }\nfor title, b in attempts.items():\n    if a_df.to_numpy().base is not b.to_numpy().base:\n        print(f'{title} does not use the same base')\n    else:\n        print(f'{title} uses the same base')</code></pre><br/>\r\nВывод:<br/>\r\n<br/>\r\n<pre><code class=\"bash\">select one column uses the same base\nselect one column using [] does not use the same base\nselect one column with loc uses the same base\nselect columns with loc and slicing uses the same base\nselect columns with loc and fancy indexing does not use the same base\nselect rows using loc and a Boolean mask does not use the same base\nselect rows with loc and slicing uses the same base\nchained indexing uses the same base</code></pre><br/>\r\nПри базовом индексировании и получении срезов, например, в случае простого индексирования по столбцам с использованием квадратных скобок или аксессора <code>.loc[]</code>, используется одна основа, но при остальных операциях это не так. В случае сомнений вышеприведённая схема вычислительных экспериментов позволит получить быстрый ответ.<br/>\r\n<br/>\r\nК сожалению, проверки неизменности основы не всегда достаточно для прогнозирования последствий использования цепного индексирования (см. ниже), но она даёт некоторое базовое понимание. В последней попытке основа остаётся прежней, но даже если мы используем это цепное индексирование для установки значений, исходный датафрейм останется неизменным. Хотя есть и обратный вариант: если основа изменяется, значит, мы работаем с копией. Здесь бы не помешали ваши комментарии, поскольку в этом вопросе я начинаю плавать.<br/>\r\n<br/>\r\nДалее же мы перейдём к заключительной теме, связанной с Pandas, а именно к пресловутому цепному индексированию и связанным с ним <code>SettingWithCopyWarning</code>. Используя ранее определённый датафрейм <code>a_df</code>, можно попробовать изменить значения конкретных элементов столбца при помощи логического индекса. Если предположить использование цепного индексирования, то на ум приходят два способа:<br/>\r\n<br/>\r\n<pre><code class=\"python\"># создание копии, чтобы не изменять исходный датафрейм\na_df_demo = a_df.copy(deep=True)\n\n# установка логического индекса\nmsk = a_df['c1']>5\n\n# attempt 1: сначала логическое индексирование (выдаёт SettingWithCopyWarning)\nprint('attempt 1')\na_df_demo.loc[msk]['c3'] = -1\nprint(a_df_demo)\n\n# attempt 2, логическое индексирование в конце\nprint('\\nattempt 2')\na_df_demo['c3'].loc[msk] = -1 # &lt;- выдаёт предупреждение\nprint(a_df_demo)</code></pre><br/>\r\nВывод:<br/>\r\n<br/>\r\n<pre><code class=\"bash\">attempt 1\n    c0  c1  c2  c3  c4\nr0   5   2   8   6   6\nr1   1   9   1   1   1\nr2   0   7   6   3   7\nr3   7   4   9   5   2\nr4   5   8   3   7   1\n\nattempt 2\n    c0  c1  c2  c3  c4\nr0   5   2   8   6   6\nr1   1   9   1  -1   1\nr2   0   7   6  -1   7\nr3   7   4   9   5   2\nr4   5   8   3  -1   1\n\n&lt;ipython-input-789-06440868e65b>:5: SettingWithCopyWarning:\nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  a_df_demo.loc[msk]['c3'] = -1</code></pre><br/>\r\nЗдесь имеет значение <a href=\"https://pandas.pydata.org/docs/user_guide/indexing.html#evaluation-order-matters\">порядок выполнения</a> операций. Первая попытка приводит к выдаче <code>SettingWithCopyWarning</code>, что вполне ожидаемо. При использовании аксессора <code>.loc[]</code> с логической маской мы получаем копию. Присваивание элементам копии новых значений не ведёт к изменению исходного датафрейма. Это ожидаемое поведение, но Pandas, в отличие от NumPy, делает дополнительный шаг и даёт пользователю рекомендацию. Хотя даже в случае Pandas не стоит особо полагаться на такие предупреждения, поскольку выводятся они не всегда. К примеру,<br/>\r\n<br/>\r\n<pre><code class=\"python\">a_df_demo = a_df.copy(deep=True)\na_df_demo.loc[['r1', 'r2', 'r3']]['c3'] = -1\nprint(a_df_demo)</code></pre><br/>\r\nНе выдаёт предупреждения, хотя датафрейм не изменяется, что видно по выводу:<br/>\r\n<br/>\r\n<pre><code class=\"bash\">    c0  c1  c2  c3  c4\nr0   5   2   8   6   6\nr1   1   9   1   1   1\nr2   0   7   6   3   7\nr3   7   4   9   5   2\nr4   5   8   3   7   1</code></pre><br/>\r\nНужно ли всё это помнить? Не обязательно. Не только потому, что практически нереально перечислить все возможности цепного индексирования, но также ввиду отсутствия гарантии неизменности поведения в различных версиях Pandas при использовании <code>SettingWithCopyWarning</code>. Хуже того, может случиться так, что в одной версии датафрейм будет изменяться, а в другой нет (личных подтверждений этому у меня нет, просто опасения).<br/>\r\n<br/>\r\nИспользование виртуальной среды и настройка <a href=\"https://learnpython.com/blog/python-requirements-file/\">файла requirements.txt</a> не только предотвратят ад зависимостей, но и защитят от подобных опасностей, хотя лучше всего знать, какие присваивания в Pandas представляют риски, чтобы их избегать. Ситуация дополнительно усложняется, когда датафрейм содержит <a href=\"https://pandas.pydata.org/docs/user_guide/indexing.html#returning-a-view-versus-a-copy\">иерархические индексы</a> и разные типы данных. В таком случае пытаться предугадать результат цепного индексирования опасно.<br/>\r\n<br/>\r\nПравильным выходом будет избегать такого вида индексирования и использовать для установки значений один аксессор. Вот пример:<br/>\r\n<br/>\r\n<pre><code class=\"python\">a_df_demo = a_df.copy(deep=True)\na_df_demo.loc['r1':'r2', 'c2'] = -1\nprint(a_df_demo)</code></pre><br/>\r\nЭтот код выводит изменённый датафрейм, не выводя предупреждение.<br/>\r\n<br/>\r\n<pre><code class=\"bash\">    c0  c1  c2  c3  c4\nr0   5   2   8   6   6\nr1   1   9  -1   1   1\nr2   0   7  -1   3   7\nr3   7   4   9   5   2\nr4   5   8   3   7   1</code></pre><br/>\r\n<h2><font color=\"#3AC1EF\">Так весь смысл в использовании одного аксессора?</font></h2><br/>\r\nИспользовать один аксессор и избегать цепного индексирования – это определённо надёжный совет, но есть тут и подвохи. Давайте создадим срез датафрейма и посмотрим, что с ним происходит при изменении исходных данных.<br/>\r\n<br/>\r\nПервая попытка подразумевает три подобных эксперимента.<br/>\r\n<br/>\r\n<pre><code class=\"python\"># -- NOT ALWAYS CHANGED --\nprint('experiment 1')\ndf = pd.DataFrame({\"a\": np.arange(4), \"b\": np.arange(4)})\nprint('data buffer pointer (before) ->', df.to_numpy().__array_interface__['data'][0])\nprint('data types (before) ->', df.dtypes.unique().tolist())\nmy_slice = df.loc[1:3]\nprint('my_slice (before) ->', my_slice.unstack().to_list())\n# Изменяет my_slice\ndf.loc[1, 'a'] = -10\nprint('data buffer pointer (after)  ->', df.to_numpy().__array_interface__['data'][0])\nprint('data types (after)  ->', df.dtypes.unique().tolist())\nprint('my_slice (after)  ->', my_slice.unstack().to_list())\n\nprint('experiment 2')\ndf = pd.DataFrame({\"a\": np.arange(4), \"b\": np.arange(4)})\nprint('data buffer pointer (before) ->', df.to_numpy().__array_interface__['data'][0])\nprint('data types (before) ->', df.dtypes.unique().tolist())\nmy_slice = df.loc[1:3]\nprint('my_slice (before) ->', my_slice.unstack().to_list())\n# Изменяет my_slice\ndf.loc[0:, 'a'] = -10\nprint('data buffer pointer (after)  ->', df.to_numpy().__array_interface__['data'][0])\nprint('data types (after)  ->', df.dtypes.unique().tolist())\nprint('my_slice (after)  ->', my_slice.unstack().to_list())\n\nprint('experiment 3')\ndf = pd.DataFrame({\"a\": np.arange(4), \"b\": np.arange(4)})\nprint('data buffer pointer (before) ->', df.to_numpy().__array_interface__['data'][0])\nprint('data types (before) ->', df.dtypes.unique().tolist())\nmy_slice = df.loc[1:3]\nprint('my_slice (before) ->', my_slice.unstack().to_list())\n# Не изменяет my_slice\ndf.loc[:, 'a'] = -10\nprint('data buffer pointer (after)  ->', df.to_numpy().__array_interface__['data'][0])\nprint('data types (after)  ->', df.dtypes.unique().tolist())\nprint('my_slice (after)  ->', my_slice.unstack().to_list())</code></pre><br/>\r\nОтличаются эти эксперименты только способом изменения исходного датафрейма. Первый изменяет лишь один элемент столбца <code>a</code>, второй изменяет весь столбец <code>a</code>, а третий также изменяет весь этот столбец, но уже с помощью <code>df.loc[:,'a']</code>.<br/>\r\n<br/>\r\nВот вывод:<br/>\r\n<br/>\r\n<pre><code class=\"bash\">experiment 1\ndata buffer pointer (before) -> 2893435341184\ndata types (before) -> [dtype('int32')]\nmy_slice (before) -> [1, 2, 3, 1, 2, 3]\ndata buffer pointer (after)  -> 2893435341184\ndata types (after)  -> [dtype('int32')]\nmy_slice (after)  -> [-10, 2, 3, 1, 2, 3]\n\nexperiment 2\ndata buffer pointer (before) -> 2893490708496\ndata types (before) -> [dtype('int32')]\nmy_slice (before) -> [1, 2, 3, 1, 2, 3]\ndata buffer pointer (after)  -> 2893490708496\ndata types (after)  -> [dtype('int32')]\nmy_slice (after)  -> [-10, -10, -10, 1, 2, 3]\n\nexperiment 3\ndata buffer pointer (before) -> 2893435341184\ndata types (before) -> [dtype('int32')]\nmy_slice (before) -> [1, 2, 3, 1, 2, 3]\ndata buffer pointer (after)  -> 2893491528672\ndata types (after)  -> [dtype('int64'), dtype('int32')]\nmy_slice (after)  -> [1, 2, 3, 1, 2, 3]</code></pre><br/>\r\nВ результате успешного изменения датафрейма его срез также изменяется только в первых двух экспериментах. Если посмотреть внимательно, тип одного из столбцов датафрейма изменился на <code>int64</code>, а его буфер данных переместился в памяти. Я думаю, что причина преобразования типа в изменении значения всего столбца <code>a</code>. В этом можно убедиться, если установить тип данных явно при создании датафрейма.<br/>\r\n<br/>\r\n<pre><code class=\"python\"># -- ALWAYS CHANGED --\nprint('experiment 1')\ndf = pd.DataFrame({\"a\": np.arange(4), \"b\": np.arange(4)}, dtype='int64')\nprint('data buffer pointer (before) ->', df.to_numpy().__array_interface__['data'][0])\nprint('data types (before) ->', df.dtypes.unique().tolist())\nmy_slice = df.loc[1:3]\nprint('my_slice (before) ->', my_slice.unstack().to_list())\n# Изменяет my_slice\ndf.loc[1, 'a'] = -10\nprint('data buffer pointer (after)  ->', df.to_numpy().__array_interface__['data'][0])\nprint('data types (after)  ->', df.dtypes.unique().tolist())\nprint('my_slice (after)  ->', my_slice.unstack().to_list())\n\nprint('experiment 2')\ndf = pd.DataFrame({\"a\": np.arange(4), \"b\": np.arange(4)}, dtype='int64')\nprint('data buffer pointer (before) ->', df.to_numpy().__array_interface__['data'][0])\nprint('data types (before) ->', df.dtypes.unique().tolist())\nmy_slice = df.loc[1:3]\nprint('my_slice (before) ->', my_slice.unstack().to_list())\n# Изменяет my_slice\ndf.loc[0:, 'a'] = -10\nprint('data buffer pointer (after)  ->', df.to_numpy().__array_interface__['data'][0])\nprint('data types (after)  ->', df.dtypes.unique().tolist())\nprint('my_slice (after)  ->', my_slice.unstack().to_list())\n\nprint('experiment 3')\ndf = pd.DataFrame({\"a\": np.arange(4), \"b\": np.arange(4)}, dtype='int64')\nprint('data buffer pointer (before) ->', df.to_numpy().__array_interface__['data'][0])\nprint('data types (before) ->', df.dtypes.unique().tolist())\nmy_slice = df.loc[1:3]\nprint('my_slice (before) ->', my_slice.unstack().to_list())\n# Не изменяет my_slice\ndf.loc[:, 'a'] = -10\nprint('data buffer pointer (after)  ->', df.to_numpy().__array_interface__['data'][0])\nprint('data types (after)  ->', df.dtypes.unique().tolist())\nprint('my_slice (after)  ->', my_slice.unstack().to_list())</code></pre><br/>\r\nВывод:<br/>\r\n<br/>\r\n<pre><code class=\"bash\">experiment 1\ndata buffer pointer (before) -> 2893491528672\ndata types (before) -> [dtype('int64')]\nmy_slice (before) -> [1, 2, 3, 1, 2, 3]\ndata buffer pointer (after)  -> 2893491528672\ndata types (after)  -> [dtype('int64')]\nmy_slice (after)  -> [-10, 2, 3, 1, 2, 3]\n\nexperiment 2\ndata buffer pointer (before) -> 2893486517968\ndata types (before) -> [dtype('int64')]\nmy_slice (before) -> [1, 2, 3, 1, 2, 3]\ndata buffer pointer (after)  -> 2893486517968\ndata types (after)  -> [dtype('int64')]\nmy_slice (after)  -> [-10, -10, -10, 1, 2, 3]\n\nexperiment 3\ndata buffer pointer (before) -> 2893491528672\ndata types (before) -> [dtype('int64')]\nmy_slice (before) -> [1, 2, 3, 1, 2, 3]\ndata buffer pointer (after)  -> 2893491528672\ndata types (after)  -> [dtype('int64')]\nmy_slice (after)  -> [-10, -10, -10, 1, 2, 3]</code></pre><br/>\r\nДумаю, нет особого смысла оставлять уже неактуальный срез, если только он не был явно скопирован с помощью <code>df.loc[1:3].copy()</code>. В противном случае всегда можно получить свежий срез датафрейма именно в момент необходимости. Хотя это вполне рабочий эксперимент, позволяющий лучше понять тему представлений и копий.<br/>\r\n<br/>\r\n<h2><font color=\"#3AC1EF\">Заключение</font></h2><br/>\r\nЧтобы понять, когда Python создаёт копии, а когда представления, необходима практика. Списки Python, массивы NumPy и датафреймы Pandas предлагают функции для создания копий и представлений, как это показано в таблице ниже.<br/>\r\n<br/>\r\n<img src=\"https://habrastorage.org/r/w1560/webt/pm/bh/x_/pmbhx_rbvhhoym1227brioxjyom.png\" data-src=\"https://habrastorage.org/webt/pm/bh/x_/pmbhx_rbvhhoym1227brioxjyom.png\"/><br/>\r\n<i><font color=\"#999999\">Интерактивная версия доступна в <a href=\"https://towardsdatascience.com/views-and-copies-in-python-1e46b5af4728\">оригинале статьи</a></font></i><br/>\r\n<br/>\r\nОднако самые важные выводы связаны с поведением инструкций присваивания на основе индексов при использовании массивов NumPy и датафреймов Pandas:<br/>\r\n<br/>\r\n<ul>\r\n<li>цепное индексирование NumPy обычно вполне ясно: базовое индексирование даёт представления, а продвинутое возвращает копии, которые исключают изменение исходного массива в случае новых присваиваний. Это поведение несколько усложняется при использовании операций изменения формы (<code>reshape</code>);</li>\r\n<li>цепного индексирования в Pandas желательно избегать, используя вместо него один аксессор для всех присваиваний. Это касается даже тех случаев, когда поведение цепного индексирования, казалось бы, можно спрогнозировать.</li>\r\n</ul><br/>\r\nПонимать принцип создания представлений и копий очень важно, особенно при работе с крупными массивами и датафреймами. Надеюсь, эта статья послужит основой для дальнейшего изучения темы. Несомненно, некоторые аспекты я упустил, а некоторые — мог неверно понять сам. Буду признателен за ваши справедливые замечания и дополнения в комментариях, которые лишний раз подтвердят истинность изречения Альберта Эйнштейна.<br/>\r\n<br/>\r\n<h3><font color=\"#3AC1EF\">▍ Рекомендуемые материалы:</font></h3><br/>\r\n<ul>\r\n<li>Прекрасная <a href=\"https://realpython.com/pandas-settingwithcopywarning\">статья</a> (англ.) о вездесущем <code>SettingWithCopyWarning</code> в Pandas;</li>\r\n<li>Документация Python по <a href=\"https://numpy.org/devdocs/user/basics.copies.html#copies-and-views\">копиям и представлениям</a>;</li>\r\n<li>Документация Pandas по <a href=\"https://pandas.pydata.org/docs/user_guide/indexing.html#returning-a-view-versus-a-copy\">копиям и представлениям</a>.</li>\r\n</ul><br/>\r\n<a href=\"http://ruvds.com/ru-rub?utm_source=habr&amp;utm_medium=article&amp;utm_campaign=Bright_Translate&amp;utm_content=rabota_s_poverxnostnymi_i_glubokimi_kopiyami_v_python\"><img src=\"https://habrastorage.org/r/w780q1/webt/ym/oc/6_/ymoc6_v0doy8yrm1y4xsrjlxotc.jpeg\" data-src=\"https://habrastorage.org/webt/ym/oc/6_/ymoc6_v0doy8yrm1y4xsrjlxotc.jpeg\" data-blurred=\"true\"/></a></div>",
        "clean_body": "\r\nВ этой статье объясняется, как делать копии списков Python, массивов NumPy и датафреймов Pandas при помощи операций получения срезов, списочного индексирования (fancy indexing) и логического (boolean indexing). Эти операции очень часто используются при анализе данных и должны рассматриваться всерьёз, поскольку ошибочные предположения могут привести к падению быстродействия или неожиданным результатам.\n\r\nPython кажется простым, но всякий раз, возвращаясь к его азам, ты находишь новые для освоения вещи. Здесь на ум приходит известное изречение Эйнштейна:\n\n«Чем больше я узнаю, тем больше понимаю, как много я ещё не знаю».\nВступление\r\nЯ часто задаюсь вопросом, действительно ли я знаю тот или иной предмет в совершенстве. Получив кандидатскую степень и проработав часть жизни исследователем, я могу с уверенностью сказать, что утвердительного ответа на этот вопрос не бывает. Я уже давно работаю с Python и осознаю ценность этого инструмента для анализа данных. С его помощью я создавал множество эффективных решений для реальных задач. И всё же каждый раз, возвращаясь к основам этого языка, я нахожу в нём нечто новое для освоения или вижу иной ракурс для восприятия уже привычных вещей.\n\r\nЭто осознание зачастую возникает во время чтения вводной части книги, которая намеренно содержит простой материал, подготавливая читателя к основной сути. Приведённая фраза Эйнштейна звучит у меня в сознании, когда в очередной раз после использования интерпретатора Python, я задумываюсь, почему столь простые вещи открываются для меня только сейчас?\n\r\nИ текущая статья появилась вслед за одним из таких случаев. В ней я хочу объяснить, как списки Python, массивы NumPy и датафреймы Pandas создают представления или полноценные копии данных при получении срезов, а также множественном и логическом индексировании. В этой теме возникает некоторая путаница, поскольку термины «поверхностная копия» и «глубокая копия» не всегда означают одно и то же, а также неясно, когда дополнительная информация вроде метаданных массива NumPy и индексов Pandas копируется полноценно, а когда поверхностно.\n\r\nЭта статья может не дать всех исчерпывающих ответов, но она обеспечит основу, которая позволит в случае сомнений дополнить инструкции из документации собственными вычислительными экспериментами.\n\r\nВсе примеры кода были подготовлены с использованием Python v3.8.10, Pandas v1.5.1 и NumPy v1.23.4.\n\nСписки Python\r\nВ этом разделе мы проведём ряд экспериментов, чтобы понять принцип создания копий списков Python. Если вы будете проделывать аналогичные действия, то помните, что Python кэширует небольшие целые числа и строки, чтобы иметь возможность обращаться к уже имеющимся объектам, а не создавать каждый раз новые. Это так называемое интернирование является одной из оптимизаций CPython, которая при написании статьи использовалась в стандартном Python. Для избежания путаницы при поиске адресов объектов рекомендуется использовать разные строки и целые числа.\n\r\nНекоторые читатели могут подумать, что списки в Python являются простой темой. Как бы не так. Давайте создадим такой список, который будет содержать целое число, другой список и вложенный список. Вдобавок к этому мы создадим вспомогательную функцию для вывода адресов различных элементов списка, которая, в целях сокращения, будет показывать только четыре последние цифры адреса.\n\ndef show_address(title, a, offset=0):\n    trim_ad = lambda ad: str(id(ad))[-4:]\n    print(f\"{title.ljust(20, ' ')}: {trim_ad(a)} | {trim_ad(a[offset+0])} |  \"\n          f\"{trim_ad(a[offset+1])} {trim_ad(a[offset+1][0])} | \"\n          f\"{trim_ad(a[offset+2])} {trim_ad(a[offset+2][0])} {trim_ad(a[offset+2][0][0])}\")\n\n# original list\na = ['1', ['2','3'], [['4','5'],['6','7']]]\nshow_address('a', a)\r\nВывод:\n\na                   : 4160 | 7728 |  9888 3376 | 3232 0848 2480\r\nОчевидно, что при каждом выполнении адреса будут отличаться. В связи с этим мы сделаем так, чтобы массив a далее не изменялся. Ниже мы попробуем реплицировать этот массив разными способами, а именно с помощью простого присваивания другой переменной и глубокого копирования:\n\nfrom copy import copy, deepcopy\n\n\nattempts = {'new binding': a,\n            'shallow copy I': a[:],\n            'shallow copy II': list(a),\n            'shallow copy III': a.copy(),\n            'shallow copy IV': copy(a),\n            'deep copy': deepcopy(a)\n            }\nfor title, b in attempts.items():\n    show_address(title, b)\r\nВывод:\n\nnew binding         : 4160 | 7728 |  9888 3376 | 3232 0848 2480\nshallow copy I      : 7072 | 7728 |  9888 3376 | 3232 0848 2480\nshallow copy II     : 9312 | 7728 |  9888 3376 | 3232 0848 2480\nshallow copy III    : 1488 | 7728 |  9888 3376 | 3232 0848 2480\nshallow copy IV     : 8128 | 7728 |  9888 3376 | 3232 0848 2480\ndeep copy           : 0528 | 7728 |  6848 3376 | 0816 2960 2480\r\nПервым делом нужно обратить внимание, что адрес списка (первый численный столбец) изменяется при каждой попытке, за исключением первой операции изменения привязки. Это говорит о том, что в ходе неё была сделана копия. Данный код реализует четыре разных способа создания поверхностной копии, подразумевающей изменение списка, при котором его элементы остаются прежними объектами. Если попробовать изменить немутабельный элемент такой неполной копии списка, исходный список останется нетронутым. При изменении же мутабельного элемента оригинальный список также меняется. Например:\n\na_demo = ['d1', ['d2', 'd3']]\nprint('a_demo (before)     ->', a_demo)\na_demo_shallow_copy = a_demo[:]\na_demo_shallow_copy[0] = 'D1'\na_demo_shallow_copy[1][0] = 'D2'\nprint('a_demo (after)      ->', a_demo)\nprint('a_demo_shallow_copy ->', a_demo_shallow_copy)\r\nВывод:\n\na_demo (before)     -> ['d1', ['d2', 'd3']]\na_demo (after)      -> ['d1', ['D2', 'd3']]\na_demo_shallow_copy -> ['D1', ['D2', 'd3']]\r\nЭто означает, что поверхностные копии могут привести к появлению побочных эффектов при наличии вложенных списков, а также при использовании других мутабельных элементов. В случае же глубокого копирования риск побочных проявлений отсутствует, что демонстрируется следующим кодом:\n\na_demo = ['d1', ['d2', 'd3']]\nprint('a_demo (before)     ->', a_demo)\na_demo_deep_copy = deepcopy(a_demo)\na_demo_deep_copy[0] = 'D1'\na_demo_deep_copy[1][0] = 'D2'\nprint('a_demo (after)      ->', a_demo)\nprint('a_demo_deep_copy ->', a_demo_deep_copy)\r\nВывод:\n\na_demo (before)  -> ['d1', ['d2', 'd3']]\na_demo (after)   -> ['d1', ['d2', 'd3']]\na_demo_deep_copy -> ['D1', ['D2', 'd3']]\r\nПоказанный пример несложно обобщить. Любой способ получения среза списка в Python, например, a[:], a[1:4], a[:5] или a[::-1], приводит к созданию поверхностной копии извлекаемой части списка. А что происходит при конкатенировании или умножении списков? Сможете спрогнозировать исход операций ниже?\n\nb = a + a\nshow_address('a', a)\nshow_address('b (first part)', b, 0)\nshow_address('b (second part)', b, 3)\n\nb = a*3\nshow_address('\\na', a)\nshow_address('b (first part)', b, 0)\nshow_address('b (second part)', b, 3)\nshow_address('b (third part)', b, 6)\r\nВывод:\n\na                   : 4160 | 7728 |  9888 3376 | 3232 0848 2480\nb (first part)      : 5712 | 7728 |  9888 3376 | 3232 0848 2480\nb (second part)     : 5712 | 7728 |  9888 3376 | 3232 0848 2480\n\na                   : 4160 | 7728 |  9888 3376 | 3232 0848 2480\nb (first part)      : 5648 | 7728 |  9888 3376 | 3232 0848 2480\nb (second part)     : 5648 | 7728 |  9888 3376 | 3232 0848 2480\nb (third part)      : 5648 | 7728 |  9888 3376 | 3232 0848 2480\r\nЗдесь видно, что мы создаём дополнительные ссылки (привязки) элементов списка, то есть это подобно поверхностному копированию. Такой подход может вести к неожиданным побочным эффектам. Вот пример:\n\na_demo = ['d1', ['d2', 'd3']]\nprint('a_demo (before) ->', a_demo)\nb = a_demo + a_demo\nb[0] = 'D1'\nb[1][0] = 'D2'\nprint('b               ->', b)\nprint('a_demo (after)  ->', a_demo)\r\nВывод:\n\na_demo (before) -> ['d1', ['d2', 'd3']]\nb               -> ['D1', ['D2', 'd3'], 'd1', ['D2', 'd3']]\na_demo (after)  -> ['d1', ['D2', 'd3']]\r\nЕщё раз призываю вас самостоятельно поэкспериментировать с подобными примерами. Простота синтаксиса и его лаконичность делают Python отличным языком для экспериментов.\n\nМассивы NumPy\r\nПо аналогии со списками Python массивы NumPy также можно копировать или раскрывать через их представление. Чтобы продемонстрировать эту функциональность, мы создадим массив из случайных целых чисел в диапазоне от 0 до 9 включительно.\n\nimport numpy as np\nimport sys\n\n\ndef show_details(a_np):\n    print('array is\\n', a_np)\n    print(f'\\ndatatype is {a_np.dtype}')\n    print(f'number of bytes is {a_np.nbytes} bytes ({a_np.size} x 8 bytes)')\n    print(f'size is {sys.getsizeof(a_np)} bytes')\n    print(f'owndata is {a_np.flags.owndata}')\n    print(f'base is {a_np.base}')\n\na_np = np.random.randint(0, 10, (5,5), dtype='int64')\nshow_details(a_np)\r\nПри этом мы попутно определили вспомогательную функцию для отображения элементов массива, общего количества занятых ими байтов, общего размера массива в памяти, а также логического значения, которое указывает, владеет ли массив используемой памятью, или же он её одалживает у базового объекта, который в этом случае тоже выводится.\n\r\nВывод кода выше:\n\n[[8 2 8 8 1]\n [7 4 2 8 8]\n [3 3 2 3 3]\n [0 0 7 6 8]\n [2 7 3 4 6]]\n\ndatatype is int64\nnumber of bytes is 200 bytes (25 x 8 bytes)\nsize is 328 bytes\nowndata is True\nbase is None\r\nТип данных этого массива явно установлен как int64, значит, каждый его элемент потребляет 8 байт. Все 25 элементов массива занимают 200 байт, но общий его размер в памяти составляет 328 байт ввиду присутствия метаданных, отражающих тип данных, размер шагов (stride) и прочую важную информацию, помогающую с этим массивом работать. Мы видим, что наш массив содержит собственные данные (owndata is True), в связи с чем его base установлена как None.\n\r\nПосмотрим, что произойдёт при создании представления:\n\na_np_view = a_np.view()\nshow_details(a_np_view)\r\nВывод:\n\n[[8 2 8 8 1]\n [7 4 2 8 8]\n [3 3 2 3 3]\n [0 0 7 6 8]\n [2 7 3 4 6]]\n\ndatatype is int64\nnumber of bytes is 200 bytes (25 x 8 bytes)\nsize is 128 bytes\nowndata is False\nbase is [[8 2 8 8 1]\n [7 4 2 8 8]\n [3 3 2 3 3]\n [0 0 7 6 8]\n [2 7 3 4 6]]\r\nСодержимое массива осталось неизменным. Не изменился и тип данных, а также количество байт, занимаемых его элементами. Остальные же атрибуты теперь иные. Размер массива сократился до 128 байт (то есть 328 – 200), поскольку его представление потребляет память для хранения атрибутов. Элементы массива не копировались, на них были созданы ссылки. Об этом говорит изменившееся значение атрибута base. На языке NumPy представление содержит тот же буфер данных (фактические данные), но при этом имеет собственные метаданные. Изменение элемента представления приведёт к изменению исходного массива.\n\r\nПосмотрим, что произойдёт при создании копии:\n\na_np_copy = a_np.copy()\nshow_details(a_np_copy)\r\nВывод:\n\n[[8 2 8 8 1]\n [7 4 2 8 8]\n [3 3 2 3 3]\n [0 0 7 6 8]\n [2 7 3 4 6]]\n\ndatatype is int64\nnumber of bytes is 200 bytes (25 x 8 bytes)\nsize is 328 bytes\nowndata is True\nbase is None\r\nВывод выглядит идентично выводу исходного массива. Изменение элемента копии не ведёт к изменению оригинала.\n\r\nМожно поэкспериментировать с изменением формы, получением срезов и индексированием, чтобы понять, когда создаётся копия, а когда представление.\n\nattempts = {'reshape': a_np.reshape(1, 25),\n            'transpose/reshape': a_np.T.reshape(1, 25),\n            'ravel': a_np.ravel(),\n            'transpose/ravel': a_np.T.ravel(),\n            'transpose/ravel (F-order)': a_np.T.ravel(order='F'),\n            'flatten': a_np.flatten(),\n            'transpose/flatten': a_np.T.flatten(),\n            'slicing': a_np[1:2:5],\n            'advanced indexing': a_np[[1, 3, 4]],\n            'combined indexing and slicing': a_np[[0, 2, 4], 1:3],\n            'Boolean indexing': a_np[[True, False, True, False, False]]\n            }\nfor title, b in attempts.items():\n    if b.base is None:\n        print(f'{title} produces a copy')\n    else:\n        print(f'{title} produces a view')\r\nВывод:\n\nreshape produces a view\ntranspose/reshape produces a view\nravel produces a view\ntranspose/ravel produces a copy\ntranspose/ravel (F-order) produces a view\nflatten produces a copy\ntranspose/flatten produces a copy\nslicing produces a view\nadvanced indexing produces a copy\ncombined indexing and slicing produces a copy\nBoolean indexing produces a copy\r\nПоведение некоторых функций не всегда одинаково. К примеру, numpy.ravel возвращает непрерывный уплощённый массив в качестве копии только при необходимости. И напротив, numpy.ndarray.flatten всегда возвращает копию массива, свёрнутую до одного измерения. Поведение numpy.reshape несколько запутанней, так что лучше почитать о ней в официальной документации.\n\r\nОсновной смысл здесь в том, что NumPy создаёт представления, в которых элементы адресуются по смещениям и шагам в исходном массиве, например, при базовом индексировании и получении среза. Такое поведение отличается от поведения списков Python. С другой стороны, при продвинутом индексировании всегда создаются копии. Операции изменения формы более сложны, и возвращение копии либо представления определяется контекстом.\n\r\nКопии, созданные в результате продвинутого индексирования, как и копии, полученные через numpy.copy, не подразумевают глубокого копирования мутабельных элементов внутри массивов. Как и поверхностные копии списков Python, копия массива NumPy содержит тот же самый объект, что может привести к неожиданностям, если этот объект допускает изменение (то есть мутабелен):\n\n\nprint('Numpy shallow copy')\na_np_demo = np.array([1, 2, [3, 4]], dtype=object)\nprint('a_np_demo (before) -> ', a_np_demo)\nb = np.copy(a_np_demo)\nb[0] = -1\nb[2][0] = -3\nprint('b                  -> ', b)\nprint('a_np_demo (after)  -> ', a_np_demo)\n\nfrom copy import deepcopy\nprint('\\nPython deep copy')\na_np_demo = np.array([1, 2, [3, 4]], dtype=object)\nprint('a_np_demo (before) -> ', a_np_demo)\nb2 = deepcopy(a_np_demo)\nb2[0] = -1\nb2[2][0] = -3\nprint('b2                 -> ', b2)\nprint('a_np_demo (after)  -> ', a_np_demo)\r\nВывод:\n\nNumpy shallow copy\na_np_demo (before) ->  [1 2 list([3, 4])]\nb                  ->  [-1 2 list([-3, 4])]\na_np_demo (after)  ->  [1 2 list([-3, 4])]\n\nPython deep copy\na_np_demo (before) ->  [1 2 list([3, 4])]\nb2                 ->  [-1 2 list([-3, 4])]\na_np_demo (after)  ->  [1 2 list([3, 4])]\r\nХотя это больше теоретический аспект, поскольку массивы NumPy обычно для хранения мутабельных объектов не используются. Но всё же будет нелишним знать, что copy.deepcopy() здесь тоже работает.\n\nДатафреймы pandas\r\nПо уже налаженной схеме мы определим датафрейм и вспомогательную функцию для вывода его описания.\n\nimport pandas as pd\nimport numpy as np\nimport sys\n\n\ndef show_details(a_df):\n    print('dataframe is\\n', a_df)\n    print(f'\\ndatatypes are {a_df.dtypes.unique()}')\n    print(f'number of bytes is {a_df.to_numpy().nbytes} bytes ({a_df.size} x 8 bytes)')\n    print(f'size is {sys.getsizeof(a_df)} bytes')\n    print(f\"pointer to data area {a_df.to_numpy().__array_interface__['data'][0]}\")\n\na_df = pd.DataFrame(np.random.randint(0, 10, (5,5), dtype='int64'),\n                    index = [f'r{i}' for i in range(5)],\n                    columns = [f'c{i}' for i in range(5)])\nshow_details(a_df)\r\nСтруктура этих данных совпадает со структурой массива NumPy, то есть в датафрейме присутствует 5х5 элементов int64, но вдобавок к ним мы определили индексы и имена столбцов. Вспомогательная функция была изменена. Датафреймы Pandas могут содержать в разных столбцах разные типы данных, поэтому мы возвращаем уникальные при помощи a_df.dtypes.unique(). Чтобы увидеть, когда содержащиеся данные копируются, а когда на них лишь даётся ссылка, мы сначала через a_df.to_numpy() получим внутренний массив NumPy, а затем используем интерфейс массива для получения указателя на первый элемент его данных.\n\r\nВывод:\n\nddataframe is\n     c0  c1  c2  c3  c4\nr0   5   2   8   6   6\nr1   1   9   1   1   1\nr2   0   7   6   3   7\nr3   7   4   9   5   2\nr4   5   8   3   7   1\n\ndatatypes are [dtype('int64')]\nnumber of bytes is 200 bytes (25 x 8 bytes)\nsize is 511 bytes\npointer to data area 2893487649296\r\nТеперь у нас есть всё необходимое для экспериментов с копиями и представлениями.\n\r\nГлядя на интерфейс API, можно найти функцию копирования датафрейма, получающую логический аргумент deep. Если он True (по умолчанию), создаётся новый объект с копией данных вызывающего объекта и индексами (это не глубокая копия в смысле copy.deepcopy() стандартной библиотеки; см. ниже). Эти данные и индексы можно изменить, не затронув исходный датафрейм. Если же deep = False, новый объект создаётся без копирования данных или индексов вызывающего объекта, то есть генерируются только ссылки на них. В таком случае любые изменения в данных оригинального датафрейма будут отражаться в его копии.\n\r\nПоэкспериментируем с представлением:\n\na_df_copy = a_df.copy(deep=False)\nshow_details(a_df_copy)\nprint(f'Same base: {a_df.to_numpy().base is a_df_copy.to_numpy().base}')\nprint(f'Same row index: {a_df.index is a_df_copy.index}')\nprint(f'Same column index: {a_df.columns is a_df_copy.columns}')\r\nВывод:\n\ndataframe is\n     c0  c1  c2  c3  c4\nr0   5   2   8   6   6\nr1   1   9   1   1   1\nr2   0   7   6   3   7\nr3   7   4   9   5   2\nr4   5   8   3   7   1\n\ndatatypes are [dtype('int64')]\nnumber of bytes is 200 bytes (25 x 8 bytes)\nsize is 511 bytes\npointer to data area 2893487649296\nSame base: True\nSame row index: True\nSame column index: True\r\nЗдесь видно, что область данных указывает на тот же адрес памяти, основой массива выступает тот же объект, и два указанных индекса представляют те же объекты.\n\r\nТеперь создадим копию (deep=True используется по умолчанию, но я включаю его для большей ясности).\n\na_df_copy = a_df.copy(deep=True)\nshow_details(a_df_copy)\nprint(f'Same base: {a_df.to_numpy().base is a_df_copy.to_numpy().base}')\nprint(f'Same row index: {a_df.index is a_df_copy.index}')\nprint(f'Same column index: {a_df.columns is a_df_copy.columns}')\r\nВывод:\n\ndataframe is\n     c0  c1  c2  c3  c4\nr0   5   2   8   6   6\nr1   1   9   1   1   1\nr2   0   7   6   3   7\nr3   7   4   9   5   2\nr4   5   8   3   7   1\n\ndatatypes are [dtype('int64')]\nnumber of bytes is 200 bytes (25 x 8 bytes)\nsize is 511 bytes\npointer to data area 2893487655536\nSame base: False\nSame row index: False\nSame column index: False\r\nЗдесь у копии уже используется иная основа, что также отражено в изменённом указателе на область данных. Помимо этого, мы создали новые объекты для двух индексов. Ещё раз напомню, что аналогично массивам NumPy при нахождении в датафрейме мутабельных элементов их изменение в копии приведёт к изменению оригинального датафрейма, как это показано ниже:\n\nimport re\n\n\na_df_demo = pd.DataFrame({'c1': [1, 2], 'c2': [3, {'key1': 'v', 'key2': 'v'}]})\nprint('a_df_demo (before) ->', re.sub(r'\\s+', ' ', str(a_df_demo)))\n# make a copy\nb = a_df_demo.copy(deep=True)\n# remove one key-value pair from the dicitionary at iloc position (1, 1)\ndel b.iloc[1,1]['key2']\nprint('b                  ->', re.sub(r'\\s+', ' ', str(b)))\nprint('a_df_demo (after)  ->', re.sub(r'\\s+', ' ', str(b)))\r\nВывод:\n\na_df_demo (before) ->  c1 c2 0 1 3 1 2 {'key1': 'v', 'key2': 'v'}\nb                  ->  c1 c2 0 1 3 1 2 {'key1': 'v'}\na_df_demo (after)  ->  c1 c2 0 1 3 1 2 {'key1': 'v'}\r\nЭто не очень частый вариант использования датафреймов Pandas, но его всё же стоит иметь в виду. К сожалению, в Pandas невозможно сделать истинную глубокую копию, используя функцию copy.deepcopy() из стандартной библиотеки, поскольку разработчики этой библиотеки реализовали pd.DataFrame.__deepcopy__() как pd.DataFrame.copy(deep=True). Не уверен, изменится ли это в будущем, но в любом случае данный приём считается антипаттерном. Pandas в этом плане отличается от NumPy.\n\r\nТеперь можно рассмотреть разные способы выбора строк и столбцов с помощью Pandas.\n\nattempts = {'select one column': a_df['c1'],\n            'select one column using []': a_df[['c1']],\n            'select one column with loc': a_df.loc[:, 'c1'],\n            'select columns with loc and slicing': a_df.loc[:, 'c1':'c3'],\n            'select columns with loc and fancy indexing': a_df.loc[:, ['c1', 'c2', 'c3']],\n            'select rows using loc and a Boolean mask': a_df.loc[a_df['c1']>5],\n            'select rows with loc and slicing': a_df.loc['r1': 'r3'],\n            'chained indexing': a_df.loc['r1': 'r3']['c1'],\n            }\nfor title, b in attempts.items():\n    if a_df.to_numpy().base is not b.to_numpy().base:\n        print(f'{title} does not use the same base')\n    else:\n        print(f'{title} uses the same base')\r\nВывод:\n\nselect one column uses the same base\nselect one column using [] does not use the same base\nselect one column with loc uses the same base\nselect columns with loc and slicing uses the same base\nselect columns with loc and fancy indexing does not use the same base\nselect rows using loc and a Boolean mask does not use the same base\nselect rows with loc and slicing uses the same base\nchained indexing uses the same base\r\nПри базовом индексировании и получении срезов, например, в случае простого индексирования по столбцам с использованием квадратных скобок или аксессора .loc[], используется одна основа, но при остальных операциях это не так. В случае сомнений вышеприведённая схема вычислительных экспериментов позволит получить быстрый ответ.\n\r\nК сожалению, проверки неизменности основы не всегда достаточно для прогнозирования последствий использования цепного индексирования (см. ниже), но она даёт некоторое базовое понимание. В последней попытке основа остаётся прежней, но даже если мы используем это цепное индексирование для установки значений, исходный датафрейм останется неизменным. Хотя есть и обратный вариант: если основа изменяется, значит, мы работаем с копией. Здесь бы не помешали ваши комментарии, поскольку в этом вопросе я начинаю плавать.\n\r\nДалее же мы перейдём к заключительной теме, связанной с Pandas, а именно к пресловутому цепному индексированию и связанным с ним SettingWithCopyWarning. Используя ранее определённый датафрейм a_df, можно попробовать изменить значения конкретных элементов столбца при помощи логического индекса. Если предположить использование цепного индексирования, то на ум приходят два способа:\n\n# создание копии, чтобы не изменять исходный датафрейм\na_df_demo = a_df.copy(deep=True)\n\n# установка логического индекса\nmsk = a_df['c1']>5\n\n# attempt 1: сначала логическое индексирование (выдаёт SettingWithCopyWarning)\nprint('attempt 1')\na_df_demo.loc[msk]['c3'] = -1\nprint(a_df_demo)\n\n# attempt 2, логическое индексирование в конце\nprint('\\nattempt 2')\na_df_demo['c3'].loc[msk] = -1 # <- выдаёт предупреждение\nprint(a_df_demo)\r\nВывод:\n\nattempt 1\n    c0  c1  c2  c3  c4\nr0   5   2   8   6   6\nr1   1   9   1   1   1\nr2   0   7   6   3   7\nr3   7   4   9   5   2\nr4   5   8   3   7   1\n\nattempt 2\n    c0  c1  c2  c3  c4\nr0   5   2   8   6   6\nr1   1   9   1  -1   1\nr2   0   7   6  -1   7\nr3   7   4   9   5   2\nr4   5   8   3  -1   1\n\n<ipython-input-789-06440868e65b>:5: SettingWithCopyWarning:\nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  a_df_demo.loc[msk]['c3'] = -1\r\nЗдесь имеет значение порядок выполнения операций. Первая попытка приводит к выдаче SettingWithCopyWarning, что вполне ожидаемо. При использовании аксессора .loc[] с логической маской мы получаем копию. Присваивание элементам копии новых значений не ведёт к изменению исходного датафрейма. Это ожидаемое поведение, но Pandas, в отличие от NumPy, делает дополнительный шаг и даёт пользователю рекомендацию. Хотя даже в случае Pandas не стоит особо полагаться на такие предупреждения, поскольку выводятся они не всегда. К примеру,\n\na_df_demo = a_df.copy(deep=True)\na_df_demo.loc[['r1', 'r2', 'r3']]['c3'] = -1\nprint(a_df_demo)\r\nНе выдаёт предупреждения, хотя датафрейм не изменяется, что видно по выводу:\n\n    c0  c1  c2  c3  c4\nr0   5   2   8   6   6\nr1   1   9   1   1   1\nr2   0   7   6   3   7\nr3   7   4   9   5   2\nr4   5   8   3   7   1\r\nНужно ли всё это помнить? Не обязательно. Не только потому, что практически нереально перечислить все возможности цепного индексирования, но также ввиду отсутствия гарантии неизменности поведения в различных версиях Pandas при использовании SettingWithCopyWarning. Хуже того, может случиться так, что в одной версии датафрейм будет изменяться, а в другой нет (личных подтверждений этому у меня нет, просто опасения).\n\r\nИспользование виртуальной среды и настройка файла requirements.txt не только предотвратят ад зависимостей, но и защитят от подобных опасностей, хотя лучше всего знать, какие присваивания в Pandas представляют риски, чтобы их избегать. Ситуация дополнительно усложняется, когда датафрейм содержит иерархические индексы и разные типы данных. В таком случае пытаться предугадать результат цепного индексирования опасно.\n\r\nПравильным выходом будет избегать такого вида индексирования и использовать для установки значений один аксессор. Вот пример:\n\na_df_demo = a_df.copy(deep=True)\na_df_demo.loc['r1':'r2', 'c2'] = -1\nprint(a_df_demo)\r\nЭтот код выводит изменённый датафрейм, не выводя предупреждение.\n\n    c0  c1  c2  c3  c4\nr0   5   2   8   6   6\nr1   1   9  -1   1   1\nr2   0   7  -1   3   7\nr3   7   4   9   5   2\nr4   5   8   3   7   1\nТак весь смысл в использовании одного аксессора?\r\nИспользовать один аксессор и избегать цепного индексирования – это определённо надёжный совет, но есть тут и подвохи. Давайте создадим срез датафрейма и посмотрим, что с ним происходит при изменении исходных данных.\n\r\nПервая попытка подразумевает три подобных эксперимента.\n\n# -- NOT ALWAYS CHANGED --\nprint('experiment 1')\ndf = pd.DataFrame({\"a\": np.arange(4), \"b\": np.arange(4)})\nprint('data buffer pointer (before) ->', df.to_numpy().__array_interface__['data'][0])\nprint('data types (before) ->', df.dtypes.unique().tolist())\nmy_slice = df.loc[1:3]\nprint('my_slice (before) ->', my_slice.unstack().to_list())\n# Изменяет my_slice\ndf.loc[1, 'a'] = -10\nprint('data buffer pointer (after)  ->', df.to_numpy().__array_interface__['data'][0])\nprint('data types (after)  ->', df.dtypes.unique().tolist())\nprint('my_slice (after)  ->', my_slice.unstack().to_list())\n\nprint('experiment 2')\ndf = pd.DataFrame({\"a\": np.arange(4), \"b\": np.arange(4)})\nprint('data buffer pointer (before) ->', df.to_numpy().__array_interface__['data'][0])\nprint('data types (before) ->', df.dtypes.unique().tolist())\nmy_slice = df.loc[1:3]\nprint('my_slice (before) ->', my_slice.unstack().to_list())\n# Изменяет my_slice\ndf.loc[0:, 'a'] = -10\nprint('data buffer pointer (after)  ->', df.to_numpy().__array_interface__['data'][0])\nprint('data types (after)  ->', df.dtypes.unique().tolist())\nprint('my_slice (after)  ->', my_slice.unstack().to_list())\n\nprint('experiment 3')\ndf = pd.DataFrame({\"a\": np.arange(4), \"b\": np.arange(4)})\nprint('data buffer pointer (before) ->', df.to_numpy().__array_interface__['data'][0])\nprint('data types (before) ->', df.dtypes.unique().tolist())\nmy_slice = df.loc[1:3]\nprint('my_slice (before) ->', my_slice.unstack().to_list())\n# Не изменяет my_slice\ndf.loc[:, 'a'] = -10\nprint('data buffer pointer (after)  ->', df.to_numpy().__array_interface__['data'][0])\nprint('data types (after)  ->', df.dtypes.unique().tolist())\nprint('my_slice (after)  ->', my_slice.unstack().to_list())\r\nОтличаются эти эксперименты только способом изменения исходного датафрейма. Первый изменяет лишь один элемент столбца a, второй изменяет весь столбец a, а третий также изменяет весь этот столбец, но уже с помощью df.loc[:,'a'].\n\r\nВот вывод:\n\nexperiment 1\ndata buffer pointer (before) -> 2893435341184\ndata types (before) -> [dtype('int32')]\nmy_slice (before) -> [1, 2, 3, 1, 2, 3]\ndata buffer pointer (after)  -> 2893435341184\ndata types (after)  -> [dtype('int32')]\nmy_slice (after)  -> [-10, 2, 3, 1, 2, 3]\n\nexperiment 2\ndata buffer pointer (before) -> 2893490708496\ndata types (before) -> [dtype('int32')]\nmy_slice (before) -> [1, 2, 3, 1, 2, 3]\ndata buffer pointer (after)  -> 2893490708496\ndata types (after)  -> [dtype('int32')]\nmy_slice (after)  -> [-10, -10, -10, 1, 2, 3]\n\nexperiment 3\ndata buffer pointer (before) -> 2893435341184\ndata types (before) -> [dtype('int32')]\nmy_slice (before) -> [1, 2, 3, 1, 2, 3]\ndata buffer pointer (after)  -> 2893491528672\ndata types (after)  -> [dtype('int64'), dtype('int32')]\nmy_slice (after)  -> [1, 2, 3, 1, 2, 3]\r\nВ результате успешного изменения датафрейма его срез также изменяется только в первых двух экспериментах. Если посмотреть внимательно, тип одного из столбцов датафрейма изменился на int64, а его буфер данных переместился в памяти. Я думаю, что причина преобразования типа в изменении значения всего столбца a. В этом можно убедиться, если установить тип данных явно при создании датафрейма.\n\n# -- ALWAYS CHANGED --\nprint('experiment 1')\ndf = pd.DataFrame({\"a\": np.arange(4), \"b\": np.arange(4)}, dtype='int64')\nprint('data buffer pointer (before) ->', df.to_numpy().__array_interface__['data'][0])\nprint('data types (before) ->', df.dtypes.unique().tolist())\nmy_slice = df.loc[1:3]\nprint('my_slice (before) ->', my_slice.unstack().to_list())\n# Изменяет my_slice\ndf.loc[1, 'a'] = -10\nprint('data buffer pointer (after)  ->', df.to_numpy().__array_interface__['data'][0])\nprint('data types (after)  ->', df.dtypes.unique().tolist())\nprint('my_slice (after)  ->', my_slice.unstack().to_list())\n\nprint('experiment 2')\ndf = pd.DataFrame({\"a\": np.arange(4), \"b\": np.arange(4)}, dtype='int64')\nprint('data buffer pointer (before) ->', df.to_numpy().__array_interface__['data'][0])\nprint('data types (before) ->', df.dtypes.unique().tolist())\nmy_slice = df.loc[1:3]\nprint('my_slice (before) ->', my_slice.unstack().to_list())\n# Изменяет my_slice\ndf.loc[0:, 'a'] = -10\nprint('data buffer pointer (after)  ->', df.to_numpy().__array_interface__['data'][0])\nprint('data types (after)  ->', df.dtypes.unique().tolist())\nprint('my_slice (after)  ->', my_slice.unstack().to_list())\n\nprint('experiment 3')\ndf = pd.DataFrame({\"a\": np.arange(4), \"b\": np.arange(4)}, dtype='int64')\nprint('data buffer pointer (before) ->', df.to_numpy().__array_interface__['data'][0])\nprint('data types (before) ->', df.dtypes.unique().tolist())\nmy_slice = df.loc[1:3]\nprint('my_slice (before) ->', my_slice.unstack().to_list())\n# Не изменяет my_slice\ndf.loc[:, 'a'] = -10\nprint('data buffer pointer (after)  ->', df.to_numpy().__array_interface__['data'][0])\nprint('data types (after)  ->', df.dtypes.unique().tolist())\nprint('my_slice (after)  ->', my_slice.unstack().to_list())\r\nВывод:\n\nexperiment 1\ndata buffer pointer (before) -> 2893491528672\ndata types (before) -> [dtype('int64')]\nmy_slice (before) -> [1, 2, 3, 1, 2, 3]\ndata buffer pointer (after)  -> 2893491528672\ndata types (after)  -> [dtype('int64')]\nmy_slice (after)  -> [-10, 2, 3, 1, 2, 3]\n\nexperiment 2\ndata buffer pointer (before) -> 2893486517968\ndata types (before) -> [dtype('int64')]\nmy_slice (before) -> [1, 2, 3, 1, 2, 3]\ndata buffer pointer (after)  -> 2893486517968\ndata types (after)  -> [dtype('int64')]\nmy_slice (after)  -> [-10, -10, -10, 1, 2, 3]\n\nexperiment 3\ndata buffer pointer (before) -> 2893491528672\ndata types (before) -> [dtype('int64')]\nmy_slice (before) -> [1, 2, 3, 1, 2, 3]\ndata buffer pointer (after)  -> 2893491528672\ndata types (after)  -> [dtype('int64')]\nmy_slice (after)  -> [-10, -10, -10, 1, 2, 3]\r\nДумаю, нет особого смысла оставлять уже неактуальный срез, если только он не был явно скопирован с помощью df.loc[1:3].copy(). В противном случае всегда можно получить свежий срез датафрейма именно в момент необходимости. Хотя это вполне рабочий эксперимент, позволяющий лучше понять тему представлений и копий.\n\nЗаключение\r\nЧтобы понять, когда Python создаёт копии, а когда представления, необходима практика. Списки Python, массивы NumPy и датафреймы Pandas предлагают функции для создания копий и представлений, как это показано в таблице ниже.\n\n\nИнтерактивная версия доступна в оригинале статьи\n\r\nОднако самые важные выводы связаны с поведением инструкций присваивания на основе индексов при использовании массивов NumPy и датафреймов Pandas:\n\n\nцепное индексирование NumPy обычно вполне ясно: базовое индексирование даёт представления, а продвинутое возвращает копии, которые исключают изменение исходного массива в случае новых присваиваний. Это поведение несколько усложняется при использовании операций изменения формы (reshape);\nцепного индексирования в Pandas желательно избегать, используя вместо него один аксессор для всех присваиваний. Это касается даже тех случаев, когда поведение цепного индексирования, казалось бы, можно спрогнозировать.\n\r\nПонимать принцип создания представлений и копий очень важно, особенно при работе с крупными массивами и датафреймами. Надеюсь, эта статья послужит основой для дальнейшего изучения темы. Несомненно, некоторые аспекты я упустил, а некоторые — мог неверно понять сам. Буду признателен за ваши справедливые замечания и дополнения в комментариях, которые лишний раз подтвердят истинность изречения Альберта Эйнштейна.\n\n▍ Рекомендуемые материалы:\n\nПрекрасная статья (англ.) о вездесущем SettingWithCopyWarning в Pandas;\nДокументация Python по копиям и представлениям;\nДокументация Pandas по копиям и представлениям.\n\n",
        "meta_tags": [
            "ruvds_перевод",
            "python",
            "numpy",
            "pandas",
            "копирование данных",
            "датафреймы",
            "глубокое копирование"
        ]
    },
    {
        "publish_datetime": 1669975322.0,
        "author": null,
        "title": "Как NodeJS обрабатывает множественные запросы?",
        "title_image_url": "https://habrastorage.org/getpro/habr/upload_files/31b/c76/cfc/31bc76cfc8bbfbb1a1cc7fa40797bcdb.png",
        "raw_body": "<div xmlns=\"http://www.w3.org/1999/xhtml\"><p>Существует много путаницы по поводу конкурентности и параллелизма. Некоторые люди используют эти термины как взаимозаменяемые, но на самом деле они означают две разные вещи.</p><figure class=\"\"><img src=\"https://habrastorage.org/r/w1560/getpro/habr/upload_files/c53/8a7/b12/c538a7b12d4f6e40251c7b6288353996.png\" width=\"409\" height=\"365\" data-src=\"https://habrastorage.org/getpro/habr/upload_files/c53/8a7/b12/c538a7b12d4f6e40251c7b6288353996.png\"/><figcaption></figcaption></figure><h3>Конкурентность</h3><p>Конкурентность — это когда выполнение двух или более задач может начинаться, выполняться и завершаться в частично совпадающие (накладывающиеся друг на друга) периоды времени. Это вовсе не означает, что они будут выполняться одновременно, но их можно чередовать так, чтобы в любой момент времени всегда выполнялась одна задача.</p><p>Приведем пример</p><p>Официант принимает заказ от клиента со столика 1 и ждет, пока он будет готов.</p><figure class=\"full-width \"><img src=\"https://habrastorage.org/r/w1560/getpro/habr/upload_files/a7f/3d0/1e6/a7f3d01e61745e68b85177b4842c3ed7.png\" width=\"630\" height=\"525\" data-src=\"https://habrastorage.org/getpro/habr/upload_files/a7f/3d0/1e6/a7f3d01e61745e68b85177b4842c3ed7.png\"/><figcaption></figcaption></figure><p>После того как заказ будет готов, он выдает заказанные блюда клиентам. Затем переходит к следующему столу 2 клиента принимает заказ и идет на кухню, ожидая, пока он будет готов, после чего отдает еду клиенту.</p><figure class=\"full-width \"><img src=\"https://habrastorage.org/r/w1560/getpro/habr/upload_files/6ec/f93/ad9/6ecf93ad9a1a826e0d8ddf334d412c72.png\" width=\"608\" height=\"510\" data-src=\"https://habrastorage.org/getpro/habr/upload_files/6ec/f93/ad9/6ecf93ad9a1a826e0d8ddf334d412c72.png\"/><figcaption></figcaption></figure><p>Эффективно ли это? НЕТ, потому что официант ничем не занимается, пока заказ не будет готов.</p><figure class=\"full-width \"><img src=\"https://habrastorage.org/r/w1560/getpro/habr/upload_files/bc4/7f8/3bb/bc47f83bbf1b3ed7e9437c3f952f79c8.png\" width=\"627\" height=\"523\" data-src=\"https://habrastorage.org/getpro/habr/upload_files/bc4/7f8/3bb/bc47f83bbf1b3ed7e9437c3f952f79c8.png\"/><figcaption></figcaption></figure><p>Теперь официант идет к столу 1, принимает заказ и передает его на кухню, возвращается к столу 2, принимает заказ и передает его на кухню. Здесь официант не ждет, пока заказ будет готов, он идет принимать следующий заказ, пока еда готовится. Когда все будет готово, он подаст блюда на все столы. При этом, мы не увеличили количество официантов.</p><p>Аналогично происходит, когда мы не увеличиваем количество потоков, но ускоряем процесс, сокращая время простоя. Работа с множеством вещей в одно и то же время. Это процесс конкурентности.</p><figure class=\"\"><img src=\"https://habrastorage.org/r/w1560/getpro/habr/upload_files/57e/2dc/d50/57e2dcd50ed044d62c1f3395c5c15e70.png\" width=\"275\" height=\"183\" data-src=\"https://habrastorage.org/getpro/habr/upload_files/57e/2dc/d50/57e2dcd50ed044d62c1f3395c5c15e70.png\"/><figcaption></figcaption></figure><p>Пример: во время приготовления пищи вам звонят, вы отвечаете на звонок, в то же время раздается сигнал кухонной плиты, вы возвращаетесь, выключаете плиту и снова отвечаете на звонок.</p><p><strong>Вы не выполняете что-то одно, а делаете две вещи одновременно, но по очереди.</strong></p><h3>Параллелизм</h3><p>Параллелизм — это когда две или более задач могут действительно выполняться одновременно. Чтобы это произошло, задачи должны запускаться на разных процессорах или ядрах.</p><p>Приведем пример</p><figure class=\"full-width \"><img src=\"https://habrastorage.org/r/w1560/getpro/habr/upload_files/9af/162/fe1/9af162fe1c72b90bd9a9b692036a0221.png\" width=\"631\" height=\"520\" data-src=\"https://habrastorage.org/getpro/habr/upload_files/9af/162/fe1/9af162fe1c72b90bd9a9b692036a0221.png\"/><figcaption></figcaption></figure><p>Пока вы готовите еду, звонит телефон, ваша мама отвечает на звонок. Здесь две разные вещи происходят с двумя людьми, но в одно и то же время.</p><p><strong>Почему так важно понимать разницу?</strong></p><blockquote><p>Параллелизм важен, потому что он позволяет структурировать код таким образом, чтобы эффективно использовать ресурсы. Параллелизм важен, потому что он может значительно повысить производительность за счет выполнения нескольких действий одновременно.</p></blockquote><p>Если вы пишете код, который будет выполняться на одном процессоре или ядре, то вам необходимо знать о конкурентности. Если ваш код будет выполняться на нескольких процессорах или ядрах, то нужно рассмотреть параллелизм.</p><h3>Что такое однопоточный процесс?</h3><p>Однопоточный процесс — это выполнение запрограммированных инструкций в одной последовательности. Приложение имеет следующий набор инструкций:</p><p>Инструкция A</p><p>Инструкция B</p><p>Инструкция C</p><p>Если этот набор инструкций выполняется в однопоточном процессе, то это будет выглядеть следующим образом:</p><figure class=\"full-width \"><img src=\"https://habrastorage.org/r/w1560/getpro/habr/upload_files/e74/3ee/ffe/e743eeffe4db7b12702be471c63a6208.png\" width=\"828\" height=\"465\" data-src=\"https://habrastorage.org/getpro/habr/upload_files/e74/3ee/ffe/e743eeffe4db7b12702be471c63a6208.png\"/><figcaption></figcaption></figure><h3>Что такое многопоточный процесс?</h3><p>Многопоточный процесс — это выполнение запрограммированных инструкций в нескольких последовательностях. Поэтому инструкциям не придется ждать завершения, если только некоторые из них не сгруппированы в разные последовательности.</p><figure class=\"full-width \"><img src=\"https://habrastorage.org/r/w1560/getpro/habr/upload_files/f47/dc9/fb4/f47dc9fb4862ecd6321b856be06eed8a.png\" width=\"828\" height=\"465\" data-src=\"https://habrastorage.org/getpro/habr/upload_files/f47/dc9/fb4/f47dc9fb4862ecd6321b856be06eed8a.png\"/><figcaption></figcaption></figure><h3>Почему Node.js является однопоточным?</h3><p>NodeJS является однопоточной платформой. Это означает, что он может обрабатывать только один запрос за один раз.</p><p>Пример: Приняв заказ со стола 1 и передав его на кухню, официант идет к столу 2. В то время когда он принимает заказ со стола 2, еда для стола 1 уже готова, но официант не может сразу же подойти и передать готовое блюдо столу 1, он должен закончить обработку заказа со стола 2 и затем передать его на кухню. И только после этого он сможет передать готовое блюдо столу 1.</p><figure class=\"full-width \"><img src=\"https://habrastorage.org/r/w1560/getpro/habr/upload_files/f52/b64/462/f52b64462278e4c0beadb0de46c4c8c5.png\" width=\"622\" height=\"518\" data-src=\"https://habrastorage.org/getpro/habr/upload_files/f52/b64/462/f52b64462278e4c0beadb0de46c4c8c5.png\"/><figcaption></figcaption></figure><p>Веб-сервер NodeJS поддерживает ограниченный пул потоков (<code>limited Thread Pool</code>) для обслуживания клиентских запросов. Многочисленные клиенты делают множественные запросы к NodeJS-серверу. NodeJS получает эти запросы и помещает их в <code>EventQueue</code>.</p><p>Сервер NodeJS имеет внутренний компонент, называемый <code>EventLoop</code>, который представляет собой бесконечный цикл, принимающий запросы и обрабатывающий их. Этот EventLoop является однопоточным. Другими словами, <code>EventLoop</code> является слушателем для <code>EventQueue</code>.</p><h3>Как Node.js обрабатывает множественные запросы?</h3><p>Событийно-ориентированная модель очень эффективна и позволяет NodeJS с легкостью обрабатывать тысячи одновременных запросов.</p><p>Node.js использует две концепции</p><ul><li><p>Неблокирующий ввод/вывод</p></li><li><p>Асинхронный</p></li></ul><figure class=\"full-width \"><img src=\"https://habrastorage.org/r/w1560/getpro/habr/upload_files/fec/70b/c99/fec70bc99f77bf7a5d3f3d732135d4eb.png\" width=\"828\" height=\"650\" data-src=\"https://habrastorage.org/getpro/habr/upload_files/fec/70b/c99/fec70bc99f77bf7a5d3f3d732135d4eb.png\"/><figcaption></figcaption></figure><p>Всякий раз, когда клиент посылает запрос, одиночный поток будет отправлять этот запрос кому-то другому. Текущий поток не будет занят обработкой этого запроса. Существуют воркеры, работающие на сервере. Сервер посылает запрос воркеру, тот дальше пересылает его другому серверу и ждет ответа. Тем временем, если поступит еще один запрос, поток отправит его другому воркеру, а тот будет ждать ответа от другого сервера.</p><p>Таким образом, одиночный поток всегда будет доступен для приема запросов от клиента. Он не будет их блокировать.</p><h3>Чем NodeJS лучше традиционной многопоточной модели ответа на запрос?</h3><p>При традиционной многопоточной модели запросов/ответов каждый клиент получает отдельный поток, в то время как, как и в случае с NodeJS, более простые запросы обрабатываются непосредственно <code>EventLoop</code>. Это оптимизирует ресурсы пула потоков, и нет необходимости создавать потоки под каждый запрос клиента.</p><hr/><p>Скоро состоится открытое занятие, на котором обсудим проблему производительности в NodeJS. Найдем причины и способы ее решения. Если интересно, регистрируйтесь <a href=\"https://otus.pw/2Irh/\">по ссылке.</a></p><p></p></div>",
        "clean_body": "Существует много путаницы по поводу конкурентности и параллелизма. Некоторые люди используют эти термины как взаимозаменяемые, но на самом деле они означают две разные вещи.КонкурентностьКонкурентность — это когда выполнение двух или более задач может начинаться, выполняться и завершаться в частично совпадающие (накладывающиеся друг на друга) периоды времени. Это вовсе не означает, что они будут выполняться одновременно, но их можно чередовать так, чтобы в любой момент времени всегда выполнялась одна задача.Приведем примерОфициант принимает заказ от клиента со столика 1 и ждет, пока он будет готов.После того как заказ будет готов, он выдает заказанные блюда клиентам. Затем переходит к следующему столу 2 клиента принимает заказ и идет на кухню, ожидая, пока он будет готов, после чего отдает еду клиенту.Эффективно ли это? НЕТ, потому что официант ничем не занимается, пока заказ не будет готов.Теперь официант идет к столу 1, принимает заказ и передает его на кухню, возвращается к столу 2, принимает заказ и передает его на кухню. Здесь официант не ждет, пока заказ будет готов, он идет принимать следующий заказ, пока еда готовится. Когда все будет готово, он подаст блюда на все столы. При этом, мы не увеличили количество официантов.Аналогично происходит, когда мы не увеличиваем количество потоков, но ускоряем процесс, сокращая время простоя. Работа с множеством вещей в одно и то же время. Это процесс конкурентности.Пример: во время приготовления пищи вам звонят, вы отвечаете на звонок, в то же время раздается сигнал кухонной плиты, вы возвращаетесь, выключаете плиту и снова отвечаете на звонок.Вы не выполняете что-то одно, а делаете две вещи одновременно, но по очереди.ПараллелизмПараллелизм — это когда две или более задач могут действительно выполняться одновременно. Чтобы это произошло, задачи должны запускаться на разных процессорах или ядрах.Приведем примерПока вы готовите еду, звонит телефон, ваша мама отвечает на звонок. Здесь две разные вещи происходят с двумя людьми, но в одно и то же время.Почему так важно понимать разницу?Параллелизм важен, потому что он позволяет структурировать код таким образом, чтобы эффективно использовать ресурсы. Параллелизм важен, потому что он может значительно повысить производительность за счет выполнения нескольких действий одновременно.Если вы пишете код, который будет выполняться на одном процессоре или ядре, то вам необходимо знать о конкурентности. Если ваш код будет выполняться на нескольких процессорах или ядрах, то нужно рассмотреть параллелизм.Что такое однопоточный процесс?Однопоточный процесс — это выполнение запрограммированных инструкций в одной последовательности. Приложение имеет следующий набор инструкций:Инструкция AИнструкция BИнструкция CЕсли этот набор инструкций выполняется в однопоточном процессе, то это будет выглядеть следующим образом:Что такое многопоточный процесс?Многопоточный процесс — это выполнение запрограммированных инструкций в нескольких последовательностях. Поэтому инструкциям не придется ждать завершения, если только некоторые из них не сгруппированы в разные последовательности.Почему Node.js является однопоточным?NodeJS является однопоточной платформой. Это означает, что он может обрабатывать только один запрос за один раз.Пример: Приняв заказ со стола 1 и передав его на кухню, официант идет к столу 2. В то время когда он принимает заказ со стола 2, еда для стола 1 уже готова, но официант не может сразу же подойти и передать готовое блюдо столу 1, он должен закончить обработку заказа со стола 2 и затем передать его на кухню. И только после этого он сможет передать готовое блюдо столу 1.Веб-сервер NodeJS поддерживает ограниченный пул потоков (limited Thread Pool) для обслуживания клиентских запросов. Многочисленные клиенты делают множественные запросы к NodeJS-серверу. NodeJS получает эти запросы и помещает их в EventQueue.Сервер NodeJS имеет внутренний компонент, называемый EventLoop, который представляет собой бесконечный цикл, принимающий запросы и обрабатывающий их. Этот EventLoop является однопоточным. Другими словами, EventLoop является слушателем для EventQueue.Как Node.js обрабатывает множественные запросы?Событийно-ориентированная модель очень эффективна и позволяет NodeJS с легкостью обрабатывать тысячи одновременных запросов.Node.js использует две концепцииНеблокирующий ввод/выводАсинхронныйВсякий раз, когда клиент посылает запрос, одиночный поток будет отправлять этот запрос кому-то другому. Текущий поток не будет занят обработкой этого запроса. Существуют воркеры, работающие на сервере. Сервер посылает запрос воркеру, тот дальше пересылает его другому серверу и ждет ответа. Тем временем, если поступит еще один запрос, поток отправит его другому воркеру, а тот будет ждать ответа от другого сервера.Таким образом, одиночный поток всегда будет доступен для приема запросов от клиента. Он не будет их блокировать.Чем NodeJS лучше традиционной многопоточной модели ответа на запрос?При традиционной многопоточной модели запросов/ответов каждый клиент получает отдельный поток, в то время как, как и в случае с NodeJS, более простые запросы обрабатываются непосредственно EventLoop. Это оптимизирует ресурсы пула потоков, и нет необходимости создавать потоки под каждый запрос клиента.Скоро состоится открытое занятие, на котором обсудим проблему производительности в NodeJS. Найдем причины и способы ее решения. Если интересно, регистрируйтесь по ссылке.",
        "meta_tags": [
            "node.js",
            "множественные запросы",
            "обработка запросов",
            "performance",
            "производительность"
        ]
    },
    {
        "publish_datetime": 1669976776.0,
        "author": "Маршак Сергей",
        "title": "На каждой новой работе своих коллег я всегда учил именно этому",
        "title_image_url": null,
        "raw_body": "<div xmlns=\"http://www.w3.org/1999/xhtml\"><p>Я часто вливался в новые коллективы и всегда знал, что у меня есть <s>пара тузов в рукаве</s> несколько фишек, которые сделают жизнь сотрудника проще и/или лучше. Я решил собрать самое полезное из того, что я сам использую в браузере в максимально коротком тексте с примерами, так, будто я прямо сейчас кого-то обучаю, поэтому всё будет в виде практических упражнений.</p><details class=\"spoiler\"><summary>Только горячие клавиши win браузера: </summary><div class=\"spoiler__content\"><p>Закрепить (опция для вкладки) </p><p>Ctrl 1 - Ctrl 9</p><p>Ctrl 0 / + / -  </p><p>Ctrl tab / shift tab</p><p>Ctrl T / Ctrl shift T</p></div></details><h4>Закрепить (опция для вкладки) </h4><p>Если правой клавишей кликнуть на вкладку, то у вас выпадет меню, в котором вам надо нажать пункт \"Закрепить\". После чего вас ждёт следующая любопытная трансформация - размер вкладки уменьшится до размеров чуть больше фавикона и сама вкладка переедет на новое ПМЖ в крайнелевую часть очереди вкладок. Каждая следующая закреплённая вкладка будет вставать в конец этой очереди. По опыту скажу, что оптимальное количество закреплённых вкладок 5, далее просто кнопками неудобно переключать )</p><p>Сама по себе функция позволяет управляться с мессенджерами, почтами, джирами и прочими приложениями, с которыми ведётся наиболее частое взаимодействие.</p><h4>Ctrl 1 - Ctrl 9 </h4><p>Откройте побольше вкладок, штук 20 для начала, затем зажмите указательным пальцем одной руки клавишу Ктрл (Ctrl), а указательным пальцем второй руки по очереди нажимайте клавиши от 1 до 9 и смотрите, что происходит. От 1 до 8 всё будет понятно и предсказуемо, а при переходе с 8 до 9 можно немного потеряться, потому что переключение будет не на вкладку номер 9, а на самую последнюю вкладку, если об этом помнить, то можно сделать себе немножечко удобнее. <em>Функция удобна очень-очень в связке с закреплёнными вкладками. Например, на вкладке №1 у вас Тележенька и при помощи Ктрл+1 вы всегда можете вернуться в месенджер и вставить скопированный текст, изображение, ссылку, свериться с первоисточником или ещё чего.</em></p><h4>Ctrl 0 / Ctrl + / Ctrl - </h4><p>Если начать нажимать Ктрл0, то на ровном месте ничего не случится, но, если вы нажмете 3 раза Ктрл+, а потом 10 раз Ктрл-,то потом за один раз, через Ктрл0 вы можете вернуть масштаб к начальному, что тоже довольно удобно. Эта функция особенна популярна в бухгалтерии, делопроизводстве, логистике и т.д.</p><h4>Ctrl tab / Ctrl shift tab</h4><p>Есть много сценариев при которых приходится переключаться между вкладками туда-сюда, попробуйте перейти на какую-то вкладку посередине, а затем попробуйте разные сочетания Ctrl tab / Ctrl shift tab одной рукой и двумя - как вам удобнее? Сильно экономит время на использование тачпада</p><h4>Ctrl T / Ctrl shift T</h4><p>Ну, и \"Сладкая парочка\": открыть новую вкладку (не так интересно) и открыть последнюю закрытую вкладку (очень интересно). Даже если вы закрыли дополнительное окно с несколькими вкладками, а потом закрыли вкладку в основном окне, то пара нажатий Ctrl shift T вернёт всё на место.</p><p>Потренеруйтесь сами и помогите своим коллегам, помните, использование клавиатуры почти всегда удобнее, чем аналогичное действие выполгненное мышью или тачпадом.</p><p></p></div>",
        "clean_body": "Я часто вливался в новые коллективы и всегда знал, что у меня есть пара тузов в рукаве несколько фишек, которые сделают жизнь сотрудника проще и/или лучше. Я решил собрать самое полезное из того, что я сам использую в браузере в максимально коротком тексте с примерами, так, будто я прямо сейчас кого-то обучаю, поэтому всё будет в виде практических упражнений.Только горячие клавиши win браузера: Закрепить (опция для вкладки) Ctrl 1 - Ctrl 9Ctrl 0 / + / -  Ctrl tab / shift tabCtrl T / Ctrl shift TЗакрепить (опция для вкладки) Если правой клавишей кликнуть на вкладку, то у вас выпадет меню, в котором вам надо нажать пункт \"Закрепить\". После чего вас ждёт следующая любопытная трансформация - размер вкладки уменьшится до размеров чуть больше фавикона и сама вкладка переедет на новое ПМЖ в крайнелевую часть очереди вкладок. Каждая следующая закреплённая вкладка будет вставать в конец этой очереди. По опыту скажу, что оптимальное количество закреплённых вкладок 5, далее просто кнопками неудобно переключать )Сама по себе функция позволяет управляться с мессенджерами, почтами, джирами и прочими приложениями, с которыми ведётся наиболее частое взаимодействие.Ctrl 1 - Ctrl 9 Откройте побольше вкладок, штук 20 для начала, затем зажмите указательным пальцем одной руки клавишу Ктрл (Ctrl), а указательным пальцем второй руки по очереди нажимайте клавиши от 1 до 9 и смотрите, что происходит. От 1 до 8 всё будет понятно и предсказуемо, а при переходе с 8 до 9 можно немного потеряться, потому что переключение будет не на вкладку номер 9, а на самую последнюю вкладку, если об этом помнить, то можно сделать себе немножечко удобнее. Функция удобна очень-очень в связке с закреплёнными вкладками. Например, на вкладке №1 у вас Тележенька и при помощи Ктрл+1 вы всегда можете вернуться в месенджер и вставить скопированный текст, изображение, ссылку, свериться с первоисточником или ещё чего.Ctrl 0 / Ctrl + / Ctrl - Если начать нажимать Ктрл0, то на ровном месте ничего не случится, но, если вы нажмете 3 раза Ктрл+, а потом 10 раз Ктрл-,то потом за один раз, через Ктрл0 вы можете вернуть масштаб к начальному, что тоже довольно удобно. Эта функция особенна популярна в бухгалтерии, делопроизводстве, логистике и т.д.Ctrl tab / Ctrl shift tabЕсть много сценариев при которых приходится переключаться между вкладками туда-сюда, попробуйте перейти на какую-то вкладку посередине, а затем попробуйте разные сочетания Ctrl tab / Ctrl shift tab одной рукой и двумя - как вам удобнее? Сильно экономит время на использование тачпадаCtrl T / Ctrl shift TНу, и \"Сладкая парочка\": открыть новую вкладку (не так интересно) и открыть последнюю закрытую вкладку (очень интересно). Даже если вы закрыли дополнительное окно с несколькими вкладками, а потом закрыли вкладку в основном окне, то пара нажатий Ctrl shift T вернёт всё на место.Потренеруйтесь сами и помогите своим коллегам, помните, использование клавиатуры почти всегда удобнее, чем аналогичное действие выполгненное мышью или тачпадом.",
        "meta_tags": [
            "браузеры",
            "продуктивность",
            "продуктивная работа",
            "продуктивность работы"
        ]
    },
    {
        "publish_datetime": 1669977027.0,
        "author": null,
        "title": "Вам нужен чистый код? Используйте правило шести",
        "title_image_url": null,
        "raw_body": "<div xmlns=\"http://www.w3.org/1999/xhtml\"><div style=\"text-align:center;\"><img src=\"https://habrastorage.org/r/w1560/webt/c_/8p/zg/c_8pzgajvfr462ecfc46npo5gw4.png\" data-src=\"https://habrastorage.org/webt/c_/8p/zg/c_8pzgajvfr462ecfc46npo5gw4.png\"/></div><br/>\r\nВсе хотят писать чистый код. Этому посвящены целые книги.<br/>\r\n<br/>\r\nНо вам не нужно читать книги, чтобы начать писать более чистый код прямо сейчас. Есть одна «хитрость», которой может научиться любой кодер, она делает код гораздо менее запутанным.<br/>\r\n<br/>\r\nРешение таково:<br/>\r\n<br/>\r\n<h2>Каждая строка делает только одно действие</h2><br/>\r\nОдна строка, одна задача.<br/>\r\n<br/>\r\nНо не стоит слишком перебарщивать.<br/>\r\n<a name=\"habracut\"></a><br/>\r\n<div style=\"text-align:center;\"><img src=\"https://habrastorage.org/r/w1560/webt/b4/kg/c6/b4kgc6wsg8igim0fzotjiorvhfy.png\" data-src=\"https://habrastorage.org/webt/b4/kg/c6/b4kgc6wsg8igim0fzotjiorvhfy.png\"/></div><br/>\r\n<i>«Катя, я вижу строку, которая выполняет два действия. Два действия, Катя!» Не становитесь таким.</i><br/>\r\n<br/>\r\nВот в чём заключается основной смысл: для понимания коротких строк кода требуется меньше мыслительных усилий, чем для понимания длинных. Над кодом, который легко читать, легче думать. Программы с короткими строками, в теории, проще поддерживать.<br/>\r\n<br/>\r\nОднако компактный код может быть непонятным. (Слыхали об <a href=\"https://en.wikipedia.org/wiki/APL_(programming_language)\">APL</a>?) И <em>возможность</em> разбиения строки не означает, что это нужно делать обязательно.<br/>\r\n<br/>\r\nВ некоторых языках можно присвоить два значения двум переменным в одной строке:<br/>\r\n<br/>\r\n<pre><code class=\"python\">x, y = 2, 7</code></pre><br/>\r\n<em>Можно</em> поместить каждое из присвоений в отдельную строку:<br/>\r\n<br/>\r\n<pre><code class=\"python\">x = 2\ny = 7</code></pre><br/>\r\nНо действительно ли это <em>необходимо</em>? Как решить, нужно ли разбивать строку?<br/>\r\n<br/>\r\n<h2>Дело не только в длине строки</h2><br/>\r\nВ начале своей книги <em><a href=\"https://www.manning.com/books/the-programmers-brain?utm_source=somacdivad&amp;amp;utm_medium=affiliate&amp;amp;utm_campaign=book_hermans2_programmers_12_8_20&amp;amp;a_aid=somacdivad&amp;amp;a_bid=d7c7c538\">The Programmer's Brain</a></em> Фелиен Херманс сообщает бесспорный факт: «Неразбериха — это часть программирования».<br/>\r\n<br/>\r\n<div style=\"text-align:center;\"><img src=\"https://habrastorage.org/r/w1560/webt/wz/uc/oc/wzucoc6kzqludtllsujtd7l8yy4.png\" data-src=\"https://habrastorage.org/webt/wz/uc/oc/wzucoc6kzqludtllsujtd7l8yy4.png\"/></div><br/>\r\n<i>«А-а-а, что это вообще означает?» Возможно, это означает, что пора сделать перерыв.</i><br/>\r\n<br/>\r\nВ книге Херманс (которую я крайне вам рекомендую) объясняется, как три функции памяти работают при понимании кода:<br/>\r\n<br/>\r\n<ul>\r\n<li><strong>Долговременная память (LTM):</strong> хранит информацию для долговременного поиска, например, ключевые слова, синтаксис, часто используемые идиомы и паттерны.</li>\r\n<li><strong>Кратковременная память (STM):</strong> хранит новую информацию для кратковременного поиска (менее 30 секунд!), например, имена переменных и специальные значения.</li>\r\n<li><strong>Рабочая память (WM):</strong> обрабатывает информацию из долговременной и кратковременной памяти, чтобы делать выводы и извлекать новое знание.</li>\r\n</ul><br/>\r\nКратковременная и рабочая память малы. И та, и другая могут хранить одновременно <a href=\"https://en.m.wikipedia.org/wiki/The_Magical_Number_Seven,_Plus_or_Minus_Two\">примерно 4-6 элементов</a>! Если перегрузить их, то вы сразу же запутаетесь.<br/>\r\n<br/>\r\n<div style=\"text-align:center;\"><img src=\"https://habrastorage.org/r/w1560/webt/c_/8p/zg/c_8pzgajvfr462ecfc46npo5gw4.png\" data-src=\"https://habrastorage.org/webt/c_/8p/zg/c_8pzgajvfr462ecfc46npo5gw4.png\"/></div><br/>\r\n<i>Как мозг обрабатывает информацию.</i><br/>\r\n<br/>\r\nЭто даёт нам правило определения того, не является ли строка кода слишком сложной:<br/>\r\n<br/>\r\n<strong>Правило шести:</strong> строку кода, содержащую больше шести элементов информации, следует упростить.<br/>\r\n<br/>\r\nВот пример на Python:<br/>\r\n<br/>\r\n<pre><code class=\"python\">map(lambda x: x.split('=')[1], s.split('?')[1].split('&amp;')[-3:])</code></pre><br/>\r\nВам сложно прочитать эту строку? Мне тоже. И на то есть причина.<br/>\r\n<br/>\r\nВам нужно знать, что такое <code>map</code>, <code>lambda</code> и <code>.split()</code>. Переменные <code>x</code> и <code>s</code>, строки <code>'='</code>, <code>'?'</code> и <code>'&amp;'</code>, индекс <code>[1]</code>, и слайс <code>[-3:]</code> занимают место в кратковременной и рабочей памяти. Суммарно это десять элементов! Мозг этого не выдерживает.<br/>\r\n<br/>\r\nХотя, возможно <em>ваш</em> может.<br/>\r\n<br/>\r\nЕсли это так, то вы, должно быть, обладаете хорошим опытом.<br/>\r\n<br/>\r\nВаш мозг разбивает синтаксис вида <code>s.split('?')[1]</code> на «часть строки справа от вопросительного знака». И вы можете воссоздать код на основе информации, хранящейся в долговременной памяти. Но вы всё равно обрабатываете за раз только небольшое количество фрагментов.<br/>\r\n<br/>\r\nИтак, мы можем определить, когда строка кода слишком сложна. Но что дальше?<br/>\r\n<br/>\r\n<h2>Если код запутывает, разбивайте его на части</h2><br/>\r\nРазбейте его на меньшие части, вот и всё.<br/>\r\n<br/>\r\nДля разбиения кода я использую две стратегии. Я назвал их SIMPLE и MORF.<br/>\r\n<br/>\r\nСтратегия <strong>SIMPLE</strong> <em>добавляет</em> строки кода для <em>снижения</em> когнитивной нагрузки.<br/>\r\n<br/>\r\n<div style=\"text-align:center;\"><img src=\"https://habrastorage.org/r/w1560/webt/ya/h1/zc/yah1zclx2cuqmjhzxuk2lniychm.png\" data-src=\"https://habrastorage.org/webt/ya/h1/zc/yah1zclx2cuqmjhzxuk2lniychm.png\"/></div><br/>\r\n<i>Разбить на несколько строк</i><br/>\r\n<br/>\r\nДавайте применим SIMPLE к той строке, которую рассматривали выше. Уберём второй аргумент из <code>map()</code> и вставим его в отдельную строку:<br/>\r\n<br/>\r\n<pre><code class=\"python\">query_params = s.split('?')[1].split('&amp;')[-3:]\nmap(lambda x: x.split('=')[1], query_params)</code></pre><br/>\r\nВозможно, код по-прежнему сложно читать. В первой строке нужно отслеживать семь элементов:<br/>\r\n<br/>\r\n<ul>\r\n<li><code>query_params</code></li>\r\n<li><code>s</code></li>\r\n<li><code>.split()</code></li>\r\n<li><code>'?'</code></li>\r\n<li><code>[1]</code></li>\r\n<li><code>'&amp;'</code></li>\r\n<li><code>[-3:]</code></li>\r\n</ul><br/>\r\nНо в каждой строке теперь нужно отслеживать меньше элементов, чем раньше. Вашему мозгу будет проще их обрабатывать.<br/>\r\n<br/>\r\nПрименим SIMPLE ещё раз и переместим <code>s.split('?')[1]</code> в новую строку:<br/>\r\n<br/>\r\n<pre><code class=\"python\">url_query_string = s.split('?')[1]\nquery_params = url_query_string.split('&amp;')[-3:]\nmap(lambda x: x.split('=')[1], query_params)</code></pre><br/>\r\nСравните это с исходным однострочным кодом. Какой из них проще обработать?<br/>\r\n<br/>\r\nВ стратегии <strong>MORF</strong> используется другой подход: код группируется в функции.<br/>\r\n<br/>\r\n<div style=\"text-align:center;\"><img src=\"https://habrastorage.org/r/w1560/webt/pr/mt/us/prmtusp722fdzgrzxhibbomdpaw.png\" data-src=\"https://habrastorage.org/webt/pr/mt/us/prmtusp722fdzgrzxhibbomdpaw.png\"/></div><br/>\r\n<i>Вынести и переписать в виде функции.</i><br/>\r\n<br/>\r\nВот как выглядит использование MORF для нашей строки:<br/>\r\n<br/>\r\n<pre><code class=\"python\">def query_params(url):\n    return url.split('?')[1].split('&amp;')[-3:]\n\nmap(lambda x: x.split('=')[1], query_params(s))</code></pre><br/>\r\nТакже можно сочетать MORF и SIMPLE:<br/>\r\n<br/>\r\n<pre><code class=\"python\">def query_params(url):\n    query_string = url.split('?')[1]\n    return query_string.split('&amp;')[-3:]\n    \nmap(lambda x: x.split('=')[1], query_params(s))</code></pre><br/>\r\nЧтобы почувствовать смысл, вам необязательно понимать код. Мозгу проще обрабатывать каждую строку.<br/>\r\n<br/>\r\nНо есть и бонус!<br/>\r\n<br/>\r\nЕсли вы знаете, что рабочая и кратковременная память не перегружены, то будете знать, что любое непонимание возникает вследствие отсутствия информации в долговременной памяти.<br/>\r\n<br/>\r\nИными словами, SIMPLE и MORF не просто помогают писать более чистый код, но и позволяют выявлять пробелы в знаниях, которые можно закрыть при помощи практики.</div>",
        "clean_body": "\r\nВсе хотят писать чистый код. Этому посвящены целые книги.\n\r\nНо вам не нужно читать книги, чтобы начать писать более чистый код прямо сейчас. Есть одна «хитрость», которой может научиться любой кодер, она делает код гораздо менее запутанным.\n\r\nРешение таково:\n\nКаждая строка делает только одно действие\r\nОдна строка, одна задача.\n\r\nНо не стоит слишком перебарщивать.\n\n\n«Катя, я вижу строку, которая выполняет два действия. Два действия, Катя!» Не становитесь таким.\n\r\nВот в чём заключается основной смысл: для понимания коротких строк кода требуется меньше мыслительных усилий, чем для понимания длинных. Над кодом, который легко читать, легче думать. Программы с короткими строками, в теории, проще поддерживать.\n\r\nОднако компактный код может быть непонятным. (Слыхали об APL?) И возможность разбиения строки не означает, что это нужно делать обязательно.\n\r\nВ некоторых языках можно присвоить два значения двум переменным в одной строке:\n\nx, y = 2, 7\nМожно поместить каждое из присвоений в отдельную строку:\n\nx = 2\ny = 7\r\nНо действительно ли это необходимо? Как решить, нужно ли разбивать строку?\n\nДело не только в длине строки\r\nВ начале своей книги The Programmer's Brain Фелиен Херманс сообщает бесспорный факт: «Неразбериха — это часть программирования».\n\n\n«А-а-а, что это вообще означает?» Возможно, это означает, что пора сделать перерыв.\n\r\nВ книге Херманс (которую я крайне вам рекомендую) объясняется, как три функции памяти работают при понимании кода:\n\n\nДолговременная память (LTM): хранит информацию для долговременного поиска, например, ключевые слова, синтаксис, часто используемые идиомы и паттерны.\nКратковременная память (STM): хранит новую информацию для кратковременного поиска (менее 30 секунд!), например, имена переменных и специальные значения.\nРабочая память (WM): обрабатывает информацию из долговременной и кратковременной памяти, чтобы делать выводы и извлекать новое знание.\n\r\nКратковременная и рабочая память малы. И та, и другая могут хранить одновременно примерно 4-6 элементов! Если перегрузить их, то вы сразу же запутаетесь.\n\n\nКак мозг обрабатывает информацию.\n\r\nЭто даёт нам правило определения того, не является ли строка кода слишком сложной:\n\nПравило шести: строку кода, содержащую больше шести элементов информации, следует упростить.\n\r\nВот пример на Python:\n\nmap(lambda x: x.split('=')[1], s.split('?')[1].split('&')[-3:])\r\nВам сложно прочитать эту строку? Мне тоже. И на то есть причина.\n\r\nВам нужно знать, что такое map, lambda и .split(). Переменные x и s, строки '=', '?' и '&', индекс [1], и слайс [-3:] занимают место в кратковременной и рабочей памяти. Суммарно это десять элементов! Мозг этого не выдерживает.\n\r\nХотя, возможно ваш может.\n\r\nЕсли это так, то вы, должно быть, обладаете хорошим опытом.\n\r\nВаш мозг разбивает синтаксис вида s.split('?')[1] на «часть строки справа от вопросительного знака». И вы можете воссоздать код на основе информации, хранящейся в долговременной памяти. Но вы всё равно обрабатываете за раз только небольшое количество фрагментов.\n\r\nИтак, мы можем определить, когда строка кода слишком сложна. Но что дальше?\n\nЕсли код запутывает, разбивайте его на части\r\nРазбейте его на меньшие части, вот и всё.\n\r\nДля разбиения кода я использую две стратегии. Я назвал их SIMPLE и MORF.\n\r\nСтратегия SIMPLE добавляет строки кода для снижения когнитивной нагрузки.\n\n\nРазбить на несколько строк\n\r\nДавайте применим SIMPLE к той строке, которую рассматривали выше. Уберём второй аргумент из map() и вставим его в отдельную строку:\n\nquery_params = s.split('?')[1].split('&')[-3:]\nmap(lambda x: x.split('=')[1], query_params)\r\nВозможно, код по-прежнему сложно читать. В первой строке нужно отслеживать семь элементов:\n\n\nquery_params\ns\n.split()\n'?'\n[1]\n'&'\n[-3:]\n\r\nНо в каждой строке теперь нужно отслеживать меньше элементов, чем раньше. Вашему мозгу будет проще их обрабатывать.\n\r\nПрименим SIMPLE ещё раз и переместим s.split('?')[1] в новую строку:\n\nurl_query_string = s.split('?')[1]\nquery_params = url_query_string.split('&')[-3:]\nmap(lambda x: x.split('=')[1], query_params)\r\nСравните это с исходным однострочным кодом. Какой из них проще обработать?\n\r\nВ стратегии MORF используется другой подход: код группируется в функции.\n\n\nВынести и переписать в виде функции.\n\r\nВот как выглядит использование MORF для нашей строки:\n\ndef query_params(url):\n    return url.split('?')[1].split('&')[-3:]\n\nmap(lambda x: x.split('=')[1], query_params(s))\r\nТакже можно сочетать MORF и SIMPLE:\n\ndef query_params(url):\n    query_string = url.split('?')[1]\n    return query_string.split('&')[-3:]\n    \nmap(lambda x: x.split('=')[1], query_params(s))\r\nЧтобы почувствовать смысл, вам необязательно понимать код. Мозгу проще обрабатывать каждую строку.\n\r\nНо есть и бонус!\n\r\nЕсли вы знаете, что рабочая и кратковременная память не перегружены, то будете знать, что любое непонимание возникает вследствие отсутствия информации в долговременной памяти.\n\r\nИными словами, SIMPLE и MORF не просто помогают писать более чистый код, но и позволяют выявлять пробелы в знаниях, которые можно закрыть при помощи практики.",
        "meta_tags": [
            "python",
            "совершенный код",
            "чистый код",
            "программирование",
            "APL",
            "LTM",
            "мозг"
        ]
    },
    {
        "publish_datetime": 1669977809.0,
        "author": "Дмитрий Головин",
        "title": "Tensorflow: Используем трансферное обучение для классификации пневмонии и оптимизируем нашу модель",
        "title_image_url": "https://habrastorage.org/getpro/habr/upload_files/bfe/a2f/c11/bfea2fc11a4e95d20a7f20598c502803.png",
        "raw_body": "<div xmlns=\"http://www.w3.org/1999/xhtml\"><figure class=\"full-width \"><img src=\"https://habrastorage.org/r/w1560/getpro/habr/upload_files/bfe/a2f/c11/bfea2fc11a4e95d20a7f20598c502803.png\" width=\"780\" height=\"439\" data-src=\"https://habrastorage.org/getpro/habr/upload_files/bfe/a2f/c11/bfea2fc11a4e95d20a7f20598c502803.png\"/><figcaption></figcaption></figure><div class=\"persona\" persona=\"true\"><img persona=\"true\" class=\"image persona__image\" src=\"https://habrastorage.org/r/w780q1/getpro/habr/upload_files/c3c/29d/6a2/c3c29d6a21b2db5f985f37973f0f7968.jpg\" data-src=\"https://habrastorage.org/getpro/habr/upload_files/c3c/29d/6a2/c3c29d6a21b2db5f985f37973f0f7968.jpg\" data-blurred=\"true\"/><h5 class=\"persona__heading\" persona=\"true\">Автор статьи: Рустем Галиев</h5><p>IBM Senior DevOps Engineer &amp; Integration Architect</p></div><p>Привет, Хабр! На связи Рустем, IBM Senior DevOps Engineer &amp; Integration Architect.<br/><br/>Сегодня мы будем работать с открытым набором данных по рентгенографии грудной клетки которые, использовали для этого <a href=\"https://www.cell.com/cell/fulltext/S0092-8674%2818%2930154-5\">исследования</a>, с предварительно обученной моделью MobileNet_v2 для классификации изображений TensorFlow и переносом обучения для создания классификатора пневмонии, который работает с рентгенограммами грудной клетки.</p><p>Целью этой статьи является не столько получение навыков классификации изображений, а сколько понимание того, насколько легко вы можете создать соответствующую модель.</p><p>Я надеюсь, вам понравится это!</p><h3>Загрузка модулей и данных</h3><p>Я знаю, вы хотите сразу приступить к разработке методов обнаружения пневмонии, но сначала давайте импортируем некоторые необходимые модули:</p><pre><code class=\"python\">import numpy as np\nimport os\nimport pathlib\nimport matplotlib.pylab as plt\nimport tensorflow as tf\nimport tensorflow_hub as hub\nimport tensorflow_datasets as tfds\ntfds.disable_progress_bar()\nfrom tqdm import tqdm\nAUTOTUNE = tf.data.experimental.AUTOTUNE</code></pre><p>Теперь давайте загрузим данные в память.</p><pre><code class=\"python\">data_dir = pathlib.Path('tflite/images')\nimage_count_train = len(list(data_dir.glob('train/*/*.jpeg')))\nimage_count_test = len(list(data_dir.glob('test/*/*.jpeg')))\nimage_count_val = len(list(data_dir.glob('val/*/*.jpeg')))\nBATCH_SIZE = 32\nIMG_HEIGHT = 224\nIMG_WIDTH = 224\nIMG_SHAPE = (IMG_HEIGHT, IMG_WIDTH, 3)\nSTEPS_PER_EPOCH = np.ceil(image_count_train/BATCH_SIZE)\nEPOCHS = 10\nSAVED_MODEL = \"pneumonia_saved_model\"\n(image_count_test, image_count_train, image_count_val)</code></pre><p>Теперь, когда у нас есть все изображения BATCH_SIZE для обучения, мы настроим классы для обучения (метки):</p><pre><code class=\"python\">CLASS_NAMES = np.array([item.name for item in data_dir.glob('train/*') if item.name != \"LICENSE.txt\"])\nnum_classes = len(CLASS_NAMES)\nCLASS_NAMES</code></pre><p>Изображения находятся в папках train, test или val. Например, чтобы увидеть изображение, вам нужно выполнить:</p><pre><code class=\"python\">pneumonia = list(data_dir.glob('train/PNEUMONIA/*.jpeg'))\n\nfor image_path in pneumonia[:3]:\n    Image.open(str(image_path))</code></pre><h3>Создание наборов данных</h3><p>Теперь, когда все загружено, мы можем создать итераторы, которые будут давать каждому набор изображений для обучения. TensorFlow предлагает отличные утилиты для этой задачи в наборах данных TensorFlow:</p><pre><code class=\"python\">test_ds = tf.data.Dataset.list_files(str(data_dir/'test/*/*'))\ntrain_ds = tf.data.Dataset.list_files(str(data_dir/'train/*/*'))\nval_ds = tf.data.Dataset.list_files(str(data_dir/'val/*/*'))\nfor f in test_ds.take(5):\n  print(f.numpy())\n\nprint('Datasets loaded')</code></pre><p>На данном этапе мы видим, что у нас есть итераторы для каждой группы: обучение, тестирование и проверка. Теперь нам нужно сделать несколько вещей:</p><ul><li><p>Мы должны декодировать каждое изображение в каналы RGB.</p></li><li><p>Мы должны изменить размер каждого изображения до наших предопределенных размеров.</p></li><li><p>Для каждого изображения мы должны вычислить метку, дающую 1 одному классу и 0 другому.</p></li><li><p>Мы должны применить каждый из этих шагов к итераторам, чтобы мы могли перебирать изображения с измененными размерами с их метками.</p></li></ul><p>Для этих задач мы будем использовать следующие ютилити методы:</p><pre><code class=\"python\">def get_label(file_path):\n  parts = tf.strings.split(file_path, os.path.sep)\n  return parts[-2] == CLASS_NAMES[0]\n\ndef decode_img(img):\n  img = tf.image.decode_jpeg(img, channels=3)\n  img = tf.image.convert_image_dtype(img, tf.float32)\n  return tf.image.resize(img, [IMG_WIDTH, IMG_HEIGHT])\n\ndef process_path(file_path):\n  label = get_label(file_path)\n  img = tf.io.read_file(file_path)\n  img = decode_img(img)\n  return img, label\n\ndef format_image(image, label):\n    image = tf.image.resize(image, IMAGE_SIZE) / 255.0\n    return  image, label\n\n\nprint('Utility methods loaded!')</code></pre><p>Применив это к нашим итераторам, теперь мы можем итерировать тестовые примеры, чтобы они имели соответствующие шейпы:</p><pre><code class=\"python\">train_examples = train_ds.map(process_path, num_parallel_calls=AUTOTUNE)\ntest_examples = test_ds.map(process_path, num_parallel_calls=AUTOTUNE)\nvalidation_examples = val_ds.map(process_path, num_parallel_calls=AUTOTUNE)\nfor image, label in test_examples.take(5):\n  print(\"Image shape: \", image.numpy().shape)\n  print(\"Label: \", label.numpy())\n\n\nprint('Check the shapes!')</code></pre><p>Интересно отметить, что теперь каждая итерация набора данных выдает тензорное изображение и тензорную метку.</p><p>Теперь, на этом шаге, нам нужно пакетировать каждый набор данных, добавить кэш для повышения производительности и выполнить предварительную выборку по мере необходимости! Этот метод обычно повышает производительность пакетной обработки в 10 раз и взят непосредственно из учебника Google:</p><pre><code class=\"python\">def prepare_for_training(ds, cache=True, shuffle_buffer_size=1000):\n    if cache:\n        if isinstance(cache, str):\n            ds = ds.cache(cache)\n        else:\n            ds = ds.cache()\n    ds = ds.shuffle(buffer_size=shuffle_buffer_size)\n    ds = ds.repeat()\n    ds = ds.batch(BATCH_SIZE)\n    ds = ds.prefetch(buffer_size=AUTOTUNE)\n    return ds\n\ntrain_examples_dataset = prepare_for_training(train_examples)\ntest_examples_dataset = prepare_for_training(test_examples)\nvalidation_examples_dataset = prepare_for_training(validation_examples)</code></pre><p>Можем сделать вызов<br/><br/><code>image_batch, label_batch = next(iter(test_examples_dataset))</code></p><p><br/>Приступим к определению модели!</p><h3>Обучение модели</h3><p>Теперь, когда у нас есть итератор, все дело в модели!</p><p>Все, что нам нужно сделать, это поместить линейный классификатор поверх слоя <code>feature_extractor_layer</code> с помощью модуля Hub.</p><p>Для скорости мы начинаем с необучаемого feature_extractor_layer, но вы также можете включить тонкую настройку для большей точности.</p><p>Модули-концентраторы для TensorFlow 1.x здесь не будут работать, поэтому мы можем использовать один из следующих вариантов:</p><pre><code class=\"python\">module_selection = (\"mobilenet_v2\", 224, 1280) #or use [\"(\\\"mobilenet_v2\\\", 224, 1280)\", \"(\\\"inception_v3\\\", 299, 2048)\"] {type:\"raw\", allow-input: true}\n\nhandle_base, pixels, FV_SIZE = module_selection\n\nMODULE_HANDLE =\"https://tfhub.dev/google/tf2-preview/{}/feature_vector/4\".format(handle_base)\n\nIMAGE_SIZE = (pixels, pixels)\n\nprint(\"Using {} with input size {} and output dimension {}\".format(MODULE_HANDLE, IMAGE_SIZE, FV_SIZE))</code></pre><p>Обратите внимание, что мы используем вектор признаков, а не полную модель. Это потому, что мы не хотим тонкой настройки (для избежания проблем со временем). Однако, если вы хотите выполнить точную настройку, загрузите полную модель (она находится в TensorFlow Hub).</p><p>Загрузите модуль TFHub:</p><pre><code class=\"python\">feature_extractor = hub.KerasLayer(MODULE_HANDLE,\n                                   input_shape=IMAGE_SIZE + (3,),\n                                   output_shape=[FV_SIZE],\n                                   trainable=False)\nfeature_extractor.trainable = False\nprint(\"Building model with\", MODULE_HANDLE)\nmodel = tf.keras.Sequential([ feature_extractor, tf.keras.layers.Dense(num_classes, activation='softmax')])\nmodel.compile(optimizer='adam',\n                  loss='sparse_categorical_crossentropy',\n                  metrics=['accuracy'])\nmodel.summary()</code></pre><p>Как видите, большинство наших параметров не поддаются обучению (см. параметр из MobileNet), поэтому обучение должно быть быстрым. Для обучения нам потребуется запустить следующее:</p><pre><code class=\"python\">hist = model.fit(train_examples_dataset, epochs=EPOCHS, steps_per_epoch=image_count_train/BATCH_SIZE, validation_steps=np.floor(image_count_val/BATCH_SIZE), validation_data=validation_examples_dataset)\ntf.saved_model.save(model, SAVED_MODEL)</code></pre><p>Мы можем проверить, что модель имеет правильную подпись, загрузив ее снова и показав информацию:</p><pre><code class=\"python\">loaded = tf.saved_model.load(SAVED_MODEL)\nprint(list(loaded.signatures.keys()))\ninfer = loaded.signatures[\"serving_default\"]\nprint(infer.structured_input_signature)\nprint(infer.structured_outputs)</code></pre><p>Мы используем следующую команду, чтобы проверить, можете ли вы также использовать интерфейс командной строки TensorFlow для проверки подписи (вне Python):<br/><br/><code>saved_model_cli show --dir $1 --tag_set serve --signature_def serving_default</code></p><p><br/>Это было невероятно легко; с трансферным обучением мы можем легко, в четыре строки кода, проделать работу целых исследовательских групп!</p><p>Теперь, когда у нас есть рабочая модель, давайте перейдем к работе по ее оптимизации.</p><h4>Преобразование классификатора пневмонии TensorFlow в TensorFlow Lite с помощью квантования</h4><p>Мы можем легко преобразовать модель из обычного TensorFlow в TensorFlow Lite с помощью Python Converter API. Этот шаг необходим для запуска наших моделей на периферийных и мобильных устройствах.</p><h4>Квантование с помощью конвертера TensorFlow Lite</h4><p>Теперь, когда у нас есть сохраненный объект SavedModel, первое, что вам нужно сделать, чтобы преобразовать его в модель TensorFlow Lite, — создать экземпляр преобразователя:</p><pre><code class=\"python\">import numpy as np\nimport os\nimport pathlib\nimport matplotlib.pylab as plt\nimport tensorflow as tf\nimport tensorflow_hub as hub\nimport tensorflow_datasets as tfds\ntfds.disable_progress_bar()\nfrom tqdm import tqdm\nAUTOTUNE = tf.data.experimental.AUTOTUNE\n\nSAVED_MODEL = \"pneumonia_saved_model\"\nconverter = tf.lite.TFLiteConverter.from_saved_model(SAVED_MODEL)</code></pre><p>Помните, что мы можем создать конвертер из моделей SavedModel, ConcreteFunction или Keras!</p><h4>Квантование после обучения</h4><p>Простейшая форма квантования после обучения квантует от плавающей запятой до 8-битной точности. Этот метод включен в качестве опции в конвертере TensorFlow Lite. При выводе вес преобразуются из 8-битной точности в числа с плавающей запятой и вычисляются с использованием ядер с плавающей запятой. Это преобразование выполняется один раз и кэшируется для уменьшения задержки.</p><pre><code class=\"python\">converter.optimizations = [tf.lite.Optimize.DEFAULT]</code></pre><p>Эта оптимизация была сделана путем размышления между оптимизацией размера и задержки. Если бы мы хотели оптимизировать только размер, мы могли бы сделать следующее:</p><pre><code class=\"python\">converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]</code></pre><p>Точно так же мы можем преобразовать нашу модель, и она будет квантована:</p><pre><code class=\"python\">tflite_model = converter.convert()\ntflite_model_file = 'converted_model.tflite'\n\nwith open(tflite_model_file, \"wb\") as f:\n    f.write(tflite_model)\n\nprint('Done quantizing')</code></pre><p>Это было удивительно просто и быстро, хотя квантование модели звучит сложно и красиво на бэкэнде, но ее весьма легко реализовать.</p><p>Проверка уменьшения размера</p><p>Давайте проверим, что квантованная модель действительно меньше:</p><pre><code class=\"python\">from pathlib import Path\n\nsaved_model = Path(SAVED_MODEL)\nfull_model_size = sum(f.stat().st_size for f in saved_model.glob('**/*') if f.is_file() )/(1024*1024)\nprint(f'Full model size {full_model_size} MB')\nconverted_model = Path(tflite_model_file)\nconverted_model_size = converted_model.stat().st_size / (1024*1024)\nprint(f'Converted model size {converted_model_size} MB')</code></pre><figure class=\"full-width \"><img src=\"https://habrastorage.org/r/w1560/getpro/habr/upload_files/5b2/511/9a5/5b25119a5c36395ea8561a233b19d360.png\" width=\"940\" height=\"160\" data-src=\"https://habrastorage.org/getpro/habr/upload_files/5b2/511/9a5/5b25119a5c36395ea8561a233b19d360.png\"/><figcaption></figcaption></figure><p>Мы видим, что за одно простое квантование мы увеличили размер почти на 80%</p><p>Мы можем добиться дальнейшего улучшения задержки, сокращения пикового использования памяти и доступа к аппаратным ускорителям только для целых чисел, убедившись, что вся математика модели квантована. Для этого нам нужно измерить динамический диапазон активаций и входов с репрезентативным набором данных. Таким образом, вы просто создадите генератор входных данных и предоставите его вашему конвертеру:</p><p>Для этого сначала вернём наш тестовый набор данных:</p><pre><code class=\"python\">def get_label(file_path):\n  parts = tf.strings.split(file_path, os.path.sep)\n  return parts[-2] == CLASS_NAMES[0]\n\n@tf.autograph.experimental.do_not_convert\ndef decode_img(img):\n  img = tf.image.decode_jpeg(img, channels=3)\n  img = tf.image.convert_image_dtype(img, tf.float32)\n  return tf.image.resize(img, [IMG_WIDTH, IMG_HEIGHT])\n\n@tf.autograph.experimental.do_not_convert\ndef process_path(file_path):\n  label = get_label(file_path)\n  img = tf.io.read_file(file_path)\n  img = decode_img(img)\n  return img, label\n\ndef format_image(image, label):\n    image = tf.image.resize(image, IMAGE_SIZE) / 255.0\n    return  image, label\n\ndef prepare_for_training(ds, cache=True, shuffle_buffer_size=1000):\n    if cache:\n        if isinstance(cache, str):\n            ds = ds.cache(cache)\n        else:\n            ds = ds.cache()\n    ds = ds.shuffle(buffer_size=shuffle_buffer_size)\n    ds = ds.repeat()\n    ds = ds.batch(BATCH_SIZE)\n    ds = ds.prefetch(buffer_size=AUTOTUNE)\n    return ds\n\ndata_dir = pathlib.Path('tflite/images')\nBATCH_SIZE = 32\nIMG_HEIGHT = 224\nIMG_WIDTH = 224\nIMG_SHAPE = (IMG_HEIGHT, IMG_WIDTH, 3)\nCLASS_NAMES = np.array([item.name for item in data_dir.glob('train/*') if item.name != \"LICENSE.txt\"])\ntest_ds = tf.data.Dataset.list_files(str(data_dir/'test/*/*'))\ntest_examples = test_ds.map(process_path, num_parallel_calls=AUTOTUNE)\ntest_examples_dataset = prepare_for_training(test_examples)</code></pre><p>А теперь давайте определим репрезентативный набор данных. Это будет настроено на то, чтобы преобразователь выполнял некоторые выводы по мере квантования, чтобы поддерживать как можно большую точность, а также преобразовывать все возможные веса и активации в INT8:</p><pre><code class=\"python\">def representative_data_gen():\n    for image_batch, label_batch in test_examples_dataset.take(1):\n        for image in image_batch:\n            yield [[image]]\n\nlen(list(representative_data_gen()))\nconverter.representative_dataset = representative_data_gen</code></pre><p>Результирующая модель будет полностью квантована, но для удобства по-прежнему будет принимать входные и выходные данные с плавающей запятой.</p><p>Операции, которые не имеют квантованных реализаций, автоматически останутся с плавающей запятой. Это позволяет выполнять преобразование гладко, но может ограничивать развертывание ускорителями, поддерживающими float.<br/><br/><em>Полноцелочисленное квантование (необязательно, просто для знания)</em><br/><br/>Чтобы преобразователь выдавал только целочисленные операции, можно указать:<br/><br/><code>converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]</code></p><p><br/>Однако имейте в виду, что если преобразователь не может найти поддерживаемую INT8-совместимую операцию с вашей моделью, он не будет работать. Этот шаг обычно необязателен, но в некоторых случаях, например при развертывании на TPU, он необходим, поскольку это оборудование поддерживает только операции INT8.</p><p>Преобразование и проверка модели</p><p>Наконец, давайте преобразуем нашу модель:</p><pre><code class=\"python\">tflite_model = converter.convert()\ntflite_model_file = 'converted_model_int8.tflite'\n\nwith open(tflite_model_file, \"wb\") as f:\n    f.write(tflite_model)\n\nprint('Done quantizing with Representative Dataset')</code></pre><h3>Сравнение размеров</h3><p>Можно подумать, что новая переделанная модель меньше, но это не всегда так. Преобразование в операции INT8 в значительной степени сосредоточено на требованиях к памяти и скорости:</p><pre><code class=\"python\">from pathlib import Path\n\nquantized_weights = Path('converted_model.tflite')\nweights_quantized_size = quantized_weights.stat().st_size/(1024*1024)\nprint(f'Quantized for weights model size {weights_quantized_size} MB')\n\nweights_and_activations_model = Path('converted_model_int8.tflite')\nweights_and_activations_model_size = weights_and_activations_model.stat().st_size/(1024*1024)\nprint(f'Quantized for weights and activations size {weights_and_activations_model_size} MB')</code></pre><figure class=\"full-width \"><img src=\"https://habrastorage.org/r/w1560/getpro/habr/upload_files/714/431/c5a/714431c5a04434c45615d9a3f73b1735.png\" width=\"1183\" height=\"311\" data-src=\"https://habrastorage.org/getpro/habr/upload_files/714/431/c5a/714431c5a04434c45615d9a3f73b1735.png\"/><figcaption></figcaption></figure><p>И мы видим, что оба размера одинаковы. На следующем этапе мы рассмотрим, что происходит со скоростью!<br/><br/><strong>Протестируем модель TensorFlow Lite с помощью интерпретатора Python.</strong></p><p>Теперь, когда у нас есть наши квантованные модели, мы можем протестировать их и проверить их точность!</p><p>Во-первых, давайте загрузим квантованную модель весов. Для этого нам нужно выделить тензоры для прогнозов:</p><pre><code class=\"python\">weights_tflite_model_file = 'converted_model.tflite'\n\ninterpreter = tf.lite.Interpreter(model_path=weights_tflite_model_file)\ninterpreter.allocate_tensors()\n\ninput_index = interpreter.get_input_details()[0][\"index\"]\noutput_index = interpreter.get_output_details()[0][\"index\"]</code></pre><p>Теперь давайте создадим простую партию из 15 изображений (из соображений производительности) и проверим ее показатели:</p><pre><code class=\"python\">import time\nstart_time = time.time()\npredictions = []\n\ntest_labels, test_imgs = [], []\ndebug = 0\nimage_batch, label_batch = next(iter(test_examples_dataset))\nfor img, label in zip(image_batch, label_batch):\n    debug += 1\n    if debug % 5 == 1:\n        print(f'I am treating image {debug} with label {label}')\n    if debug == 15:\n        break\n    interpreter.set_tensor(input_index, np.array([img]))\n    interpreter.invoke()\n    predictions.append(interpreter.get_tensor(output_index))\n    test_labels.append(label.numpy())\n    test_imgs.append(img)\n\n\nprint(f'Predictions calculated in {time.time() - start_time} seconds')</code></pre><figure class=\"full-width \"><img src=\"https://habrastorage.org/r/w1560/getpro/habr/upload_files/252/a6a/ec4/252a6aec4d00041735380e9dddd5ba46.png\" width=\"1019\" height=\"574\" data-src=\"https://habrastorage.org/getpro/habr/upload_files/252/a6a/ec4/252a6aec4d00041735380e9dddd5ba46.png\"/><figcaption></figcaption></figure><p>Теперь у нас есть все прогнозы. Рассчитаем точность, чувствительность и специфичность:</p><pre><code class=\"python\">ok_value = 0\nwrong_value = 0\ntrue_positives = 0\ntotal = 0\ntrue_negatives = 0\nfalse_positives = 0\nfalse_negatives = 0\nfor predictions_array, true_label in zip(predictions, test_labels):\n    predicted_label = np.argmax(predictions_array)\n    if predicted_label == true_label:\n        ok_value += 1\n        if CLASS_NAMES[int(true_label)] == 'NORMAL':\n            true_negatives += 1\n        else:\n            true_positives += 1\n    else:\n        wrong_value += 1\n        if CLASS_NAMES[predicted_label] == 'NORMAL':\n            false_negatives +=1\n        else:\n            false_positives += 1\n    total += 1\n\n\nprint(f'Accuracy: {(true_positives + true_negatives) / total} \\n ')\nprint(f'Sensitivity: {true_positives/ (true_positives + false_negatives)} \\n ')\nprint(f'Specificity: {true_negatives / (true_negatives + false_positives)}')</code></pre><figure class=\"full-width \"><img src=\"https://habrastorage.org/r/w1560/getpro/habr/upload_files/006/349/dcc/006349dccbfa1b7fc2de5e4b21a5741f.png\" width=\"1110\" height=\"224\" data-src=\"https://habrastorage.org/getpro/habr/upload_files/006/349/dcc/006349dccbfa1b7fc2de5e4b21a5741f.png\"/><figcaption></figcaption></figure><p>Наша модель очень хороша: ее, наверное, можно было бы улучшить, но получить такой результат за 30 минут — это очень хорошо!</p><p>Теперь давайте проверим квантованную модель весов и активаций:</p><pre><code class=\"python\">weights_tflite_model_file = 'converted_model_int8.tflite'\n\ninterpreter = tf.lite.Interpreter(model_path=weights_tflite_model_file)\ninterpreter.allocate_tensors()\n\ninput_index = interpreter.get_input_details()[0][\"index\"]\noutput_index = interpreter.get_output_details()[0][\"index\"]</code></pre><p>Как и раньше, давайте создадим простую партию из 15 изображений (опять же, из соображений производительности) и проверим ее метрики:</p><pre><code class=\"python\">import  time\nstart_time = time.time()\npredictions = []\n\ntest_labels, test_imgs = [], []\ndebug = 0\nimage_batch, label_batch = next(iter(test_examples_dataset))\nfor img, label in zip(image_batch, label_batch):\n    debug += 1\n    if debug % 5 == 1:\n        print(f'I am treating image {debug} with label {label}')\n    if debug == 15:\n        break\n    interpreter.set_tensor(input_index, np.array([img]))\n    interpreter.invoke()\n    predictions.append(interpreter.get_tensor(output_index))\n    test_labels.append(label.numpy())\n    test_imgs.append(img)\n\n\nprint(f'Predictions calculated in {time.time()  -  start_time} seconds')</code></pre><figure class=\"full-width \"><img src=\"https://habrastorage.org/r/w1560/getpro/habr/upload_files/1e2/311/1a3/1e23111a3ee54c7158cdcb9596801924.png\" width=\"1078\" height=\"170\" data-src=\"https://habrastorage.org/getpro/habr/upload_files/1e2/311/1a3/1e23111a3ee54c7158cdcb9596801924.png\"/><figcaption></figcaption></figure><p>Теперь у нас есть все прогнозы. Рассчитаем точность, чувствительность и специфичность:</p><pre><code class=\"python\">ok_value = 0\nwrong_value = 0\ntrue_positives = 0\ntotal = 0\ntrue_negatives = 0\nfalse_positives = 0\nfalse_negatives = 0\nfor predictions_array, true_label in zip(predictions, test_labels):\n    predicted_label = np.argmax(predictions_array)\n    if predicted_label == true_label:\n        ok_value += 1\n        if CLASS_NAMES[int(true_label)] == 'NORMAL':\n            true_negatives += 1\n        else:\n            true_positives += 1\n    else:\n        wrong_value += 1\n        if CLASS_NAMES[predicted_label] == 'NORMAL':\n            false_negatives +=1\n        else:\n            false_positives += 1\n    total += 1\n\n\nprint(f'Accuracy: {(true_positives + true_negatives) / total} \\n ')\nprint(f'Sensitivity: {true_positives/ (true_positives + false_negatives)} \\n ')\nprint(f'Specificity: {true_negatives / (true_negatives + false_positives)}')</code></pre><figure class=\"full-width \"><img src=\"https://habrastorage.org/r/w1560/getpro/habr/upload_files/81b/805/f95/81b805f9575b5b43e2eaa92796e9ab27.png\" width=\"1151\" height=\"222\" data-src=\"https://habrastorage.org/getpro/habr/upload_files/81b/805/f95/81b805f9575b5b43e2eaa92796e9ab27.png\"/><figcaption></figcaption></figure><p>Мы видим, что, хотя модель с оптимизацией весов немного меньше и лучше, модель INT8 намного быстрее. Идея квантования INT8 состоит в том, чтобы потерять точность (немного) для увеличения скорости.<br/><br/>Резюмируя:</p><ul><li><p>Мы загрузили набор рентгеновских данных из репозитория лаборатории.</p></li><li><p>Мы создали данные наборы данных с помощью наборов данных TensorFlow, которые создают итераторы из наших изображений.</p></li><li><p>Мы узнали, как адаптировать эти наборы данных, сопоставив несколько методов, которые позволяли переформатировать изображения до 224 x 224 x 3 и возвращали правильную метку, причем все в пакетном режиме.</p></li><li><p>Мы создали, обучили и сохранили нашу модель с передачей обучения, используя MobileNet v2 и простой слой softmax над ним.</p></li><li><p>Мы квантовали сохраненную модель классификации пневмонии для весов в качестве оптимизации после обучения.</p></li><li><p>Мы подтвердили, что мы увеличиваем размер на 80%, просто делая это.</p></li><li><p>Мы узнали о квантовании активаций с репрезентативным набором данных и о квантовании с полным целым числом.</p></li><li><p>Мы оценили обе модели, чтобы проверить производительность.</p></li></ul><p>Так как статья подготовлена в преддверии старта курса <a href=\"https://otus.pw/DSuI/\">Machine Learning. Professional</a>, хочу пригласить всех на <a href=\"https://otus.pw/DSuI/\">бесплатный урок курса</a>, где преподаватели OTUS расскажут какие подходы к ансамблированию сегодня существуют в машинном обучении, как устроены такие популярные техники ансамблирования как Bagging, Random Forest и Gradient Boosting. Когда и как их стоит применять для решения ML-задач.</p><ul><li><p><a href=\"https://otus.pw/DSuI/\">Зарегистрироваться на бесплатный урок</a></p></li></ul><p></p></div>",
        "clean_body": "Автор статьи: Рустем ГалиевIBM Senior DevOps Engineer & Integration ArchitectПривет, Хабр! На связи Рустем, IBM Senior DevOps Engineer & Integration Architect.Сегодня мы будем работать с открытым набором данных по рентгенографии грудной клетки которые, использовали для этого исследования, с предварительно обученной моделью MobileNet_v2 для классификации изображений TensorFlow и переносом обучения для создания классификатора пневмонии, который работает с рентгенограммами грудной клетки.Целью этой статьи является не столько получение навыков классификации изображений, а сколько понимание того, насколько легко вы можете создать соответствующую модель.Я надеюсь, вам понравится это!Загрузка модулей и данныхЯ знаю, вы хотите сразу приступить к разработке методов обнаружения пневмонии, но сначала давайте импортируем некоторые необходимые модули:import numpy as np\nimport os\nimport pathlib\nimport matplotlib.pylab as plt\nimport tensorflow as tf\nimport tensorflow_hub as hub\nimport tensorflow_datasets as tfds\ntfds.disable_progress_bar()\nfrom tqdm import tqdm\nAUTOTUNE = tf.data.experimental.AUTOTUNEТеперь давайте загрузим данные в память.data_dir = pathlib.Path('tflite/images')\nimage_count_train = len(list(data_dir.glob('train/*/*.jpeg')))\nimage_count_test = len(list(data_dir.glob('test/*/*.jpeg')))\nimage_count_val = len(list(data_dir.glob('val/*/*.jpeg')))\nBATCH_SIZE = 32\nIMG_HEIGHT = 224\nIMG_WIDTH = 224\nIMG_SHAPE = (IMG_HEIGHT, IMG_WIDTH, 3)\nSTEPS_PER_EPOCH = np.ceil(image_count_train/BATCH_SIZE)\nEPOCHS = 10\nSAVED_MODEL = \"pneumonia_saved_model\"\n(image_count_test, image_count_train, image_count_val)Теперь, когда у нас есть все изображения BATCH_SIZE для обучения, мы настроим классы для обучения (метки):CLASS_NAMES = np.array([item.name for item in data_dir.glob('train/*') if item.name != \"LICENSE.txt\"])\nnum_classes = len(CLASS_NAMES)\nCLASS_NAMESИзображения находятся в папках train, test или val. Например, чтобы увидеть изображение, вам нужно выполнить:pneumonia = list(data_dir.glob('train/PNEUMONIA/*.jpeg'))\n\nfor image_path in pneumonia[:3]:\n    Image.open(str(image_path))Создание наборов данныхТеперь, когда все загружено, мы можем создать итераторы, которые будут давать каждому набор изображений для обучения. TensorFlow предлагает отличные утилиты для этой задачи в наборах данных TensorFlow:test_ds = tf.data.Dataset.list_files(str(data_dir/'test/*/*'))\ntrain_ds = tf.data.Dataset.list_files(str(data_dir/'train/*/*'))\nval_ds = tf.data.Dataset.list_files(str(data_dir/'val/*/*'))\nfor f in test_ds.take(5):\n  print(f.numpy())\n\nprint('Datasets loaded')На данном этапе мы видим, что у нас есть итераторы для каждой группы: обучение, тестирование и проверка. Теперь нам нужно сделать несколько вещей:Мы должны декодировать каждое изображение в каналы RGB.Мы должны изменить размер каждого изображения до наших предопределенных размеров.Для каждого изображения мы должны вычислить метку, дающую 1 одному классу и 0 другому.Мы должны применить каждый из этих шагов к итераторам, чтобы мы могли перебирать изображения с измененными размерами с их метками.Для этих задач мы будем использовать следующие ютилити методы:def get_label(file_path):\n  parts = tf.strings.split(file_path, os.path.sep)\n  return parts[-2] == CLASS_NAMES[0]\n\ndef decode_img(img):\n  img = tf.image.decode_jpeg(img, channels=3)\n  img = tf.image.convert_image_dtype(img, tf.float32)\n  return tf.image.resize(img, [IMG_WIDTH, IMG_HEIGHT])\n\ndef process_path(file_path):\n  label = get_label(file_path)\n  img = tf.io.read_file(file_path)\n  img = decode_img(img)\n  return img, label\n\ndef format_image(image, label):\n    image = tf.image.resize(image, IMAGE_SIZE) / 255.0\n    return  image, label\n\n\nprint('Utility methods loaded!')Применив это к нашим итераторам, теперь мы можем итерировать тестовые примеры, чтобы они имели соответствующие шейпы:train_examples = train_ds.map(process_path, num_parallel_calls=AUTOTUNE)\ntest_examples = test_ds.map(process_path, num_parallel_calls=AUTOTUNE)\nvalidation_examples = val_ds.map(process_path, num_parallel_calls=AUTOTUNE)\nfor image, label in test_examples.take(5):\n  print(\"Image shape: \", image.numpy().shape)\n  print(\"Label: \", label.numpy())\n\n\nprint('Check the shapes!')Интересно отметить, что теперь каждая итерация набора данных выдает тензорное изображение и тензорную метку.Теперь, на этом шаге, нам нужно пакетировать каждый набор данных, добавить кэш для повышения производительности и выполнить предварительную выборку по мере необходимости! Этот метод обычно повышает производительность пакетной обработки в 10 раз и взят непосредственно из учебника Google:def prepare_for_training(ds, cache=True, shuffle_buffer_size=1000):\n    if cache:\n        if isinstance(cache, str):\n            ds = ds.cache(cache)\n        else:\n            ds = ds.cache()\n    ds = ds.shuffle(buffer_size=shuffle_buffer_size)\n    ds = ds.repeat()\n    ds = ds.batch(BATCH_SIZE)\n    ds = ds.prefetch(buffer_size=AUTOTUNE)\n    return ds\n\ntrain_examples_dataset = prepare_for_training(train_examples)\ntest_examples_dataset = prepare_for_training(test_examples)\nvalidation_examples_dataset = prepare_for_training(validation_examples)Можем сделать вызовimage_batch, label_batch = next(iter(test_examples_dataset))Приступим к определению модели!Обучение моделиТеперь, когда у нас есть итератор, все дело в модели!Все, что нам нужно сделать, это поместить линейный классификатор поверх слоя feature_extractor_layer с помощью модуля Hub.Для скорости мы начинаем с необучаемого feature_extractor_layer, но вы также можете включить тонкую настройку для большей точности.Модули-концентраторы для TensorFlow 1.x здесь не будут работать, поэтому мы можем использовать один из следующих вариантов:module_selection = (\"mobilenet_v2\", 224, 1280) #or use [\"(\\\"mobilenet_v2\\\", 224, 1280)\", \"(\\\"inception_v3\\\", 299, 2048)\"] {type:\"raw\", allow-input: true}\n\nhandle_base, pixels, FV_SIZE = module_selection\n\nMODULE_HANDLE =\"https://tfhub.dev/google/tf2-preview/{}/feature_vector/4\".format(handle_base)\n\nIMAGE_SIZE = (pixels, pixels)\n\nprint(\"Using {} with input size {} and output dimension {}\".format(MODULE_HANDLE, IMAGE_SIZE, FV_SIZE))Обратите внимание, что мы используем вектор признаков, а не полную модель. Это потому, что мы не хотим тонкой настройки (для избежания проблем со временем). Однако, если вы хотите выполнить точную настройку, загрузите полную модель (она находится в TensorFlow Hub).Загрузите модуль TFHub:feature_extractor = hub.KerasLayer(MODULE_HANDLE,\n                                   input_shape=IMAGE_SIZE + (3,),\n                                   output_shape=[FV_SIZE],\n                                   trainable=False)\nfeature_extractor.trainable = False\nprint(\"Building model with\", MODULE_HANDLE)\nmodel = tf.keras.Sequential([ feature_extractor, tf.keras.layers.Dense(num_classes, activation='softmax')])\nmodel.compile(optimizer='adam',\n                  loss='sparse_categorical_crossentropy',\n                  metrics=['accuracy'])\nmodel.summary()Как видите, большинство наших параметров не поддаются обучению (см. параметр из MobileNet), поэтому обучение должно быть быстрым. Для обучения нам потребуется запустить следующее:hist = model.fit(train_examples_dataset, epochs=EPOCHS, steps_per_epoch=image_count_train/BATCH_SIZE, validation_steps=np.floor(image_count_val/BATCH_SIZE), validation_data=validation_examples_dataset)\ntf.saved_model.save(model, SAVED_MODEL)Мы можем проверить, что модель имеет правильную подпись, загрузив ее снова и показав информацию:loaded = tf.saved_model.load(SAVED_MODEL)\nprint(list(loaded.signatures.keys()))\ninfer = loaded.signatures[\"serving_default\"]\nprint(infer.structured_input_signature)\nprint(infer.structured_outputs)Мы используем следующую команду, чтобы проверить, можете ли вы также использовать интерфейс командной строки TensorFlow для проверки подписи (вне Python):saved_model_cli show --dir $1 --tag_set serve --signature_def serving_defaultЭто было невероятно легко; с трансферным обучением мы можем легко, в четыре строки кода, проделать работу целых исследовательских групп!Теперь, когда у нас есть рабочая модель, давайте перейдем к работе по ее оптимизации.Преобразование классификатора пневмонии TensorFlow в TensorFlow Lite с помощью квантованияМы можем легко преобразовать модель из обычного TensorFlow в TensorFlow Lite с помощью Python Converter API. Этот шаг необходим для запуска наших моделей на периферийных и мобильных устройствах.Квантование с помощью конвертера TensorFlow LiteТеперь, когда у нас есть сохраненный объект SavedModel, первое, что вам нужно сделать, чтобы преобразовать его в модель TensorFlow Lite, — создать экземпляр преобразователя:import numpy as np\nimport os\nimport pathlib\nimport matplotlib.pylab as plt\nimport tensorflow as tf\nimport tensorflow_hub as hub\nimport tensorflow_datasets as tfds\ntfds.disable_progress_bar()\nfrom tqdm import tqdm\nAUTOTUNE = tf.data.experimental.AUTOTUNE\n\nSAVED_MODEL = \"pneumonia_saved_model\"\nconverter = tf.lite.TFLiteConverter.from_saved_model(SAVED_MODEL)Помните, что мы можем создать конвертер из моделей SavedModel, ConcreteFunction или Keras!Квантование после обученияПростейшая форма квантования после обучения квантует от плавающей запятой до 8-битной точности. Этот метод включен в качестве опции в конвертере TensorFlow Lite. При выводе вес преобразуются из 8-битной точности в числа с плавающей запятой и вычисляются с использованием ядер с плавающей запятой. Это преобразование выполняется один раз и кэшируется для уменьшения задержки.converter.optimizations = [tf.lite.Optimize.DEFAULT]Эта оптимизация была сделана путем размышления между оптимизацией размера и задержки. Если бы мы хотели оптимизировать только размер, мы могли бы сделать следующее:converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]Точно так же мы можем преобразовать нашу модель, и она будет квантована:tflite_model = converter.convert()\ntflite_model_file = 'converted_model.tflite'\n\nwith open(tflite_model_file, \"wb\") as f:\n    f.write(tflite_model)\n\nprint('Done quantizing')Это было удивительно просто и быстро, хотя квантование модели звучит сложно и красиво на бэкэнде, но ее весьма легко реализовать.Проверка уменьшения размераДавайте проверим, что квантованная модель действительно меньше:from pathlib import Path\n\nsaved_model = Path(SAVED_MODEL)\nfull_model_size = sum(f.stat().st_size for f in saved_model.glob('**/*') if f.is_file() )/(1024*1024)\nprint(f'Full model size {full_model_size} MB')\nconverted_model = Path(tflite_model_file)\nconverted_model_size = converted_model.stat().st_size / (1024*1024)\nprint(f'Converted model size {converted_model_size} MB')Мы видим, что за одно простое квантование мы увеличили размер почти на 80%Мы можем добиться дальнейшего улучшения задержки, сокращения пикового использования памяти и доступа к аппаратным ускорителям только для целых чисел, убедившись, что вся математика модели квантована. Для этого нам нужно измерить динамический диапазон активаций и входов с репрезентативным набором данных. Таким образом, вы просто создадите генератор входных данных и предоставите его вашему конвертеру:Для этого сначала вернём наш тестовый набор данных:def get_label(file_path):\n  parts = tf.strings.split(file_path, os.path.sep)\n  return parts[-2] == CLASS_NAMES[0]\n\n@tf.autograph.experimental.do_not_convert\ndef decode_img(img):\n  img = tf.image.decode_jpeg(img, channels=3)\n  img = tf.image.convert_image_dtype(img, tf.float32)\n  return tf.image.resize(img, [IMG_WIDTH, IMG_HEIGHT])\n\n@tf.autograph.experimental.do_not_convert\ndef process_path(file_path):\n  label = get_label(file_path)\n  img = tf.io.read_file(file_path)\n  img = decode_img(img)\n  return img, label\n\ndef format_image(image, label):\n    image = tf.image.resize(image, IMAGE_SIZE) / 255.0\n    return  image, label\n\ndef prepare_for_training(ds, cache=True, shuffle_buffer_size=1000):\n    if cache:\n        if isinstance(cache, str):\n            ds = ds.cache(cache)\n        else:\n            ds = ds.cache()\n    ds = ds.shuffle(buffer_size=shuffle_buffer_size)\n    ds = ds.repeat()\n    ds = ds.batch(BATCH_SIZE)\n    ds = ds.prefetch(buffer_size=AUTOTUNE)\n    return ds\n\ndata_dir = pathlib.Path('tflite/images')\nBATCH_SIZE = 32\nIMG_HEIGHT = 224\nIMG_WIDTH = 224\nIMG_SHAPE = (IMG_HEIGHT, IMG_WIDTH, 3)\nCLASS_NAMES = np.array([item.name for item in data_dir.glob('train/*') if item.name != \"LICENSE.txt\"])\ntest_ds = tf.data.Dataset.list_files(str(data_dir/'test/*/*'))\ntest_examples = test_ds.map(process_path, num_parallel_calls=AUTOTUNE)\ntest_examples_dataset = prepare_for_training(test_examples)А теперь давайте определим репрезентативный набор данных. Это будет настроено на то, чтобы преобразователь выполнял некоторые выводы по мере квантования, чтобы поддерживать как можно большую точность, а также преобразовывать все возможные веса и активации в INT8:def representative_data_gen():\n    for image_batch, label_batch in test_examples_dataset.take(1):\n        for image in image_batch:\n            yield [[image]]\n\nlen(list(representative_data_gen()))\nconverter.representative_dataset = representative_data_genРезультирующая модель будет полностью квантована, но для удобства по-прежнему будет принимать входные и выходные данные с плавающей запятой.Операции, которые не имеют квантованных реализаций, автоматически останутся с плавающей запятой. Это позволяет выполнять преобразование гладко, но может ограничивать развертывание ускорителями, поддерживающими float.Полноцелочисленное квантование (необязательно, просто для знания)Чтобы преобразователь выдавал только целочисленные операции, можно указать:converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]Однако имейте в виду, что если преобразователь не может найти поддерживаемую INT8-совместимую операцию с вашей моделью, он не будет работать. Этот шаг обычно необязателен, но в некоторых случаях, например при развертывании на TPU, он необходим, поскольку это оборудование поддерживает только операции INT8.Преобразование и проверка моделиНаконец, давайте преобразуем нашу модель:tflite_model = converter.convert()\ntflite_model_file = 'converted_model_int8.tflite'\n\nwith open(tflite_model_file, \"wb\") as f:\n    f.write(tflite_model)\n\nprint('Done quantizing with Representative Dataset')Сравнение размеровМожно подумать, что новая переделанная модель меньше, но это не всегда так. Преобразование в операции INT8 в значительной степени сосредоточено на требованиях к памяти и скорости:from pathlib import Path\n\nquantized_weights = Path('converted_model.tflite')\nweights_quantized_size = quantized_weights.stat().st_size/(1024*1024)\nprint(f'Quantized for weights model size {weights_quantized_size} MB')\n\nweights_and_activations_model = Path('converted_model_int8.tflite')\nweights_and_activations_model_size = weights_and_activations_model.stat().st_size/(1024*1024)\nprint(f'Quantized for weights and activations size {weights_and_activations_model_size} MB')И мы видим, что оба размера одинаковы. На следующем этапе мы рассмотрим, что происходит со скоростью!Протестируем модель TensorFlow Lite с помощью интерпретатора Python.Теперь, когда у нас есть наши квантованные модели, мы можем протестировать их и проверить их точность!Во-первых, давайте загрузим квантованную модель весов. Для этого нам нужно выделить тензоры для прогнозов:weights_tflite_model_file = 'converted_model.tflite'\n\ninterpreter = tf.lite.Interpreter(model_path=weights_tflite_model_file)\ninterpreter.allocate_tensors()\n\ninput_index = interpreter.get_input_details()[0][\"index\"]\noutput_index = interpreter.get_output_details()[0][\"index\"]Теперь давайте создадим простую партию из 15 изображений (из соображений производительности) и проверим ее показатели:import time\nstart_time = time.time()\npredictions = []\n\ntest_labels, test_imgs = [], []\ndebug = 0\nimage_batch, label_batch = next(iter(test_examples_dataset))\nfor img, label in zip(image_batch, label_batch):\n    debug += 1\n    if debug % 5 == 1:\n        print(f'I am treating image {debug} with label {label}')\n    if debug == 15:\n        break\n    interpreter.set_tensor(input_index, np.array([img]))\n    interpreter.invoke()\n    predictions.append(interpreter.get_tensor(output_index))\n    test_labels.append(label.numpy())\n    test_imgs.append(img)\n\n\nprint(f'Predictions calculated in {time.time() - start_time} seconds')Теперь у нас есть все прогнозы. Рассчитаем точность, чувствительность и специфичность:ok_value = 0\nwrong_value = 0\ntrue_positives = 0\ntotal = 0\ntrue_negatives = 0\nfalse_positives = 0\nfalse_negatives = 0\nfor predictions_array, true_label in zip(predictions, test_labels):\n    predicted_label = np.argmax(predictions_array)\n    if predicted_label == true_label:\n        ok_value += 1\n        if CLASS_NAMES[int(true_label)] == 'NORMAL':\n            true_negatives += 1\n        else:\n            true_positives += 1\n    else:\n        wrong_value += 1\n        if CLASS_NAMES[predicted_label] == 'NORMAL':\n            false_negatives +=1\n        else:\n            false_positives += 1\n    total += 1\n\n\nprint(f'Accuracy: {(true_positives + true_negatives) / total} \\n ')\nprint(f'Sensitivity: {true_positives/ (true_positives + false_negatives)} \\n ')\nprint(f'Specificity: {true_negatives / (true_negatives + false_positives)}')Наша модель очень хороша: ее, наверное, можно было бы улучшить, но получить такой результат за 30 минут — это очень хорошо!Теперь давайте проверим квантованную модель весов и активаций:weights_tflite_model_file = 'converted_model_int8.tflite'\n\ninterpreter = tf.lite.Interpreter(model_path=weights_tflite_model_file)\ninterpreter.allocate_tensors()\n\ninput_index = interpreter.get_input_details()[0][\"index\"]\noutput_index = interpreter.get_output_details()[0][\"index\"]Как и раньше, давайте создадим простую партию из 15 изображений (опять же, из соображений производительности) и проверим ее метрики:import  time\nstart_time = time.time()\npredictions = []\n\ntest_labels, test_imgs = [], []\ndebug = 0\nimage_batch, label_batch = next(iter(test_examples_dataset))\nfor img, label in zip(image_batch, label_batch):\n    debug += 1\n    if debug % 5 == 1:\n        print(f'I am treating image {debug} with label {label}')\n    if debug == 15:\n        break\n    interpreter.set_tensor(input_index, np.array([img]))\n    interpreter.invoke()\n    predictions.append(interpreter.get_tensor(output_index))\n    test_labels.append(label.numpy())\n    test_imgs.append(img)\n\n\nprint(f'Predictions calculated in {time.time()  -  start_time} seconds')Теперь у нас есть все прогнозы. Рассчитаем точность, чувствительность и специфичность:ok_value = 0\nwrong_value = 0\ntrue_positives = 0\ntotal = 0\ntrue_negatives = 0\nfalse_positives = 0\nfalse_negatives = 0\nfor predictions_array, true_label in zip(predictions, test_labels):\n    predicted_label = np.argmax(predictions_array)\n    if predicted_label == true_label:\n        ok_value += 1\n        if CLASS_NAMES[int(true_label)] == 'NORMAL':\n            true_negatives += 1\n        else:\n            true_positives += 1\n    else:\n        wrong_value += 1\n        if CLASS_NAMES[predicted_label] == 'NORMAL':\n            false_negatives +=1\n        else:\n            false_positives += 1\n    total += 1\n\n\nprint(f'Accuracy: {(true_positives + true_negatives) / total} \\n ')\nprint(f'Sensitivity: {true_positives/ (true_positives + false_negatives)} \\n ')\nprint(f'Specificity: {true_negatives / (true_negatives + false_positives)}')Мы видим, что, хотя модель с оптимизацией весов немного меньше и лучше, модель INT8 намного быстрее. Идея квантования INT8 состоит в том, чтобы потерять точность (немного) для увеличения скорости.Резюмируя:Мы загрузили набор рентгеновских данных из репозитория лаборатории.Мы создали данные наборы данных с помощью наборов данных TensorFlow, которые создают итераторы из наших изображений.Мы узнали, как адаптировать эти наборы данных, сопоставив несколько методов, которые позволяли переформатировать изображения до 224 x 224 x 3 и возвращали правильную метку, причем все в пакетном режиме.Мы создали, обучили и сохранили нашу модель с передачей обучения, используя MobileNet v2 и простой слой softmax над ним.Мы квантовали сохраненную модель классификации пневмонии для весов в качестве оптимизации после обучения.Мы подтвердили, что мы увеличиваем размер на 80%, просто делая это.Мы узнали о квантовании активаций с репрезентативным набором данных и о квантовании с полным целым числом.Мы оценили обе модели, чтобы проверить производительность.Так как статья подготовлена в преддверии старта курса Machine Learning. Professional, хочу пригласить всех на бесплатный урок курса, где преподаватели OTUS расскажут какие подходы к ансамблированию сегодня существуют в машинном обучении, как устроены такие популярные техники ансамблирования как Bagging, Random Forest и Gradient Boosting. Когда и как их стоит применять для решения ML-задач.Зарегистрироваться на бесплатный урок",
        "meta_tags": [
            "tensorflow",
            "machine learning"
        ]
    },
    {
        "publish_datetime": 1669981516.0,
        "author": null,
        "title": "Основные трудности и ошибки при разработке дизайн-системы",
        "title_image_url": "https://habrastorage.org/getpro/habr/upload_files/dad/927/557/dad927557b4231ab1a74c96c3c7b2251.png",
        "raw_body": "<div xmlns=\"http://www.w3.org/1999/xhtml\"><p>Про то, что такое дизайн-система, как она должна работать, уже написано немало статей. Но зачастую авторы охватывают лишь какой-то отдельный аспект этой обширной темы. Я же, в свою очередь, хочу рассмотреть именно сам процесс создания дизайн-системы, основанный на опыте нашей команды, рассказать об основных трудностях, с которыми мы столкнулись и, возможно, предостеречь от распространённых ошибок, которые мы совершили на этом тернистом пути. А следовать ему или нет, решение остается за вами.</p><p>Ну что же, погнали…</p><h2>Немного теории</h2><p>Что же такое дизайн-система? Согласно определению из «Википедии»: «дизайн-система — набор компонентов, правил, предписаний и инструментов для повышения качества и скорости разработки продуктов». Тут особо и поспорить-то не с чем.</p><p>Я бы, условно, разделил дизайн-систему на две составляющие:</p><ul><li><p>визуальное представление (для дизайнеров);</p></li><li><p>техническая реализация (для разработчиков).</p></li></ul><p><strong>Визуальное представление</strong> — это набор компонентов, шрифтов, иконок, цветовых схем и так далее в условной Figma или Sketch. Эта часть разрабатывается и используется дизайнерами для быстрого проектирования и построения интерфейса.</p><p><strong>Техническая реализация</strong> — это зеркальное отражение визуального представления, но только в коде для разработчиков. В отличие от визуального представления, которое должно существовать в единственном экземпляре, технических реализаций может быть много — начиная от разделения по платформам (iOS, Android, Web), заканчивая разделением по конкретным фреймворкам (iOS: UIKit и SwiftUI; Android: XML/Layout и Compose, Web: Angular и React).</p><p>Дополнительно я бы разделил дизайн-системы ещё на две категории:</p><ul><li><p>локальные;</p></li><li><p>глобальные.</p></li></ul><figure class=\"full-width \"><img src=\"https://habrastorage.org/r/w1560/getpro/habr/upload_files/317/0d3/9c5/3170d39c512bf2b068376ce05c721773.png\" alt=\"Использование локальных и глобальных дизайн-систем\" title=\"Использование локальных и глобальных дизайн-систем\" width=\"1753\" height=\"915\" data-src=\"https://habrastorage.org/getpro/habr/upload_files/317/0d3/9c5/3170d39c512bf2b068376ce05c721773.png\"/><figcaption>Использование локальных и глобальных дизайн-систем</figcaption></figure><p><strong>Локальные дизайн-системы</strong> — это системы, которые разработаны и работают только на одном продукте компании. В большинстве проектов реализован данный подход.</p><p><strong>Глобальные дизайн-системы</strong> — концептуально почти ничем не отличают от локальных, за исключением того, что они создаются для группы продуктов, а это, в свою очередь, накладывает на них ряд дополнительных требований и ограничений.</p><p>Локальную дизайн-систему можно разрабатывать просто, как часть продукта без дополнительных расходов (вы просто складываете все ваши компоненты в одно место, объединяете общие компоненты между собой и подбиваете их под общую стилистику и гайдлайны вашей компании). Локальная дизайн система так или иначе появляется в любом проекте сама-собой, потому что дизайнерам и разработчикам нужно удобнее переиспользовать компоненты, чем каждый раз создавать новые. Но если вы все же хотите замахнуться на глобальную дизайн-систему, то она сама должна являться полноценным продуктом, которому вы будете посвящать большую часть времени команды. А потребителем продукта будет являться весьма искушённая публика — разработчики и дизайнеры.</p><blockquote><p>Если преследуем цель повысить узнаваемость продукта, можно обойтись и локальными дизайн-системами, которые просто будут объединены общими гайдлайнами. Например, посмотрим на продукты той же самой компании «Яндекс»: когда открываешь приложение «Яндекс.Go» и «Яндекс.Еда», визуально кажется, что продукты похожи, хотя это две независимые команды, с разными локальными дизайн системами, объединенными единой стилистикой. (возможно на данный момент уже что-то поменялось)</p></blockquote><p>Отлично, теперь можно переходить дальше.</p><h2>Знакомимся с задачей</h2><p>Перед моей командой была поставлена задача создания визуального представления и технической реализации дизайн-системы для крупного заказчика. Конечными потребителями должны были стать 15 миллионов пользователей. А использовать дизайн-систему должна была не одна команда, не две, а вся организация в целом.</p><h4>Проводим анализ аудитории</h4><p>Как мы помним, наша дизайн система - это самостоятельный продукт. И что же нам делать, когда мы приступаем к разработке продукта? Сразу бежать проектировать компоненты и писать код — конечно, нет! Нужно провести анализ аудитории, чтобы понять потребности других команд. Мы провели ряд опросов.</p><p><strong>Опрос №1. Для дизайнеров</strong></p><ul><li><p>какими инструментами проектирования пользуются;</p></li><li><p>какие подходы к построению дизайна используют;</p></li><li><p>количество дизайнеров в команде.</p></li></ul><p>Тут не было никаких откровений. Все дизайнеры пользовались Figma, подходы к проектированию у всех были плюс-минус одинаковыми. Но выяснился интересный факт, что в компании уже существует несколько локальных дизайн-систем, которые функционируют в рамках группы продуктов, но между собой они никак не связаны.</p><p>Задача перед дизайнерами была ясна и понятна: выбрать наиболее распространённую дизайн-систему и доработать её до того уровня, чтобы учитывать потребности всех остальных команд. Конечно, когда вы приходите на проект, хочется всё сжечь и сделать с нуля. Кажется, что так намного быстрее и правильнее, но как показывает практика - доработать и возможно немного переработать старое намного быстрее, чем разрабатывать с нуля.</p><p><strong>Опрос №2. Для разработчиков</strong></p><ul><li><p>минимальная поддерживаемая версия операционной системы;</p></li><li><p>какой стек технологий используется;</p></li><li><p>количество разработчиков в команде.</p></li></ul><p>После проведения опроса мы получили достаточно распространённую картину. Минимальные версии операционных систем у большинства команд были — iOS 11 и Android 5.0, стек стандартный: для iOS — UIKit, Android — Layout + XML.</p><figure class=\"full-width \"><img src=\"https://habrastorage.org/r/w1560/getpro/habr/upload_files/b7a/5ad/118/b7a5ad118f0a3637f02654e01809d8f7.png\" alt=\"Результаты опросов стека технологий в нашей компании\" title=\"Результаты опросов стека технологий в нашей компании\" width=\"1753\" height=\"1161\" data-src=\"https://habrastorage.org/getpro/habr/upload_files/b7a/5ad/118/b7a5ad118f0a3637f02654e01809d8f7.png\"/><figcaption>Результаты опросов стека технологий в нашей компании</figcaption></figure><p>Мы рассматриваем случай технического аспекта дизайн-системы для мобильной разработки, для веба всё плюс-минус аналогично.</p><p>Казалось бы, всё готово, статистика собрана, с командами пообщались, можно приниматься за разработку, но тут мы не учли один очень важный аспект, о котором поговорим далее.</p><h4>Не пытайтесь быть умнее пользователей</h4><p>Наша команда собрала статистку, учла все требования и пожелания и разработала первую версию библиотеки. Но мы не учли, что встретим серьёзное сопротивление со стороны большого числа других команд, работающими над продуктами с достаточно продолжительным жизненным циклом.</p><p>Виноваты ли были команды, что не хотели переходить на новую дизайн-систему? Конечно, нет! Только представьте, приходят к вам в команду незнакомые люди и говорят, что дизайнерам нужно полностью перевести дизайн на новые компоненты, а разработчикам полностью переписать весь код, связанный c UI, так потом ещё и провести полный регресс. Не знаю, кто бы на их месте ответил бы по-другому.</p><p>А что это значит? Что мы неправильно выбрали первоначальную аудиторию, на которую должны были ориентироваться. Ведь, как мы помним, дизайн-система должна ускорять процесс разработки продуктов, а не тормозить его. А для команд, которые уже давно работают над продуктом, предложенная новинка не принесёт никакой пользы, кроме огромного бэклога. Поэтому легче всего было пойти другим путём и найти молодые команды, которые только формировались и не имели полноценного дизайна, а разработка либо ещё не началась, либо была на начальном этапе.</p><figure class=\"full-width \"><img src=\"https://habrastorage.org/r/w1560/getpro/habr/upload_files/56a/a86/7fb/56aa867fb25e9d9c54236855f4c0b631.png\" alt=\"Результаты опросов стека технологий молодых проектов\" title=\"Результаты опросов стека технологий молодых проектов\" width=\"1753\" height=\"1161\" data-src=\"https://habrastorage.org/getpro/habr/upload_files/56a/a86/7fb/56aa867fb25e9d9c54236855f4c0b631.png\"/><figcaption>Результаты опросов стека технологий молодых проектов</figcaption></figure><p>Нам пришлось дополнить опрос и заново собрать статистику. Результат отличался. Если в случае с ОС от Google нам повезло и Android-сообщество использует в большинстве своём консервативные подходы к вёрстке — Layout + XML, то для iOS у новых команд был существенный перевес в сторону SwiftUI и для них это было важным критерием перехода на новую библиотеку.</p><p>Хорошо, что у нас было достаточно компетенции и команда быстро зарелизила новую версию под SwiftUI. Но из минусов остался тот факт, что нам до сих пор приходится поддерживать две версии библиотеки — SwiftUI и UIKit. А это в два раза больше работы.</p><p>Но нам нужно сохранять лояльность комьюнити, поэтому мы не бросаем поддержку UIKit, но все новые фичи в основном разрабатываем под SwiftUI.</p><h4>Внедряйте дизайн-систему небольшими шагами</h4><p>После того как мы провели опрос и реализовали базовую функциональность библиотеки, пришло время для её интеграции в другие продукты. К сожалению или радости, у нашей команды не было своего продукта, на котором можно в полной мере обкатать библиотеку.</p><p>Мы решили искать молодые команды, у которых только начиналась разработка нового продукта и у них не было времени на разработку собственной дизайн-системы. А главное, чтобы они были лояльны к багам и недоработкам в библиотеке.</p><p>Казалось бы, найти такие команды сложно. Но важно понять, что вы можете предложить взамен. Мы нашли компромисс: ребята использовали библиотеку, репортили о багах и недоработках в библиотеке, а мы брали их задачи в бэклог с максимальным приоритетом и оперативно выпускали хотфиксы в случае критических неисправностей.</p><p>Небольшой совет: я советую вам начинать обкатывать библиотеку, как можно быстрее, чтобы раньше собирать фидбэк пользователей. Лучше двигаться маленькими шагами и постоянно получать фидбэк, чем уйти на пол года, сделать что-то и понять, что конечный результат никому не нужен</p><h4>Запустите систему сбора обратной связи</h4><p>После того, как мы начали работать над дизайн-системой как над продуктом, которым будут пользоваться другие люди, мы поняли, что нужно как-то собирать обратную связь и демонстрировать статус работы.</p><p>Изначально мы начинали все с простого чата в Telegram, куда писали новости о релизах, обсуждали проблемы и так далее (не судите нас строго, нам нужно было быстро закрыть потребность сбора фидбэка). Но позже мы поняли, что очень много запросов пользователей теряется, а недовольство повышается.</p><p>Мы решили эту проблему просто открытием нашей доски Jira на просмотр всем командам. А также добавили шорткаты на заведение задач на баги и доработки.</p><p>Помимо этого, мы ввели дежурства. Дежурный — это разработчик, который отвечает за сбор обратной по багам. Если баги критические, то он либо правит их сам, либо назначает ответственного и позже выпускает hotfix с исправлениями. Также дежурный отвечает на вопросы по работе с библиотекой.</p><p>Если вы используете продукцию Atlassian, имеет смысл воспользоваться Jira Service Desk — это сервис для организации службы поддержки. В нём удобно разрабатывать формы заявки с автоматическим созданием задач в Jira.</p><figure class=\"full-width \"><img src=\"https://habrastorage.org/r/w1560/getpro/habr/upload_files/088/53f/63c/08853f63c7183b3d55b8652bb5d33709.png\" alt=\"Issue-трекер проекта на GitHub\" title=\"Issue-трекер проекта на GitHub\" width=\"1753\" height=\"1161\" data-src=\"https://habrastorage.org/getpro/habr/upload_files/088/53f/63c/08853f63c7183b3d55b8652bb5d33709.png\"/><figcaption>Issue-трекер проекта на GitHub</figcaption></figure><blockquote><p>К моменту публикации нашей статьи, мы уже согласовали со службой безопасности все нюансы и выложили библиотеку в открытый доступ. Поэтому стек технологий несколько поменялся, мы используем Github Projects + Issues, а общение и флуд по бибилотеке так же оставили в Telegram-канале</p></blockquote><h4>Синхронизация дизайна и кода</h4><p>После того, как первые команды начали пользоваться нашей библиотекой на нас полетел шквал вопросов о статусе готовности компонентов, о том на каких фреймворках они работают, как называется класс в коде, соответсвующий компоненту.</p><p>И тут мы подходим к одному из самых острых вопросов, с которым вы точно сталкивались — синхронизация дизайна и кода.</p><p>Процесс проектирования дизайна всегда стартует чуть раньше разработки. И как решить проблему, чтобы предоставить дизайнерам доступ к новым компонентам как можно раньше, но, тем не менее, показать пользователям, что компонент ещё не готов в коде?</p><p>Мы ввели ряд правил:</p><ul><li><p>изменения дизайна в существующих компонентах не публикуются, пока не будут произведены соответствующие доработки в коде;</p></li><li><p>в дизайн-системе проставляется статус готовности компонента — «не реализован» / «в разработке» / «готов»;</p></li><li><p>дизайн и разработка синхронизируются два раза в спринт.</p></li></ul><p>На ранних этапах у нас возникали проблемы с тем, что дизайнер добавлял в дизайн систему новые компоненты или немного менял старые, не говоря об этом разработчику. Соответственно, страдали пользователи, потому что они не могли найти нужный компонент в дизайн-системе: в дизайне есть, а в коде — нет.</p><p>Изначально у нас было очень простое правило — готовые в коде компоненты дизайнер не меняет, а если меняет, то не публикует, пока разработчик не внесёт изменения в библиотеку. Если во время работы над дизайном возникает потребность в доработке компонента, то обязательно заводится задача на доработку в коде, и, пока её не реализовали, используется прошлая стабильная версия компонента.</p><p>Важно не забывать отмечать статус готовности компонента, название класса в коде и фреймворк, на котором он доступен.</p><blockquote><p>P.S. Очень жалко, что в Figma нет нормальной поддержки версионирования или системы аналогичной Git для разработчиков. Не надо бежать и писать комментарии, что такая система есть, она как бы есть, но пока еще ни одна команда дизайнеров не показала, как ей удобно можно было бы пользоваться</p></blockquote><figure class=\"full-width \"><img src=\"https://habrastorage.org/r/w1560/getpro/habr/upload_files/a64/2ff/371/a642ff371a90dc9a2e38edcd01ac9f98.png\" alt=\"Структура компонента\" title=\"Структура компонента\" width=\"1753\" height=\"1161\" data-src=\"https://habrastorage.org/getpro/habr/upload_files/a64/2ff/371/a642ff371a90dc9a2e38edcd01ac9f98.png\"/><figcaption>Структура компонента</figcaption></figure><h4>Не откладывайте автоматизацию процессов</h4><p>На первых этапах, когда мы только начали разрабатывать дизайн-систему, у нас был настроен только автоматический прогон тестов и деплой библиотеки.</p><p>Но на определённом моменте, разработка как будто стала сильно тормозить. Это было весьма странно, ведь никакой дополнительной нагрузки на нас не ложилось. Мы начали ресерчить эту ситуацию и поняли, что у нас просто катастрофически много времени уходит на рутинные процессы, типа обновления пака иконок и синхронизации цветовых палитр. А, на секундочку, в библиотеке сейчас около 200 иконок, 20 шрифтов и 3-х тем, состоящих из 30 цветов.</p><p>Давайте немного посчитаем, в среднем на обновление иконки, разработчик тратит от 1-5 мин, если с прогоном тестов, так и до полу часа, добавьте к этому тот факт, что обычно обновляется не одна и не 2 иконки и получите очень интересную картину. У нас разработчики могли спокойно потрать 2-3 часа в неделю на синхронизацию дизайна и кода.</p><p>Представьте, что в процессе разработки дизайн-системы, дизайнер постоянно обновляет все эти ресурсы, а затем разработчикам приходится вручную их выкачивать и сверять, правильно ли он всё загрузил. Несложно прикинуть в голове, что на добавление иконки человек тратит в среднем минуту — скачать, добавить и проверить. Это никуда не годится для команды, которая целиком занимается дизайн-системой.</p><p>Мы с ребятами, посидели, подумали, проанализировали решения команд из других IT-компаний и написали плагин, который умеет выгружать иконки — конвертировать их в Vector в Android и генерация xcassets в Xcode. Сейчас у нас каждый раз просто выкачивается весь пак иконок и автоматически конвертируется в нужный формат.</p><figure class=\"full-width \"><img src=\"https://habrastorage.org/r/w1560/getpro/habr/upload_files/719/7fa/cbb/7197facbb6304c18d5a7fb647fea2a36.png\" alt=\"Схема работы скрипта по обновлению ресурсов\" title=\"Схема работы скрипта по обновлению ресурсов\" width=\"1753\" height=\"1161\" data-src=\"https://habrastorage.org/getpro/habr/upload_files/719/7fa/cbb/7197facbb6304c18d5a7fb647fea2a36.png\"/><figcaption>Схема работы скрипта по обновлению ресурсов</figcaption></figure><p>С темами и цветами схема поинтереснее — мы воспользовались API Figma для выгрузки компонентов. У Figma не самое удобное API, поэтому приходилось делать много запросов и склеивать. В результате у нас получился json-объект со всеми данными о теме. На его основе, используя язык шаблонной генерации liquid, генерируются .swift/.kt файлы с темами приложения.</p><p>За счёт автоматизации процессов мы существенно снизили время на синхронизацию, добавление/обновление новых тем и ресурсов.</p><blockquote><p>Тут не обязательно самим писать тулзы для выкачивания ресурсов и кодогенерации. Мы сами написали эти скрипты, потому что у нас были специфичные нюансы и готовые решения нам не подходили. На первых этапах, я бы советовал воспользоваться готовыми тулзами c открытым исходным кодом: точно знаю, что у ребят из RedMadRobot и HeadHunter они лежат на GitHub.</p></blockquote><h4>Открыта для расширения, закрыта для изменения</h4><p>Как только мы начали работать над инструментом, которым пользуются другие люди, на нас повалилось просто колоссальное количество предложений и пожеланий по улучшению. И самая частая просьба — «добавьте вот этот компонент в дизайн-систему, и вот этот, вот этот, а еще вот этот…».</p><p>Понятное дело, разработчики преследуют меркантильный интерес и просто хотят спихнуть поддержку и разработку компонента на вашу сторону. Тут важно найти баланс и видеть картину в целом: вы делаете систему, которой будут пользоваться не одна команда. Поэтому не стоит добавлять в дизайн-систему специфичные для конкретного продукта компоненты  — это усложнит поддержку и вызовет негатив у других команд, которым компонент не нужен. Но с другой стороны, если он действительно будет использоваться большей частью команд, то включить его, конечно, стоит.</p><p>Если бы добавляли все компоненты, которые нас просили бы добавить другие команды, то наша дизайн система превратилась бы в простую свалку, которую потом бы никто не захотел тянуть к себе в проект</p><p>Как мы помним, дизайн-система призвана помогать и направлять, но ни в коем случае не ограничивать свободу и творчество людей, разрабатывающих на ее основе продукт. Поэтому мы использовали один из принципов SOLID: «открыт для расширения, закрыт для измерения». Разработчики и дизайнеры, могут изменять и комбинировать наши компоненты, тем самым создавая свой уникальный дизайн, но не ломая при этом основные принципы глобальной дизайн системы и не превращая ее в свалку.</p><p>Тут вам поможет понимания следующих правил. Дизайн-система состоит из атомов и молекул. Атомы — это минимальные неизменяемые компоненты, из которых строятся более сложные элементы — молекулы. Будет намного проще, если разрабатываемая система будет состоять в большей степени из атомов. Поэтому лучше сделать много маленьких компонентов и из них уже комбинировать дизайн, нежели сделать один большой и неповоротливый, а потом править его, чтобы удовлетворить потребности всех команд.</p><figure class=\"full-width \"><img src=\"https://habrastorage.org/r/w1560/getpro/habr/upload_files/7e0/def/19c/7e0def19cc345702a1077deddab16618.png\" alt=\"Отличие &quot;простых&quot; компонентов от &quot;сложного&quot;\" title=\"Отличие &quot;простых&quot; компонентов от &quot;сложного&quot;\" width=\"1753\" height=\"931\" data-src=\"https://habrastorage.org/getpro/habr/upload_files/7e0/def/19c/7e0def19cc345702a1077deddab16618.png\"/><figcaption>Отличие \"простых\" компонентов от \"сложного\"</figcaption></figure><p>Найти баланс между функциональностью и универсальностью всегда очень сложно. Тут придётся рассматривать каждый случай индивидуально.</p><h4>Разбивайте библиотеку на модули</h4><p>После того, как продукты, использующие нашу библиотеку пошли несколько релизов в production, к нам постепенно начали обращаться команды с просьбами уменьшить вес библиотеки или ускорить процесс сборки.</p><p>Ни для кого не секрет, что одним из важных показателей, повышающим конверсию скачивания приложений, является размер.</p><p>Первым делом мы поджали размер ресурсов. Этого оказалось недостаточно, и мы пошли дальше. В iOS проекте у нас были и SwiftUI- и UIKit-компоненты, но зачем они разработчикам сразу в одном проекте. Куда лучше, если команда сама выбирает, что подключать. Вывод — нужно делить на модули.</p><p>Мы пришли к следующей схеме разделения:</p><ul><li><p>модуль ресурсов — хранит все ресурсы, картинки, шрифты;</p></li><li><p>модуль темизации — хранит цветовые темы и механизм обновления;</p></li><li><p>модуль компонентов SwiftUI;</p></li><li><p>модуль компонентов UIKit.</p></li></ul><figure class=\"full-width \"><img src=\"https://habrastorage.org/r/w780q1/getpro/habr/upload_files/9a9/29c/d13/9a929cd130b4cb05f688a7b37c44e98b.jpg\" alt=\"Модули дизайн-систем\" title=\"Модули дизайн-систем\" width=\"1280\" height=\"422\" data-src=\"https://habrastorage.org/getpro/habr/upload_files/9a9/29c/d13/9a929cd130b4cb05f688a7b37c44e98b.jpg\" data-blurred=\"true\"/><figcaption>Модули дизайн-систем</figcaption></figure><p>Если команде нужны только шрифты и иконки, она подключает модуль ресурсов. Если только темизация — то модуль темизации. А если им нужны компоненты — то выбирают фреймворк, на основе которого им нужны компоненты, и подключают SwiftUI или UIKit соответственно.</p><blockquote><p>Можно было пойти дальше и выделять каждый компоненты в отдельный модуль, но, на мой взгляд, это уже overhead.</p></blockquote><p>Так же модульность повысит скорость сборки проекта. Какие-то части можно даже заранее упаковать в XCFramework и кэшировать на CI.</p><p>У нас был интересный кейс в iOS, с которым, мы, к сожалению, ничего не смогли сделать. Xcode 12/13 очень долго процессит SF Symbols, потому-то в у нас бибилиотеке их больше 200. Никакие настройки и флаги тут не помогли. Мы решили эту проблему выгрузкой бинарной версии библиотеки — SPM поддерживает такую возможность. (за счет нее не нужно пересобирать бибилиотеку каждый раз, она уже лежит скомпилированная)</p><h4>Проработайте механизм темизации</h4><p>Простите за тавтологию, но на тему темизации я могу дискутировать очень много, чем собственно я и занимался со своей командой.</p><p>Темизация — это одна из самых больших головных болей, с которой сталкивается каждая команда, работающая с дизайн-системой. В предыдущем шаге мы её вынесли в отдельный модуль.</p><p>Тема может состоять не только из цветов. В неё могут быть включены ещё и ресурсы.</p><p>Наша модель темы состоит из следующего набора:</p><ul><li><p>цветовая палитра — набор цветов, используемых в теме;</p></li><li><p>шрифтовая палитра — набор шрифтов, используемых в теме;</p></li><li><p>ресурсы — набор специфичных ресурсов, которые могут меняться в зависисмости от темы.</p></li></ul><p>На самом деле спектр настроек у темы может быть существенно шире, например, можно включить туда скругление и даже звуковые сигналы.</p><p>Самое сложное, с чем мы столкнулись — это синхронизировать нейминг токенов цветовой и шрифтовой схемы. На проектах с продолжительным жизненным циклом — это было огромной болью. При этом, цветовая тема так же должна быть открыта для расширения. Дизайнеры должны иметь возможность добавлять новые цветовые токены, тем самым расширяя количество персонализированных цветов.</p><p>Если вы жёстко зашьёте одну цветовую/шрифтовую схему, то просто поставите крест на дизайн-системе. Очень часто дизайнерам и разработчикам понадобятся новые цвета и шрифты, специфичные для их продукта.</p><figure class=\"full-width \"><img src=\"https://habrastorage.org/r/w1560/getpro/habr/upload_files/751/ebd/d55/751ebdd55226637c37df0adcfa1e261b.png\" alt=\"Возможность расширения дизайн-системы\" title=\"Возможность расширения дизайн-системы\" width=\"1753\" height=\"1330\" data-src=\"https://habrastorage.org/getpro/habr/upload_files/751/ebd/d55/751ebdd55226637c37df0adcfa1e261b.png\"/><figcaption>Возможность расширения дизайн-системы</figcaption></figure><p>Выходом будет добавить возможность расширять вашу тему новыми цветами и шрифтами, а еще лучше позволить вручную задавать цвета и шрифты компонентов без необходимости использовать темизацию. Это немного увеличит время разработки, но существенно повысит гибкость дизайн-системы.</p><blockquote><p>У нас был пример команды, которая полностью отказалась от предложенной нами системы темизации и написала собственные схемы.</p></blockquote><h4>Полноценно работайте с example-проектом</h4><p>Если у вас на проекте есть дизайн-система, выделенная в отдельный модуль, то с большей вероятности у вас есть и Sandbox (Example-проект), где вы проверяете ваши компоненты, чтобы не тащить их сразу в основной проект. Часто бывает, что это просто свалка, на которой линтер даже не настроен. Да и зачем же следить за этим проектом, он же не идет в Prod?</p><p>У нас есть свой Example-проект, но мы пошли немного дальше и решили его сделать полезным не только разработчикам, но и дизайнерам, тестировщикам, а так же пользователям нашей библиотеки.</p><p>Ранее я говорил, что у нашей дизайн-системы нет своего продукта, на котором мы обкатывали поведение компонентов, так вот Example-проект и является этим продуктом.</p><p>Для нас это приложение стало не просто витриной с компонентами, а полноценным инструментом взаимодействия разработчиков, дизайнеров и тестировщиков.</p><blockquote><p>При разработке мы стремились сделать example-проекта максимально простым в реализации. Не стоит его слишком сильно усложнять и делать выбор в сторону функциональность и скорости разработки.</p></blockquote><p>Мы выделили ряд функций, которым example-проект должно соответствовать:</p><ul><li><p>отображать работу компонентов дизайн-системы во всех состояниях — это нужно для написания тестов и проведения дизайн-ревью;</p></li><li><p>код демонстрирует разработчикам, как правильно использовать те или иные компоненты. Помимо документации, иногда удобно открыть экран в приложении и посмотреть, как компонент работает или реализована определённая функция в коде;</p></li><li><p>возможность редактировать цвета и создавать новые темы. Эта функция появилась ни сразу, но у наших дизайнеров возникла потребность проверять, как будет выглядеть тот или иной цвет непосредственно на устройстве и тестировать это восприятие на пользователях. В Figma есть функция Mirror, который позволяет продемонстрировать макет на реальном устройстве — это удобно чисто для дизайнеров, но, например, если вы будете проводить тестирование на фокус-группе, то такой метод не очень подойдёт.</p></li></ul><figure class=\"full-width \"><img src=\"https://habrastorage.org/r/w1560/getpro/habr/upload_files/737/088/cc4/737088cc40ea42754ad6eab3371f38a1.png\" alt=\"&quot;Live&quot; редактирование компонента\" title=\"&quot;Live&quot; редактирование компонента\" width=\"1753\" height=\"1265\" data-src=\"https://habrastorage.org/getpro/habr/upload_files/737/088/cc4/737088cc40ea42754ad6eab3371f38a1.png\"/><figcaption>\"Live\" редактирование компонента</figcaption></figure><p>В результате у нас получился инструмент, с помощью которого мы не только демонстрируем дизайн-систему, но и всячески её тестируем и дорабатываем.</p><p>К сожалению, у нас тоже не хватает времени на всё, но следующим шагом по доработке приложения, мы хотели бы добавить возможность динамического заполнения экрана данными из JSON (своего рода Backend Driven UI для тестирования). Чтобы условно тестировщик писал тест-кейс в формате JSON на компонент со всеми краевыми случаями, в которых компонент может сломаться. Эти данные бы подставлялись и прогонялись автоматические тесты или ручное тестирование.</p><h4>Организуйте внутреннее комьюнити вокруг библиотеки</h4><p>Важно обрести союзников, которые понесут дизайн-систему дальше в проекты, будут отвечать на простые вопросы коллег и помогут с обратной связью. Проводите внутренние образовательные мероприятия, собирайтесь на неформальных встречах и просто любите создаваемый продукт.</p><h2>Вместо заключения</h2><p>На самом деле, я начал писать эту статью уже давно. Сейчас я больше склонен думать, что создание единой глобальной дизайн-системы скорее похоже на поиск Эльдорадо или священного грааля. Все его ищут, но мало кому удаётся найти. И главный вопрос нужен ли он вам на столько, чтобы тратить такое количество ресурсов или это просто тренд и прихоть?</p><p>На мой взгляд, в большинстве случаев стоит ограничиться единой системой гайдлайнов и фирменных цветов компании. Прибегать к глобальной дизайн-системе стоит только в том случае, если у вас есть действительно много внешне похожих продуктов с большим числом переиспользуемых компонентов. И желательно, чтобы они только планировались или находились на ранних этапах разработки. Или если вам нужно действительно быстро и с минимальными затратами выпускать MVP-проекты или White Label приложения.</p><p>Во всех остальных случаях я бы советовал придерживаться локальной системы с набором гайдлайнов.</p><p>Создание и внедрение дизайн-системы — сложный и кропотливый процесс. Надеюсь, я рассмотрел все его основные аспекты и узкие места. Дойдя до логичного конца, можно существенно ускорить работу коллег и повысить узнаваемость продуктов среди целевой аудитории. Но всегда думайте — а стоит ли оно того или можно обойтись малой кровью.</p><p>Ссылки на наши библиотеки из примеров выше (<a href=\"https://github.com/admiral-team/admiralui-android\">Android</a>/<a href=\"https://github.com/admiral-team/admiralui-ios\">iOS</a>)</p><p></p></div>",
        "clean_body": "Про то, что такое дизайн-система, как она должна работать, уже написано немало статей. Но зачастую авторы охватывают лишь какой-то отдельный аспект этой обширной темы. Я же, в свою очередь, хочу рассмотреть именно сам процесс создания дизайн-системы, основанный на опыте нашей команды, рассказать об основных трудностях, с которыми мы столкнулись и, возможно, предостеречь от распространённых ошибок, которые мы совершили на этом тернистом пути. А следовать ему или нет, решение остается за вами.Ну что же, погнали…Немного теорииЧто же такое дизайн-система? Согласно определению из «Википедии»: «дизайн-система — набор компонентов, правил, предписаний и инструментов для повышения качества и скорости разработки продуктов». Тут особо и поспорить-то не с чем.Я бы, условно, разделил дизайн-систему на две составляющие:визуальное представление (для дизайнеров);техническая реализация (для разработчиков).Визуальное представление — это набор компонентов, шрифтов, иконок, цветовых схем и так далее в условной Figma или Sketch. Эта часть разрабатывается и используется дизайнерами для быстрого проектирования и построения интерфейса.Техническая реализация — это зеркальное отражение визуального представления, но только в коде для разработчиков. В отличие от визуального представления, которое должно существовать в единственном экземпляре, технических реализаций может быть много — начиная от разделения по платформам (iOS, Android, Web), заканчивая разделением по конкретным фреймворкам (iOS: UIKit и SwiftUI; Android: XML/Layout и Compose, Web: Angular и React).Дополнительно я бы разделил дизайн-системы ещё на две категории:локальные;глобальные.Использование локальных и глобальных дизайн-системЛокальные дизайн-системы — это системы, которые разработаны и работают только на одном продукте компании. В большинстве проектов реализован данный подход.Глобальные дизайн-системы — концептуально почти ничем не отличают от локальных, за исключением того, что они создаются для группы продуктов, а это, в свою очередь, накладывает на них ряд дополнительных требований и ограничений.Локальную дизайн-систему можно разрабатывать просто, как часть продукта без дополнительных расходов (вы просто складываете все ваши компоненты в одно место, объединяете общие компоненты между собой и подбиваете их под общую стилистику и гайдлайны вашей компании). Локальная дизайн система так или иначе появляется в любом проекте сама-собой, потому что дизайнерам и разработчикам нужно удобнее переиспользовать компоненты, чем каждый раз создавать новые. Но если вы все же хотите замахнуться на глобальную дизайн-систему, то она сама должна являться полноценным продуктом, которому вы будете посвящать большую часть времени команды. А потребителем продукта будет являться весьма искушённая публика — разработчики и дизайнеры.Если преследуем цель повысить узнаваемость продукта, можно обойтись и локальными дизайн-системами, которые просто будут объединены общими гайдлайнами. Например, посмотрим на продукты той же самой компании «Яндекс»: когда открываешь приложение «Яндекс.Go» и «Яндекс.Еда», визуально кажется, что продукты похожи, хотя это две независимые команды, с разными локальными дизайн системами, объединенными единой стилистикой. (возможно на данный момент уже что-то поменялось)Отлично, теперь можно переходить дальше.Знакомимся с задачейПеред моей командой была поставлена задача создания визуального представления и технической реализации дизайн-системы для крупного заказчика. Конечными потребителями должны были стать 15 миллионов пользователей. А использовать дизайн-систему должна была не одна команда, не две, а вся организация в целом.Проводим анализ аудиторииКак мы помним, наша дизайн система - это самостоятельный продукт. И что же нам делать, когда мы приступаем к разработке продукта? Сразу бежать проектировать компоненты и писать код — конечно, нет! Нужно провести анализ аудитории, чтобы понять потребности других команд. Мы провели ряд опросов.Опрос №1. Для дизайнеровкакими инструментами проектирования пользуются;какие подходы к построению дизайна используют;количество дизайнеров в команде.Тут не было никаких откровений. Все дизайнеры пользовались Figma, подходы к проектированию у всех были плюс-минус одинаковыми. Но выяснился интересный факт, что в компании уже существует несколько локальных дизайн-систем, которые функционируют в рамках группы продуктов, но между собой они никак не связаны.Задача перед дизайнерами была ясна и понятна: выбрать наиболее распространённую дизайн-систему и доработать её до того уровня, чтобы учитывать потребности всех остальных команд. Конечно, когда вы приходите на проект, хочется всё сжечь и сделать с нуля. Кажется, что так намного быстрее и правильнее, но как показывает практика - доработать и возможно немного переработать старое намного быстрее, чем разрабатывать с нуля.Опрос №2. Для разработчиковминимальная поддерживаемая версия операционной системы;какой стек технологий используется;количество разработчиков в команде.После проведения опроса мы получили достаточно распространённую картину. Минимальные версии операционных систем у большинства команд были — iOS 11 и Android 5.0, стек стандартный: для iOS — UIKit, Android — Layout + XML.Результаты опросов стека технологий в нашей компанииМы рассматриваем случай технического аспекта дизайн-системы для мобильной разработки, для веба всё плюс-минус аналогично.Казалось бы, всё готово, статистика собрана, с командами пообщались, можно приниматься за разработку, но тут мы не учли один очень важный аспект, о котором поговорим далее.Не пытайтесь быть умнее пользователейНаша команда собрала статистку, учла все требования и пожелания и разработала первую версию библиотеки. Но мы не учли, что встретим серьёзное сопротивление со стороны большого числа других команд, работающими над продуктами с достаточно продолжительным жизненным циклом.Виноваты ли были команды, что не хотели переходить на новую дизайн-систему? Конечно, нет! Только представьте, приходят к вам в команду незнакомые люди и говорят, что дизайнерам нужно полностью перевести дизайн на новые компоненты, а разработчикам полностью переписать весь код, связанный c UI, так потом ещё и провести полный регресс. Не знаю, кто бы на их месте ответил бы по-другому.А что это значит? Что мы неправильно выбрали первоначальную аудиторию, на которую должны были ориентироваться. Ведь, как мы помним, дизайн-система должна ускорять процесс разработки продуктов, а не тормозить его. А для команд, которые уже давно работают над продуктом, предложенная новинка не принесёт никакой пользы, кроме огромного бэклога. Поэтому легче всего было пойти другим путём и найти молодые команды, которые только формировались и не имели полноценного дизайна, а разработка либо ещё не началась, либо была на начальном этапе.Результаты опросов стека технологий молодых проектовНам пришлось дополнить опрос и заново собрать статистику. Результат отличался. Если в случае с ОС от Google нам повезло и Android-сообщество использует в большинстве своём консервативные подходы к вёрстке — Layout + XML, то для iOS у новых команд был существенный перевес в сторону SwiftUI и для них это было важным критерием перехода на новую библиотеку.Хорошо, что у нас было достаточно компетенции и команда быстро зарелизила новую версию под SwiftUI. Но из минусов остался тот факт, что нам до сих пор приходится поддерживать две версии библиотеки — SwiftUI и UIKit. А это в два раза больше работы.Но нам нужно сохранять лояльность комьюнити, поэтому мы не бросаем поддержку UIKit, но все новые фичи в основном разрабатываем под SwiftUI.Внедряйте дизайн-систему небольшими шагамиПосле того как мы провели опрос и реализовали базовую функциональность библиотеки, пришло время для её интеграции в другие продукты. К сожалению или радости, у нашей команды не было своего продукта, на котором можно в полной мере обкатать библиотеку.Мы решили искать молодые команды, у которых только начиналась разработка нового продукта и у них не было времени на разработку собственной дизайн-системы. А главное, чтобы они были лояльны к багам и недоработкам в библиотеке.Казалось бы, найти такие команды сложно. Но важно понять, что вы можете предложить взамен. Мы нашли компромисс: ребята использовали библиотеку, репортили о багах и недоработках в библиотеке, а мы брали их задачи в бэклог с максимальным приоритетом и оперативно выпускали хотфиксы в случае критических неисправностей.Небольшой совет: я советую вам начинать обкатывать библиотеку, как можно быстрее, чтобы раньше собирать фидбэк пользователей. Лучше двигаться маленькими шагами и постоянно получать фидбэк, чем уйти на пол года, сделать что-то и понять, что конечный результат никому не нуженЗапустите систему сбора обратной связиПосле того, как мы начали работать над дизайн-системой как над продуктом, которым будут пользоваться другие люди, мы поняли, что нужно как-то собирать обратную связь и демонстрировать статус работы.Изначально мы начинали все с простого чата в Telegram, куда писали новости о релизах, обсуждали проблемы и так далее (не судите нас строго, нам нужно было быстро закрыть потребность сбора фидбэка). Но позже мы поняли, что очень много запросов пользователей теряется, а недовольство повышается.Мы решили эту проблему просто открытием нашей доски Jira на просмотр всем командам. А также добавили шорткаты на заведение задач на баги и доработки.Помимо этого, мы ввели дежурства. Дежурный — это разработчик, который отвечает за сбор обратной по багам. Если баги критические, то он либо правит их сам, либо назначает ответственного и позже выпускает hotfix с исправлениями. Также дежурный отвечает на вопросы по работе с библиотекой.Если вы используете продукцию Atlassian, имеет смысл воспользоваться Jira Service Desk — это сервис для организации службы поддержки. В нём удобно разрабатывать формы заявки с автоматическим созданием задач в Jira.Issue-трекер проекта на GitHubК моменту публикации нашей статьи, мы уже согласовали со службой безопасности все нюансы и выложили библиотеку в открытый доступ. Поэтому стек технологий несколько поменялся, мы используем Github Projects + Issues, а общение и флуд по бибилотеке так же оставили в Telegram-каналеСинхронизация дизайна и кодаПосле того, как первые команды начали пользоваться нашей библиотекой на нас полетел шквал вопросов о статусе готовности компонентов, о том на каких фреймворках они работают, как называется класс в коде, соответсвующий компоненту.И тут мы подходим к одному из самых острых вопросов, с которым вы точно сталкивались — синхронизация дизайна и кода.Процесс проектирования дизайна всегда стартует чуть раньше разработки. И как решить проблему, чтобы предоставить дизайнерам доступ к новым компонентам как можно раньше, но, тем не менее, показать пользователям, что компонент ещё не готов в коде?Мы ввели ряд правил:изменения дизайна в существующих компонентах не публикуются, пока не будут произведены соответствующие доработки в коде;в дизайн-системе проставляется статус готовности компонента — «не реализован» / «в разработке» / «готов»;дизайн и разработка синхронизируются два раза в спринт.На ранних этапах у нас возникали проблемы с тем, что дизайнер добавлял в дизайн систему новые компоненты или немного менял старые, не говоря об этом разработчику. Соответственно, страдали пользователи, потому что они не могли найти нужный компонент в дизайн-системе: в дизайне есть, а в коде — нет.Изначально у нас было очень простое правило — готовые в коде компоненты дизайнер не меняет, а если меняет, то не публикует, пока разработчик не внесёт изменения в библиотеку. Если во время работы над дизайном возникает потребность в доработке компонента, то обязательно заводится задача на доработку в коде, и, пока её не реализовали, используется прошлая стабильная версия компонента.Важно не забывать отмечать статус готовности компонента, название класса в коде и фреймворк, на котором он доступен.P.S. Очень жалко, что в Figma нет нормальной поддержки версионирования или системы аналогичной Git для разработчиков. Не надо бежать и писать комментарии, что такая система есть, она как бы есть, но пока еще ни одна команда дизайнеров не показала, как ей удобно можно было бы пользоватьсяСтруктура компонентаНе откладывайте автоматизацию процессовНа первых этапах, когда мы только начали разрабатывать дизайн-систему, у нас был настроен только автоматический прогон тестов и деплой библиотеки.Но на определённом моменте, разработка как будто стала сильно тормозить. Это было весьма странно, ведь никакой дополнительной нагрузки на нас не ложилось. Мы начали ресерчить эту ситуацию и поняли, что у нас просто катастрофически много времени уходит на рутинные процессы, типа обновления пака иконок и синхронизации цветовых палитр. А, на секундочку, в библиотеке сейчас около 200 иконок, 20 шрифтов и 3-х тем, состоящих из 30 цветов.Давайте немного посчитаем, в среднем на обновление иконки, разработчик тратит от 1-5 мин, если с прогоном тестов, так и до полу часа, добавьте к этому тот факт, что обычно обновляется не одна и не 2 иконки и получите очень интересную картину. У нас разработчики могли спокойно потрать 2-3 часа в неделю на синхронизацию дизайна и кода.Представьте, что в процессе разработки дизайн-системы, дизайнер постоянно обновляет все эти ресурсы, а затем разработчикам приходится вручную их выкачивать и сверять, правильно ли он всё загрузил. Несложно прикинуть в голове, что на добавление иконки человек тратит в среднем минуту — скачать, добавить и проверить. Это никуда не годится для команды, которая целиком занимается дизайн-системой.Мы с ребятами, посидели, подумали, проанализировали решения команд из других IT-компаний и написали плагин, который умеет выгружать иконки — конвертировать их в Vector в Android и генерация xcassets в Xcode. Сейчас у нас каждый раз просто выкачивается весь пак иконок и автоматически конвертируется в нужный формат.Схема работы скрипта по обновлению ресурсовС темами и цветами схема поинтереснее — мы воспользовались API Figma для выгрузки компонентов. У Figma не самое удобное API, поэтому приходилось делать много запросов и склеивать. В результате у нас получился json-объект со всеми данными о теме. На его основе, используя язык шаблонной генерации liquid, генерируются .swift/.kt файлы с темами приложения.За счёт автоматизации процессов мы существенно снизили время на синхронизацию, добавление/обновление новых тем и ресурсов.Тут не обязательно самим писать тулзы для выкачивания ресурсов и кодогенерации. Мы сами написали эти скрипты, потому что у нас были специфичные нюансы и готовые решения нам не подходили. На первых этапах, я бы советовал воспользоваться готовыми тулзами c открытым исходным кодом: точно знаю, что у ребят из RedMadRobot и HeadHunter они лежат на GitHub.Открыта для расширения, закрыта для измененияКак только мы начали работать над инструментом, которым пользуются другие люди, на нас повалилось просто колоссальное количество предложений и пожеланий по улучшению. И самая частая просьба — «добавьте вот этот компонент в дизайн-систему, и вот этот, вот этот, а еще вот этот…».Понятное дело, разработчики преследуют меркантильный интерес и просто хотят спихнуть поддержку и разработку компонента на вашу сторону. Тут важно найти баланс и видеть картину в целом: вы делаете систему, которой будут пользоваться не одна команда. Поэтому не стоит добавлять в дизайн-систему специфичные для конкретного продукта компоненты  — это усложнит поддержку и вызовет негатив у других команд, которым компонент не нужен. Но с другой стороны, если он действительно будет использоваться большей частью команд, то включить его, конечно, стоит.Если бы добавляли все компоненты, которые нас просили бы добавить другие команды, то наша дизайн система превратилась бы в простую свалку, которую потом бы никто не захотел тянуть к себе в проектКак мы помним, дизайн-система призвана помогать и направлять, но ни в коем случае не ограничивать свободу и творчество людей, разрабатывающих на ее основе продукт. Поэтому мы использовали один из принципов SOLID: «открыт для расширения, закрыт для измерения». Разработчики и дизайнеры, могут изменять и комбинировать наши компоненты, тем самым создавая свой уникальный дизайн, но не ломая при этом основные принципы глобальной дизайн системы и не превращая ее в свалку.Тут вам поможет понимания следующих правил. Дизайн-система состоит из атомов и молекул. Атомы — это минимальные неизменяемые компоненты, из которых строятся более сложные элементы — молекулы. Будет намного проще, если разрабатываемая система будет состоять в большей степени из атомов. Поэтому лучше сделать много маленьких компонентов и из них уже комбинировать дизайн, нежели сделать один большой и неповоротливый, а потом править его, чтобы удовлетворить потребности всех команд.Отличие \"простых\" компонентов от \"сложного\"Найти баланс между функциональностью и универсальностью всегда очень сложно. Тут придётся рассматривать каждый случай индивидуально.Разбивайте библиотеку на модулиПосле того, как продукты, использующие нашу библиотеку пошли несколько релизов в production, к нам постепенно начали обращаться команды с просьбами уменьшить вес библиотеки или ускорить процесс сборки.Ни для кого не секрет, что одним из важных показателей, повышающим конверсию скачивания приложений, является размер.Первым делом мы поджали размер ресурсов. Этого оказалось недостаточно, и мы пошли дальше. В iOS проекте у нас были и SwiftUI- и UIKit-компоненты, но зачем они разработчикам сразу в одном проекте. Куда лучше, если команда сама выбирает, что подключать. Вывод — нужно делить на модули.Мы пришли к следующей схеме разделения:модуль ресурсов — хранит все ресурсы, картинки, шрифты;модуль темизации — хранит цветовые темы и механизм обновления;модуль компонентов SwiftUI;модуль компонентов UIKit.Модули дизайн-системЕсли команде нужны только шрифты и иконки, она подключает модуль ресурсов. Если только темизация — то модуль темизации. А если им нужны компоненты — то выбирают фреймворк, на основе которого им нужны компоненты, и подключают SwiftUI или UIKit соответственно.Можно было пойти дальше и выделять каждый компоненты в отдельный модуль, но, на мой взгляд, это уже overhead.Так же модульность повысит скорость сборки проекта. Какие-то части можно даже заранее упаковать в XCFramework и кэшировать на CI.У нас был интересный кейс в iOS, с которым, мы, к сожалению, ничего не смогли сделать. Xcode 12/13 очень долго процессит SF Symbols, потому-то в у нас бибилиотеке их больше 200. Никакие настройки и флаги тут не помогли. Мы решили эту проблему выгрузкой бинарной версии библиотеки — SPM поддерживает такую возможность. (за счет нее не нужно пересобирать бибилиотеку каждый раз, она уже лежит скомпилированная)Проработайте механизм темизацииПростите за тавтологию, но на тему темизации я могу дискутировать очень много, чем собственно я и занимался со своей командой.Темизация — это одна из самых больших головных болей, с которой сталкивается каждая команда, работающая с дизайн-системой. В предыдущем шаге мы её вынесли в отдельный модуль.Тема может состоять не только из цветов. В неё могут быть включены ещё и ресурсы.Наша модель темы состоит из следующего набора:цветовая палитра — набор цветов, используемых в теме;шрифтовая палитра — набор шрифтов, используемых в теме;ресурсы — набор специфичных ресурсов, которые могут меняться в зависисмости от темы.На самом деле спектр настроек у темы может быть существенно шире, например, можно включить туда скругление и даже звуковые сигналы.Самое сложное, с чем мы столкнулись — это синхронизировать нейминг токенов цветовой и шрифтовой схемы. На проектах с продолжительным жизненным циклом — это было огромной болью. При этом, цветовая тема так же должна быть открыта для расширения. Дизайнеры должны иметь возможность добавлять новые цветовые токены, тем самым расширяя количество персонализированных цветов.Если вы жёстко зашьёте одну цветовую/шрифтовую схему, то просто поставите крест на дизайн-системе. Очень часто дизайнерам и разработчикам понадобятся новые цвета и шрифты, специфичные для их продукта.Возможность расширения дизайн-системыВыходом будет добавить возможность расширять вашу тему новыми цветами и шрифтами, а еще лучше позволить вручную задавать цвета и шрифты компонентов без необходимости использовать темизацию. Это немного увеличит время разработки, но существенно повысит гибкость дизайн-системы.У нас был пример команды, которая полностью отказалась от предложенной нами системы темизации и написала собственные схемы.Полноценно работайте с example-проектомЕсли у вас на проекте есть дизайн-система, выделенная в отдельный модуль, то с большей вероятности у вас есть и Sandbox (Example-проект), где вы проверяете ваши компоненты, чтобы не тащить их сразу в основной проект. Часто бывает, что это просто свалка, на которой линтер даже не настроен. Да и зачем же следить за этим проектом, он же не идет в Prod?У нас есть свой Example-проект, но мы пошли немного дальше и решили его сделать полезным не только разработчикам, но и дизайнерам, тестировщикам, а так же пользователям нашей библиотеки.Ранее я говорил, что у нашей дизайн-системы нет своего продукта, на котором мы обкатывали поведение компонентов, так вот Example-проект и является этим продуктом.Для нас это приложение стало не просто витриной с компонентами, а полноценным инструментом взаимодействия разработчиков, дизайнеров и тестировщиков.При разработке мы стремились сделать example-проекта максимально простым в реализации. Не стоит его слишком сильно усложнять и делать выбор в сторону функциональность и скорости разработки.Мы выделили ряд функций, которым example-проект должно соответствовать:отображать работу компонентов дизайн-системы во всех состояниях — это нужно для написания тестов и проведения дизайн-ревью;код демонстрирует разработчикам, как правильно использовать те или иные компоненты. Помимо документации, иногда удобно открыть экран в приложении и посмотреть, как компонент работает или реализована определённая функция в коде;возможность редактировать цвета и создавать новые темы. Эта функция появилась ни сразу, но у наших дизайнеров возникла потребность проверять, как будет выглядеть тот или иной цвет непосредственно на устройстве и тестировать это восприятие на пользователях. В Figma есть функция Mirror, который позволяет продемонстрировать макет на реальном устройстве — это удобно чисто для дизайнеров, но, например, если вы будете проводить тестирование на фокус-группе, то такой метод не очень подойдёт.\"Live\" редактирование компонентаВ результате у нас получился инструмент, с помощью которого мы не только демонстрируем дизайн-систему, но и всячески её тестируем и дорабатываем.К сожалению, у нас тоже не хватает времени на всё, но следующим шагом по доработке приложения, мы хотели бы добавить возможность динамического заполнения экрана данными из JSON (своего рода Backend Driven UI для тестирования). Чтобы условно тестировщик писал тест-кейс в формате JSON на компонент со всеми краевыми случаями, в которых компонент может сломаться. Эти данные бы подставлялись и прогонялись автоматические тесты или ручное тестирование.Организуйте внутреннее комьюнити вокруг библиотекиВажно обрести союзников, которые понесут дизайн-систему дальше в проекты, будут отвечать на простые вопросы коллег и помогут с обратной связью. Проводите внутренние образовательные мероприятия, собирайтесь на неформальных встречах и просто любите создаваемый продукт.Вместо заключенияНа самом деле, я начал писать эту статью уже давно. Сейчас я больше склонен думать, что создание единой глобальной дизайн-системы скорее похоже на поиск Эльдорадо или священного грааля. Все его ищут, но мало кому удаётся найти. И главный вопрос нужен ли он вам на столько, чтобы тратить такое количество ресурсов или это просто тренд и прихоть?На мой взгляд, в большинстве случаев стоит ограничиться единой системой гайдлайнов и фирменных цветов компании. Прибегать к глобальной дизайн-системе стоит только в том случае, если у вас есть действительно много внешне похожих продуктов с большим числом переиспользуемых компонентов. И желательно, чтобы они только планировались или находились на ранних этапах разработки. Или если вам нужно действительно быстро и с минимальными затратами выпускать MVP-проекты или White Label приложения.Во всех остальных случаях я бы советовал придерживаться локальной системы с набором гайдлайнов.Создание и внедрение дизайн-системы — сложный и кропотливый процесс. Надеюсь, я рассмотрел все его основные аспекты и узкие места. Дойдя до логичного конца, можно существенно ускорить работу коллег и повысить узнаваемость продуктов среди целевой аудитории. Но всегда думайте — а стоит ли оно того или можно обойтись малой кровью.Ссылки на наши библиотеки из примеров выше (Android/iOS)",
        "meta_tags": [
            "дизайн-система",
            "uikit",
            "swiftui",
            "мобильная разработка",
            "components",
            "компоненты",
            "layout"
        ]
    },
    {
        "publish_datetime": 1669981696.0,
        "author": "Artur Netsvetaev",
        "title": "Релиз InvokeAI 2.2: универсальный холст, удобные установщики, автозагрузка моделей и DPM++",
        "title_image_url": "https://habrastorage.org/getpro/habr/upload_files/aa8/52c/c31/aa852cc31b24e9624f0e642d8628106d.jpg",
        "raw_body": "<div xmlns=\"http://www.w3.org/1999/xhtml\"><p>Привет! InvokeAI 2.2 теперь доступен для всех. В этом обновлении добавлены UI Outpainting, Embedding Management и другие функции. Ознакомьтесь с выделенными обновлениями ниже, а также с полным описанием всех функций, включенных в релиз.</p><div class=\"tm-iframe_temp\" data-src=\"https://embedd.srv.habr.com/iframe/638a0d846983449a675f045f\" data-style=\"\" id=\"638a0d846983449a675f045f\" width=\"\"></div><h3>Что такое InvokeAI? </h3><p><a href=\"https://github.com/invoke-ai/InvokeAI\" rel=\"noopener noreferrer nofollow\">InvokeAI </a>это интерфейс и оптимизированная реализация нейросети Stable Diffusion. InvokeAI был одним из самых ранних форков основного репозитория CompVis, а теперь превратился в полноценный инструментарий Stable Diffusion с открытым исходным кодом под названием InvokeAI.</p><h3>Унифицированный холст </h3><p>В веб-интерфейсе теперь есть бесконечный холст для inpainting, outpainting, img2img, sketch2img и txt2img, чтобы вы могли оптимизировать свой творческий процесс. Код холста был переписан для значительного повышения производительности и поддержки множества функций, вроде кисти, неограниченной истории, отображения прогресса генерации в реальном времени и многого другого.</p><h3>Управление моделями для стилизации (embeddings) </h3><p>Легко добавляйте модели с Huggingface прямо в «Инвок», используя токен для создания нужного стиля (модель подтянется автоматически). Возможность одновременного использования нескольких моделей позволяет легко импортировать и изучать различные стили в рамках одной сессии!</p><h3>Просмотрщик </h3><p>В веб-интерфейсе теперь есть просмотрщик, позволяющее более детально изучить ваши генерации. Больше не нужно открывать изображения во внешнем файловом проводнике, даже если речь идет о больших картинках!</p><h3>Установка в 1 клик </h3><p>С автоматическими инсталляторами использование «Инвок» стало еще проще. Наши пакеты для разных ОС (Mac M1/M2, Windows и Linux) помогут вам настроить все необходимое. Наш инсталлятор с исходниками доступен сейчас, а исполняемые файлы появятся в ближайшие день-два. Нажимайте и начинайте!</p><h3>Поддержка семплера DPM++ (экспериментальная) </h3><p>Добавлена поддержка DPM++! Пожалуйста, обратите внимание, что это экспериментальный вариант, и он может быть изменен в будущем, так как мы продолжаем совершенствовать нашу внутреннюю систему.</p><h3>Что нас ждет? </h3><p>Мы постоянно обсуждаем и исследуем новые идеи, чтобы сделать InvokeAI лучшим приложением с каждым релизом. Начинается работа над созданием модульной архитектуры бэкенда, которая позволит нам поддерживать очереди, атомарное выполнение, легко добавлять новые функции и многое другое. </p><p>В скором времени мы также официально добавим поддержку SD2.0. Если вы разработчик, который в настоящее время использует InvokeAI в качестве бэкенда, мы приглашаем вас присоединиться к обсуждению и предоставить обратную связь, чтобы мы могли создать лучшую систему из возможных.</p><h3>Наши ценности </h3><p>Поскольку InvokeAI все чаще используется творческими профессионалами и коммерческими проектами, мы считаем важным поделиться нашими ценностями с сообществом, которое решило поверить в нашу работу.</p><p>Команда InvokeAI полностью привержена созданию инструментов, которые не только продвигают этот невероятный мир генеративного искусства дальше, но и расширяют возможности художников и креативщиков, которые играют ключевую роль в этой экосистеме. </p><p>Мы считаем, что наша роль в разработке этого программного обеспечения этична, и стремимся осмысленно реагировать на все проблемы сообщества. Чтобы узнать больше, пожалуйста, <a href=\"https://github.com/invoke-ai/InvokeAI/blob/08ef4d62e91f9b07cae8cb6ba165fa2bc8b22e2d/InvokeAI_Statement_of_Values.md\" rel=\"noopener noreferrer nofollow\">ознакомьтесь с нашим заявлением здесь</a>.</p><hr/><p>Если вы разработчик, желающий развить или внести свой вклад в проект, профессионал, ищущий профессиональные инструменты для внедрения в свой рабочий процесс, или просто ищете отличный опыт работы с SD с открытым исходным кодом, мы будем рады, если вы присоединитесь к сообществу.</p><p>Вы можете получить <a href=\"https://github.com/invoke-ai/InvokeAI/releases\" rel=\"noopener noreferrer nofollow\">последнюю версию на GitHub</a>, а также <a href=\"https://discord.gg/ZmtBAhwWhy\" rel=\"noopener noreferrer nofollow\">присоединиться к сообществу в discord здесь</a>.</p><hr/><p>О себе: Меня зовут Артур Нецветаев, я менеджер продуктов, предприниматель и <a href=\"https://netsvetaev.com/\" rel=\"noopener noreferrer nofollow\">дизайнер интерфейсов</a>. Я участвую в разработке интерфейса <a href=\"https://github.com/invoke-ai/InvokeAI\" rel=\"noopener noreferrer nofollow\">InvokeAI</a> и пользуюсь им сам с момента создания.</p><p></p></div>",
        "clean_body": "Привет! InvokeAI 2.2 теперь доступен для всех. В этом обновлении добавлены UI Outpainting, Embedding Management и другие функции. Ознакомьтесь с выделенными обновлениями ниже, а также с полным описанием всех функций, включенных в релиз.Что такое InvokeAI? InvokeAI это интерфейс и оптимизированная реализация нейросети Stable Diffusion. InvokeAI был одним из самых ранних форков основного репозитория CompVis, а теперь превратился в полноценный инструментарий Stable Diffusion с открытым исходным кодом под названием InvokeAI.Унифицированный холст В веб-интерфейсе теперь есть бесконечный холст для inpainting, outpainting, img2img, sketch2img и txt2img, чтобы вы могли оптимизировать свой творческий процесс. Код холста был переписан для значительного повышения производительности и поддержки множества функций, вроде кисти, неограниченной истории, отображения прогресса генерации в реальном времени и многого другого.Управление моделями для стилизации (embeddings) Легко добавляйте модели с Huggingface прямо в «Инвок», используя токен для создания нужного стиля (модель подтянется автоматически). Возможность одновременного использования нескольких моделей позволяет легко импортировать и изучать различные стили в рамках одной сессии!Просмотрщик В веб-интерфейсе теперь есть просмотрщик, позволяющее более детально изучить ваши генерации. Больше не нужно открывать изображения во внешнем файловом проводнике, даже если речь идет о больших картинках!Установка в 1 клик С автоматическими инсталляторами использование «Инвок» стало еще проще. Наши пакеты для разных ОС (Mac M1/M2, Windows и Linux) помогут вам настроить все необходимое. Наш инсталлятор с исходниками доступен сейчас, а исполняемые файлы появятся в ближайшие день-два. Нажимайте и начинайте!Поддержка семплера DPM++ (экспериментальная) Добавлена поддержка DPM++! Пожалуйста, обратите внимание, что это экспериментальный вариант, и он может быть изменен в будущем, так как мы продолжаем совершенствовать нашу внутреннюю систему.Что нас ждет? Мы постоянно обсуждаем и исследуем новые идеи, чтобы сделать InvokeAI лучшим приложением с каждым релизом. Начинается работа над созданием модульной архитектуры бэкенда, которая позволит нам поддерживать очереди, атомарное выполнение, легко добавлять новые функции и многое другое. В скором времени мы также официально добавим поддержку SD2.0. Если вы разработчик, который в настоящее время использует InvokeAI в качестве бэкенда, мы приглашаем вас присоединиться к обсуждению и предоставить обратную связь, чтобы мы могли создать лучшую систему из возможных.Наши ценности Поскольку InvokeAI все чаще используется творческими профессионалами и коммерческими проектами, мы считаем важным поделиться нашими ценностями с сообществом, которое решило поверить в нашу работу.Команда InvokeAI полностью привержена созданию инструментов, которые не только продвигают этот невероятный мир генеративного искусства дальше, но и расширяют возможности художников и креативщиков, которые играют ключевую роль в этой экосистеме. Мы считаем, что наша роль в разработке этого программного обеспечения этична, и стремимся осмысленно реагировать на все проблемы сообщества. Чтобы узнать больше, пожалуйста, ознакомьтесь с нашим заявлением здесь.Если вы разработчик, желающий развить или внести свой вклад в проект, профессионал, ищущий профессиональные инструменты для внедрения в свой рабочий процесс, или просто ищете отличный опыт работы с SD с открытым исходным кодом, мы будем рады, если вы присоединитесь к сообществу.Вы можете получить последнюю версию на GitHub, а также присоединиться к сообществу в discord здесь.О себе: Меня зовут Артур Нецветаев, я менеджер продуктов, предприниматель и дизайнер интерфейсов. Я участвую в разработке интерфейса InvokeAI и пользуюсь им сам с момента создания.",
        "meta_tags": [
            "ai",
            "stablediffusion",
            "invokeai",
            "neural networks",
            "neural paintings",
            "image processing",
            "graphic design",
            "нейросети",
            "machinelearning",
            "дизайн интерфейсов"
        ]
    },
    {
        "publish_datetime": 1669986394.0,
        "author": "Артур Шарк",
        "title": "Заполнить виджет градиентом, изображением или гифкой с помощью ShaderMask",
        "title_image_url": "https://habrastorage.org/getpro/habr/upload_files/111/821/55d/11182155d5ffaca2883f09b5c6218fbe.png",
        "raw_body": "<div xmlns=\"http://www.w3.org/1999/xhtml\"><figure class=\"\"><img src=\"https://habrastorage.org/r/w780q1/getpro/habr/upload_files/270/92a/678/27092a678ca8cbf222a39d21226ee0fd.jpeg\" alt=\"\" title=\"\" width=\"auto\" height=\"auto\" data-src=\"https://habrastorage.org/getpro/habr/upload_files/270/92a/678/27092a678ca8cbf222a39d21226ee0fd.jpeg\" data-blurred=\"true\"/><figcaption></figcaption></figure><p>Один из наиболее популярных способов сделать элемент UI выразительным и аутентичным состоит в том, чтобы заполнить его картинкой, градиентом или анимированной гифкой.</p><p>Ниже приведен пример реализации данных эффектов на Flutter. Представленный подход будет работать с любым виджетом на всех поддерживаемых платформах. В качестве примера мы будем заполнять графикой Text.</p><h2>План</h2><p>Реализация будет идти по сценарию, предложенному командой разработчиков Flutter в серии видео \"Widget of the Week\".</p><div class=\"tm-iframe_temp\" data-src=\"https://embedd.srv.habr.com/iframe/637c8d6961ecc8ef4a7a57a0\" data-style=\"\" id=\"637c8d6961ecc8ef4a7a57a0\" width=\"\"></div><p><strong>Основные шаги для заполнения текста графикой:</strong></p><ol><li><p>Создать TextChild виджет для отображения текста.</p></li><li><p>Создать <a href=\"https://api.flutter.dev/flutter/dart-ui/Shader-class.html\" rel=\"noopener noreferrer nofollow\">Shader</a> с нашей кастомной графикой.</p></li><li><p>Применить Shader к TextChild с помощью <a href=\"https://api.flutter.dev/flutter/widgets/ShaderMask-class.html\" rel=\"noopener noreferrer nofollow\">ShaderMask</a>.</p></li></ol><pre><code class=\"dart\">Widget buildBeautifulText() {\n  // 1. Create text child\n  final textChild = TextChild();\n  \n  // 2. Create shader\n  final shaderCallback = createShader();\n  \n  // 3. Apply shader to text child\n  return ShaderMask(\n    blendMode: BlendMode.srcIn,\n    shaderCallback: shaderCallback,\n    child: textChild,\n  );\n}</code></pre><h2>Кейс 1. Шейдер градиента</h2><figure class=\"\"><img src=\"https://habrastorage.org/r/w780q1/getpro/habr/upload_files/585/37a/f1c/58537af1c6c0a7ebac032f8beda2e72c.jpeg\" alt=\"\" title=\"\" width=\"auto\" height=\"auto\" data-src=\"https://habrastorage.org/getpro/habr/upload_files/585/37a/f1c/58537af1c6c0a7ebac032f8beda2e72c.jpeg\" data-blurred=\"true\"/><figcaption></figcaption></figure><p>Заполнить виджет градиентом достаточно легко, и при удачном применении данного эффекта можно получить весьма впечатляющие результаты. Для реализации нам потребуется описать желаемый градиент и попросить его создать шейдер. Полученный шейдер можно сразу применить к дочернему виджету, используя ShaderMask.</p><pre><code class=\"dart\">// Create gradient shader\nShaderCallback gradientShader() {\n  // Define linear gradient\n  const gradient = LinearGradient(\n    colors: [\n      Colors.red,\n      Colors.blue,\n    ],\n    begin: Alignment.topLeft,\n    end: Alignment.bottomRight,\n    tileMode: TileMode.mirror,\n  );\n  // Create shader\n  final shaderCallback = gradient.createShader;\n  return shaderCallback;\n}\n\n// Build text with gradient shader\nWidget buildBeautifulText() {\n  // 1. Create text child\n  final textChild = TextChild();\n\n  // 2. Create shader callback\n  final shaderCallback = gradientShader();\n\n  // 3. Apply shader to text child\n  return ShaderMask(\n    blendMode: BlendMode.srcIn,\n    shaderCallback: shaderCallback,\n    child: textChild,\n  );\n}</code></pre><p>В примере мы использовали линейный градиент от красного к синему. Процесс можно также повторить с градиентами любого типа (<a href=\"https://api.flutter.dev/flutter/painting/LinearGradient-class.html\" rel=\"noopener noreferrer nofollow\">Linear</a>, <a href=\"https://api.flutter.dev/flutter/painting/RadialGradient-class.html\" rel=\"noopener noreferrer nofollow\">Radial</a>, <a href=\"https://api.flutter.dev/flutter/painting/SweepGradient-class.html\" rel=\"noopener noreferrer nofollow\">Sweep</a>). </p><p>Полный код для данного кейса можно посмотреть и запустить через <a href=\"https://dartpad.dev/3a10925e525aafb17f7675dda73d834a\" rel=\"noopener noreferrer nofollow\">DartPad</a>.</p><h2>Кейс 2. Шейдер изображения</h2><figure class=\"full-width \"><img src=\"https://habrastorage.org/getpro/habr/upload_files/eb3/c7a/97f/eb3c7a97f44e16cafae7e7e61e0a3666.gif\" alt=\"\" title=\"\" width=\"796\" height=\"415\" data-src=\"https://habrastorage.org/getpro/habr/upload_files/eb3/c7a/97f/eb3c7a97f44e16cafae7e7e61e0a3666.gif\"/><figcaption></figcaption></figure><p>В Flutter есть класс <a href=\"https://api.flutter.dev/flutter/dart-ui/ImageShader-class.html\" rel=\"noopener noreferrer nofollow\">ImageShader</a>, который позволяет создавать шейдеры для изображений. Для этого необходимо передать ему <em>данные изображения</em>.</p><p><strong>Шаг 1. Создать ImageProvider</strong></p><p>Мы будем использовать <a href=\"https://api.flutter.dev/flutter/painting/ImageProvider-class.html\" rel=\"noopener noreferrer nofollow\">ImageProvider</a>, чтобы получить <em>данные изображения</em> из любого доступного источника (<a href=\"https://api.flutter.dev/flutter/painting/NetworkImage-class.html\" rel=\"noopener noreferrer nofollow\">сеть</a>, <a href=\"https://api.flutter.dev/flutter/painting/AssetImage-class.html\" rel=\"noopener noreferrer nofollow\">assets</a>,  <a href=\"https://api.flutter.dev/flutter/painting/FileImage-class.html\" rel=\"noopener noreferrer nofollow\">файл</a>, <a href=\"https://api.flutter.dev/flutter/painting/MemoryImage-class.html\" rel=\"noopener noreferrer nofollow\">память</a>). ImageProvider поддерживает форматы <code>JPEG</code>, <code>PNG</code>, <code>GIF</code>, <code>Animated GIF</code>, <code>WebP</code>, <code>Animated WebP</code>, <code>BMP</code> и <code>WBMP</code>.</p><pre><code class=\"dart\">// 1. Create ImageProvider\n// JPEG\nconst jpegProvider = NetworkImage(\n  'https://picsum.photos/1000',\n);\n\n// Animated GIF\nconst gifProvider = NetworkImage(\n  'https://media.giphy.com/media/5VKbvrjxpVJCM/giphy.gif',\n);</code></pre><p><strong>Шаг 2. Создать ImageShader для изображения</strong></p><p>ImageProvider поставляет нам экземпляры класса <a href=\"https://api.flutter.dev/flutter/dart-ui/Image-class.html\" rel=\"noopener noreferrer nofollow\">Image</a> из пакета <code>dart:ui</code>, которые мы можем передать в ImageShader, чтобы создать <a href=\"https://api.flutter.dev/flutter/rendering/ShaderCallback.html\" rel=\"noopener noreferrer nofollow\">ShaderCallback</a>. Данный колбэк создает шейдер с учетом границ поверхности, к которой он будет применен.</p><p>Мы заполним графикой весь прямоугольник. В этом процессе будем использовать преобразования матрицы <a href=\"https://api.flutter.dev/flutter/vector_math_64/Matrix4-class.html\" rel=\"noopener noreferrer nofollow\">Matrix4</a>, чтобы изменить размер и отцентровать изображение.</p><p>Можно пойти альтернативным путем и вместо изменений матрицы изменить <a href=\"https://api.flutter.dev/flutter/dart-ui/TileMode.html\" rel=\"noopener noreferrer nofollow\">TileMode</a>. Режимы <code>mirror</code> и <code>repeat</code> должны хорошо себя проявить при работе с повторяющимися узорами.</p><p>Код этого шага можно изменить, чтобы настроить сочетания Matrix4 и TileMode для реализации своего уникального дизайна.</p><pre><code class=\"dart\">// 2. Create image shader for given Rect size\nShaderCallback createImageShader(ui.Image image) {\n  shaderCalback(Rect bounds) {\n    // Calculate scale for X and Y sides\n    final scaleX = bounds.width / image.width;\n    final scaleY = bounds.height / image.height;\n    final scale = max(scaleX, scaleY);\n    // Calculate offset to center resized image\n    final scaledImageWidth = image.width * scale;\n    final sacledImageHeight = image.height * scale;\n    final offset = Offset(\n      (scaledImageWidth - bounds.width) / 2,\n      (sacledImageHeight - bounds.height) / 2,\n    );\n    final matrix = Matrix4.identity()\n      // Scale image\n      ..scale(scale, scale)\n      // Center horizontally and vertically\n      ..leftTranslate(\n        -offset.dx,\n        -offset.dy,\n      );\n    // Image shader\n    return ImageShader(\n      image,\n      TileMode.decal,\n      TileMode.decal,\n      matrix.storage,\n    );\n  }</code></pre><p><strong>Шаг 3. Подписаться на ImageStream</strong></p><p>При использовании ImageProvider у нас есть возможность подписаться на <a href=\"https://api.flutter.dev/flutter/painting/ImageStream-class.html\" rel=\"noopener noreferrer nofollow\">ImageStream</a>, который отслеживает текущий кадр изображения. Подписка на данный поток позволит нам реагировать на изменения изображения, которые происходят в  результате анимаций или изменений исходного ресурса изображения.</p><p>Документация Flutter уже содержит <a href=\"https://api.flutter.dev/flutter/painting/ImageProvider-class.html\" rel=\"noopener noreferrer nofollow\">код</a> использования ImageStream в виджете. Нам остается лишь изменить его метод <code>build</code> и добавить поле <code>child</code> для дочернего виджета.</p><p>Добавляем поле <code>child</code>:</p><pre><code class=\"dart\">// See MyImage class from Flutter docs\n// https://api.flutter.dev/flutter/painting/ImageProvider-class.html\nclass ImageShaderBuilder extends StatefulWidget {\n  const ImageShaderBuilder({\n    super.key,\n    required this.imageProvider,\n    // Add child widget\n    required this.child,\n  });\n\n  // Add child widget\n  final Widget child;\n  final ImageProvider imageProvider;\n\n  @override\n  State&lt;ImageShaderBuilder> createState() => _ImageShaderBuilderState();\n}</code></pre><p>Изменяем метод <code>build</code>:</p><pre><code class=\"dart\">// See MyImage class from Flutter docs\n// https://api.flutter.dev/flutter/painting/ImageProvider-class.html\nclass _ImageShaderBuilderState extends State&lt;ImageShaderBuilder> {\n  \n  // Keep the source code\n\n  // Change only build method\n  @override\n  Widget build(BuildContext context) {\n    final image = _imageInfo?.image;\n    // No image for shader -> show child\n    if (image == null) {\n      return widget.child;\n    }\n    final shaderCallback = createImageShader(image);\n    // Apply shader to the child\n    return ShaderMask(\n      blendMode: BlendMode.srcIn,\n      shaderCallback: shaderCallback,\n      child: widget.child,\n    );\n  }\n}</code></pre><p><strong>Шаг 4. Использовать шейдер изображения</strong></p><p>Теперь мы можем использовать <code>ImageShaderBuilder</code> для реализации ярких и запоминающихся пользовательских интерфейсов.</p><pre><code class=\"dart\">Widget buildBeautifulText() {\n  // 1. Create text child\n  const textChild = TextChild();\n\n  // 2. Create ImageProvider\n  const imageProvider = NetworkImage(\n    'https://media.giphy.com/media/5VKbvrjxpVJCM/giphy.gif',\n  );\n\n  // 3. Apply shader to text child\n  return const ImageShaderBuilder(\n    imageProvider: imageProvider,\n    child: textChild,\n  );\n}</code></pre><p>Полный код для данного кейса можно посмотреть и запустить через <a href=\"https://dartpad.dev/bd2b5913a16c9aa38ad84d0059806cee\" rel=\"noopener noreferrer nofollow\">DartPad</a>.</p><h2>Заключение</h2><p>Благодарю за чтение! </p><p>Не стесняйтесь писать внизу свои мысли, предложения и пожелания по поводу данной статьи. Я буду рад учесть их в своих следующих публикациях, а также отвечу на любые вопросы в комментариях.</p><p>Ставьте лайки, если статья оказалась полезна.</p><p><strong>Об авторе</strong></p><ul><li><p><em>Имя:</em> Иван Мосягин (<a href=\"https://www.linkedin.com/in/mosivan/\" rel=\"noopener noreferrer nofollow\">LinkedIn</a>)</p></li><li><p><em>Компания:</em> Shark Company (<a href=\"https://www.linkedin.com/company/sharkcompany/\" rel=\"noopener noreferrer nofollow\">LinkedIn</a>)</p></li><li><p><em>Должность:</em> Flutter Developer</p></li></ul><p></p></div>",
        "clean_body": "Один из наиболее популярных способов сделать элемент UI выразительным и аутентичным состоит в том, чтобы заполнить его картинкой, градиентом или анимированной гифкой.Ниже приведен пример реализации данных эффектов на Flutter. Представленный подход будет работать с любым виджетом на всех поддерживаемых платформах. В качестве примера мы будем заполнять графикой Text.ПланРеализация будет идти по сценарию, предложенному командой разработчиков Flutter в серии видео \"Widget of the Week\".Основные шаги для заполнения текста графикой:Создать TextChild виджет для отображения текста.Создать Shader с нашей кастомной графикой.Применить Shader к TextChild с помощью ShaderMask.Widget buildBeautifulText() {\n  // 1. Create text child\n  final textChild = TextChild();\n  \n  // 2. Create shader\n  final shaderCallback = createShader();\n  \n  // 3. Apply shader to text child\n  return ShaderMask(\n    blendMode: BlendMode.srcIn,\n    shaderCallback: shaderCallback,\n    child: textChild,\n  );\n}Кейс 1. Шейдер градиентаЗаполнить виджет градиентом достаточно легко, и при удачном применении данного эффекта можно получить весьма впечатляющие результаты. Для реализации нам потребуется описать желаемый градиент и попросить его создать шейдер. Полученный шейдер можно сразу применить к дочернему виджету, используя ShaderMask.// Create gradient shader\nShaderCallback gradientShader() {\n  // Define linear gradient\n  const gradient = LinearGradient(\n    colors: [\n      Colors.red,\n      Colors.blue,\n    ],\n    begin: Alignment.topLeft,\n    end: Alignment.bottomRight,\n    tileMode: TileMode.mirror,\n  );\n  // Create shader\n  final shaderCallback = gradient.createShader;\n  return shaderCallback;\n}\n\n// Build text with gradient shader\nWidget buildBeautifulText() {\n  // 1. Create text child\n  final textChild = TextChild();\n\n  // 2. Create shader callback\n  final shaderCallback = gradientShader();\n\n  // 3. Apply shader to text child\n  return ShaderMask(\n    blendMode: BlendMode.srcIn,\n    shaderCallback: shaderCallback,\n    child: textChild,\n  );\n}В примере мы использовали линейный градиент от красного к синему. Процесс можно также повторить с градиентами любого типа (Linear, Radial, Sweep). Полный код для данного кейса можно посмотреть и запустить через DartPad.Кейс 2. Шейдер изображенияВ Flutter есть класс ImageShader, который позволяет создавать шейдеры для изображений. Для этого необходимо передать ему данные изображения.Шаг 1. Создать ImageProviderМы будем использовать ImageProvider, чтобы получить данные изображения из любого доступного источника (сеть, assets,  файл, память). ImageProvider поддерживает форматы JPEG, PNG, GIF, Animated GIF, WebP, Animated WebP, BMP и WBMP.// 1. Create ImageProvider\n// JPEG\nconst jpegProvider = NetworkImage(\n  'https://picsum.photos/1000',\n);\n\n// Animated GIF\nconst gifProvider = NetworkImage(\n  'https://media.giphy.com/media/5VKbvrjxpVJCM/giphy.gif',\n);Шаг 2. Создать ImageShader для изображенияImageProvider поставляет нам экземпляры класса Image из пакета dart:ui, которые мы можем передать в ImageShader, чтобы создать ShaderCallback. Данный колбэк создает шейдер с учетом границ поверхности, к которой он будет применен.Мы заполним графикой весь прямоугольник. В этом процессе будем использовать преобразования матрицы Matrix4, чтобы изменить размер и отцентровать изображение.Можно пойти альтернативным путем и вместо изменений матрицы изменить TileMode. Режимы mirror и repeat должны хорошо себя проявить при работе с повторяющимися узорами.Код этого шага можно изменить, чтобы настроить сочетания Matrix4 и TileMode для реализации своего уникального дизайна.// 2. Create image shader for given Rect size\nShaderCallback createImageShader(ui.Image image) {\n  shaderCalback(Rect bounds) {\n    // Calculate scale for X and Y sides\n    final scaleX = bounds.width / image.width;\n    final scaleY = bounds.height / image.height;\n    final scale = max(scaleX, scaleY);\n    // Calculate offset to center resized image\n    final scaledImageWidth = image.width * scale;\n    final sacledImageHeight = image.height * scale;\n    final offset = Offset(\n      (scaledImageWidth - bounds.width) / 2,\n      (sacledImageHeight - bounds.height) / 2,\n    );\n    final matrix = Matrix4.identity()\n      // Scale image\n      ..scale(scale, scale)\n      // Center horizontally and vertically\n      ..leftTranslate(\n        -offset.dx,\n        -offset.dy,\n      );\n    // Image shader\n    return ImageShader(\n      image,\n      TileMode.decal,\n      TileMode.decal,\n      matrix.storage,\n    );\n  }Шаг 3. Подписаться на ImageStreamПри использовании ImageProvider у нас есть возможность подписаться на ImageStream, который отслеживает текущий кадр изображения. Подписка на данный поток позволит нам реагировать на изменения изображения, которые происходят в  результате анимаций или изменений исходного ресурса изображения.Документация Flutter уже содержит код использования ImageStream в виджете. Нам остается лишь изменить его метод build и добавить поле child для дочернего виджета.Добавляем поле child:// See MyImage class from Flutter docs\n// https://api.flutter.dev/flutter/painting/ImageProvider-class.html\nclass ImageShaderBuilder extends StatefulWidget {\n  const ImageShaderBuilder({\n    super.key,\n    required this.imageProvider,\n    // Add child widget\n    required this.child,\n  });\n\n  // Add child widget\n  final Widget child;\n  final ImageProvider imageProvider;\n\n  @override\n  State<ImageShaderBuilder> createState() => _ImageShaderBuilderState();\n}Изменяем метод build:// See MyImage class from Flutter docs\n// https://api.flutter.dev/flutter/painting/ImageProvider-class.html\nclass _ImageShaderBuilderState extends State<ImageShaderBuilder> {\n  \n  // Keep the source code\n\n  // Change only build method\n  @override\n  Widget build(BuildContext context) {\n    final image = _imageInfo?.image;\n    // No image for shader -> show child\n    if (image == null) {\n      return widget.child;\n    }\n    final shaderCallback = createImageShader(image);\n    // Apply shader to the child\n    return ShaderMask(\n      blendMode: BlendMode.srcIn,\n      shaderCallback: shaderCallback,\n      child: widget.child,\n    );\n  }\n}Шаг 4. Использовать шейдер изображенияТеперь мы можем использовать ImageShaderBuilder для реализации ярких и запоминающихся пользовательских интерфейсов.Widget buildBeautifulText() {\n  // 1. Create text child\n  const textChild = TextChild();\n\n  // 2. Create ImageProvider\n  const imageProvider = NetworkImage(\n    'https://media.giphy.com/media/5VKbvrjxpVJCM/giphy.gif',\n  );\n\n  // 3. Apply shader to text child\n  return const ImageShaderBuilder(\n    imageProvider: imageProvider,\n    child: textChild,\n  );\n}Полный код для данного кейса можно посмотреть и запустить через DartPad.ЗаключениеБлагодарю за чтение! Не стесняйтесь писать внизу свои мысли, предложения и пожелания по поводу данной статьи. Я буду рад учесть их в своих следующих публикациях, а также отвечу на любые вопросы в комментариях.Ставьте лайки, если статья оказалась полезна.Об автореИмя: Иван Мосягин (LinkedIn)Компания: Shark Company (LinkedIn)Должность: Flutter Developer",
        "meta_tags": [
            "flutter",
            "ui",
            "программирование",
            "интерфейс",
            "разработка по",
            "how-to",
            "графика",
            "мобильная разработка",
            "веб-дизайн",
            "frontend"
        ]
    },
    {
        "publish_datetime": 1669991225.0,
        "author": null,
        "title": "Советы по отладке при работе над проектами Swift",
        "title_image_url": "https://habrastorage.org/getpro/habr/upload_files/5cd/722/5bc/5cd7225bc2afaee5aac7f984cfb71b7e.webp",
        "raw_body": "<div xmlns=\"http://www.w3.org/1999/xhtml\"><p>Вот несколько моих любимых трюков и советов по отладке, которые я использую при работе над проектами Swift.</p><figure class=\"full-width \"><img src=\"https://habrastorage.org/getpro/habr/upload_files/5cd/722/5bc/5cd7225bc2afaee5aac7f984cfb71b7e.webp\" width=\"699\" height=\"466\"/><figcaption></figcaption></figure><h2>Настройте свой .lldbinit</h2><p>Во-первых, большинство из нас хотят работать со Swift, а не с Objective-C, но в зависимости от настроек вашего проекта у вас по умолчанию может быть включен Objective-C. У нас есть 2 варианта:</p><ul><li><p>Мы можем вручную изменить язык во время сеанса lldb, вызвав <em>settings set target.language swift</em></p></li><li><p>Мы можем создать файл <em>.lldbinit</em> в нашем домашнем каталоге и добавить его туда по умолчанию для всех сеансов отладки, например: <em>echo 'Settings set target.language swift' > ~/.lldbinit</em>, за которым следует <em>chmod +x ~/.lldbinit</em></p></li></ul><p>Кроме того, <em>.lldbinit</em> — отличное место для добавления дополнительных вещей, которые вы будете использовать в своих проектах. Вот часть моих:</p><pre><code class=\"swift\">settings set target.language swift\n\nbreakpoint set -r NSWindow.initialFirstResponder --one-shot true --auto-continue true\nbreakpoint command add\ne import AppKit\ne import Foundation\ne func $vc&lt;T>(_ input: T) -> NSViewController { unsafeBitCast(input, to: NSViewController.self) }\ne func $view&lt;T>(_ input: T) -> NSView { unsafeBitCast(input, to: NSView.self) }\nDONE\n\nbreakpoint set -n UIApplicationMain --one-shot true --auto-continue true\nbreakpoint command add\ne import UIKit\ne import Foundation\ne func $vc&lt;T>(_ input: T) -> UIViewController { unsafeBitCast(input, to: UIViewController.self) }\ne func $view&lt;T>(_ input: T) -> UIView { unsafeBitCast(input, to: UIView.self) }\nDONE</code></pre><p>Это позволяет мне использовать адрес памяти, чтобы легко получить информацию о моих типах:</p><p><strong><em>po $vc(0x128027ad400)</em></strong></p><p>Примечания:</p><ul><li><p>Использование <strong>$</strong> для имен переменных и функций — это то, как мы получаем эти вещи, доступные за пределами только текущего контекста выражения, от Apple:</p><figure class=\"full-width \"><img src=\"https://habrastorage.org/r/w1560/getpro/habr/upload_files/758/e73/397/758e7339783b0aca449704162a382e2b.png\" alt=\"\" title=\"\" width=\"687\" height=\"213\" data-src=\"https://habrastorage.org/getpro/habr/upload_files/758/e73/397/758e7339783b0aca449704162a382e2b.png\"/><figcaption></figcaption></figure></li></ul><ul><li><p>Мы настраиваем начальный брейкпоинт (точка останова или точка прерывания) как триггер для добавления новых функций в систему. В противном случае они не будут работать, поскольку выражения не оцениваются как часть инициализации lldb из-за отсутствия кадров стека.</p></li><li><p>Я работаю как в контексте Mac, так и в iOS, поэтому я устанавливаю 2 отдельных брейкпоинта и варианты общих функций, которые я использую.</p></li></ul><h3>Используйте переменные фрейма</h3><p>Большинство разработчиков Swift привыкли использовать <em>print object</em> или сокращенно <em>po</em>, но есть альтернатива, которая часто работает быстрее и работает в тех случаях, когда po может не сработать: <em>frame variable</em> или <em>v</em></p><p>Короткий псевдоним был добавлен еще в Xcode 10.2, и вот примечание Apple об этом:</p><figure class=\"full-width \"><img src=\"https://habrastorage.org/r/w1560/getpro/habr/upload_files/d80/ca5/262/d80ca52624cf8d7cdffd3b655f7d2ce5.png\" width=\"966\" height=\"217\" data-src=\"https://habrastorage.org/getpro/habr/upload_files/d80/ca5/262/d80ca52624cf8d7cdffd3b655f7d2ce5.png\"/><figcaption></figcaption></figure><p><strong><u>🤔 </u><em><u>v</u></em><u> и </u><em><u>vo</u></em><u> работают для сохраненных свойств, но не будут работать для вычисляемых. Вам понадобится po для них.</u></strong>  </p><p>Вот пример:</p><figure class=\"full-width \"><img src=\"https://habrastorage.org/r/w1560/getpro/habr/upload_files/711/b15/f3c/711b15f3cf01c87114689ea7d2b22aa5.png\" width=\"1004\" height=\"440\" data-src=\"https://habrastorage.org/getpro/habr/upload_files/711/b15/f3c/711b15f3cf01c87114689ea7d2b22aa5.png\"/><figcaption></figcaption></figure><p>Вы можете добавить к нему дополнительные флажки, как например опцию <strong>-O</strong>, чтобы получить еще больше информации.</p><h3>Используйте выражения</h3><p>Вышеупомянутый <strong>po</strong> — это псевдоним для <strong>e -O -</strong>, который оценит объект и попытается вызвать для него метод <em>description</em>, если он существует, он оценит данное выражение, а затем попытается вызвать для него метод <em>description</em>.</p><p>Но выражения более ценны, и было бы целесообразно использовать их напрямую, а не полагаться на <em>po</em>.</p><p>Мы можем взаимодействовать с нашей системой, используя <em>e</em> или <em>expression</em>, это может быть очень удобно при работе с переменными:</p><pre><code class=\"swift\">e var $vc = self.controller\ne $vc.view.layer.borderColor = CGColor.red\ne CATransation.flush() // Refresh the core animation screen without having to end debugging session</code></pre><h3>Наблюдайте за системой</h3><p>Мы можем использовать брейкпоинты для многих вещей, от изменения вводимых (*входных) данных по умолчанию в поля (например, формы входа):</p><figure class=\"full-width \"><img src=\"https://habrastorage.org/r/w1560/getpro/habr/upload_files/71f/a73/87c/71fa7387c338a68a75368cc0f9f54eb3.png\" width=\"580\" height=\"268\" data-src=\"https://habrastorage.org/getpro/habr/upload_files/71f/a73/87c/71fa7387c338a68a75368cc0f9f54eb3.png\"/><figcaption></figcaption></figure><p>До использования команд отладчика для создания цепочек символических брейкпоинтов, например:  </p><p><strong><em><u>breakpoint set --name \"[CommandBarInputContainer layout]\"</u></em></strong><em>  </em></p><p>создавал бы точку останова при вызове макета моего NSView. Это происходило бы слишком часто, но я бы мог установить её как часть выполнения другого брейкпоинта, например, когда пользователь меняет ввод текста.</p><p>Я также мог бы использовать <em>--one-shot true</em>, чтобы точка останова выполнялась только один раз для каждого триггера.</p><h3>Наблюдайте за изменением переменной</h3><p>Мы можем добавить брейкпоинты при изменении переменной либо с помощью пользовательского интерфейса Xcode, либо с помощью команды lldb:</p><p><strong><em><u>watchpoint set variable self.homeViewController</u></em></strong></p><figure class=\"\"><img src=\"https://habrastorage.org/getpro/habr/upload_files/3a6/5ad/e64/3a65ade6454fdc2bf6681d3fe40fb69a.webp\" alt=\"Watchpoint UI\" title=\"Watchpoint UI\" width=\"500\" height=\"535\"/><figcaption>Watchpoint UI</figcaption></figure><p>Затем всякий раз, когда эта переменная изменяется, Xcode останавливает наш сеанс отладки и предоставляет нам такую информацию:</p><figure class=\"\"><img src=\"https://habrastorage.org/getpro/habr/upload_files/6f6/0c4/e3b/6f60c4e3bbd65416771cc9d408325414.webp\" width=\"432\" height=\"166\"/><figcaption></figcaption></figure><p>Затем мы можем распечатать и взаимодействовать с этим значением:</p><pre><code class=\"swift\">po value\n▿ Optional&lt;NSViewController>\n  ▿ some : &lt;HomeButton.HomeViewController: 0x13407cf3ac0></code></pre><h3>Какие ваши любимые?</h3><p>Дайте мне знать, какие у вас любимые советы или команды lldb!</p><p><a href=\"https://twitter.com/intent/follow?original_referer=https%3A%2F%2Fwww.merowing.info%2F&amp;ref_src=twsrc%5Etfw%7Ctwcamp%5Ebuttonembed%7Ctwterm%5Efollow%7Ctwgr%5Emerowing_&amp;region=follow_link&amp;screen_name=merowing_\" rel=\"noopener noreferrer nofollow\">Follow @merowing_</a></p><p><a href=\"https://www.merowing.info/swift-debugging-tips/\" rel=\"noopener noreferrer nofollow\">Оригинал статьи</a></p><p>Подписывайся на наши соцсети: <a href=\"https://t.me/swiftbook_news\" rel=\"noopener noreferrer nofollow\">Telegram</a> / <a href=\"https://vk.com/swiftbook\" rel=\"noopener noreferrer nofollow\">VKontakte</a><br/>Вступай в открытый чат для iOS-разработчиков: <a href=\"https://zen.yandex.ru/profile/editor/id/62305a2685b4d86601d09326/630e1238f8df182ac8cc30ab/t.me/swiftbook_chat\" rel=\"noopener noreferrer nofollow\">t.me/swiftbook_chat</a><br/>Смотри <a href=\"https://swiftbook.org/shop\" rel=\"noopener noreferrer nofollow\">бесплатные уроки по iOS-разработке с нуля</a></p><p></p></div>",
        "clean_body": "Вот несколько моих любимых трюков и советов по отладке, которые я использую при работе над проектами Swift.Настройте свой .lldbinitВо-первых, большинство из нас хотят работать со Swift, а не с Objective-C, но в зависимости от настроек вашего проекта у вас по умолчанию может быть включен Objective-C. У нас есть 2 варианта:Мы можем вручную изменить язык во время сеанса lldb, вызвав settings set target.language swiftМы можем создать файл .lldbinit в нашем домашнем каталоге и добавить его туда по умолчанию для всех сеансов отладки, например: echo 'Settings set target.language swift' > ~/.lldbinit, за которым следует chmod +x ~/.lldbinitКроме того, .lldbinit — отличное место для добавления дополнительных вещей, которые вы будете использовать в своих проектах. Вот часть моих:settings set target.language swift\n\nbreakpoint set -r NSWindow.initialFirstResponder --one-shot true --auto-continue true\nbreakpoint command add\ne import AppKit\ne import Foundation\ne func $vc<T>(_ input: T) -> NSViewController { unsafeBitCast(input, to: NSViewController.self) }\ne func $view<T>(_ input: T) -> NSView { unsafeBitCast(input, to: NSView.self) }\nDONE\n\nbreakpoint set -n UIApplicationMain --one-shot true --auto-continue true\nbreakpoint command add\ne import UIKit\ne import Foundation\ne func $vc<T>(_ input: T) -> UIViewController { unsafeBitCast(input, to: UIViewController.self) }\ne func $view<T>(_ input: T) -> UIView { unsafeBitCast(input, to: UIView.self) }\nDONEЭто позволяет мне использовать адрес памяти, чтобы легко получить информацию о моих типах:po $vc(0x128027ad400)Примечания:Использование $ для имен переменных и функций — это то, как мы получаем эти вещи, доступные за пределами только текущего контекста выражения, от Apple:Мы настраиваем начальный брейкпоинт (точка останова или точка прерывания) как триггер для добавления новых функций в систему. В противном случае они не будут работать, поскольку выражения не оцениваются как часть инициализации lldb из-за отсутствия кадров стека.Я работаю как в контексте Mac, так и в iOS, поэтому я устанавливаю 2 отдельных брейкпоинта и варианты общих функций, которые я использую.Используйте переменные фреймаБольшинство разработчиков Swift привыкли использовать print object или сокращенно po, но есть альтернатива, которая часто работает быстрее и работает в тех случаях, когда po может не сработать: frame variable или vКороткий псевдоним был добавлен еще в Xcode 10.2, и вот примечание Apple об этом:🤔 v и vo работают для сохраненных свойств, но не будут работать для вычисляемых. Вам понадобится po для них. Вот пример:Вы можете добавить к нему дополнительные флажки, как например опцию -O, чтобы получить еще больше информации.Используйте выраженияВышеупомянутый po — это псевдоним для e -O -, который оценит объект и попытается вызвать для него метод description, если он существует, он оценит данное выражение, а затем попытается вызвать для него метод description.Но выражения более ценны, и было бы целесообразно использовать их напрямую, а не полагаться на po.Мы можем взаимодействовать с нашей системой, используя e или expression, это может быть очень удобно при работе с переменными:e var $vc = self.controller\ne $vc.view.layer.borderColor = CGColor.red\ne CATransation.flush() // Refresh the core animation screen without having to end debugging sessionНаблюдайте за системойМы можем использовать брейкпоинты для многих вещей, от изменения вводимых (*входных) данных по умолчанию в поля (например, формы входа):До использования команд отладчика для создания цепочек символических брейкпоинтов, например:  breakpoint set --name \"[CommandBarInputContainer layout]\" создавал бы точку останова при вызове макета моего NSView. Это происходило бы слишком часто, но я бы мог установить её как часть выполнения другого брейкпоинта, например, когда пользователь меняет ввод текста.Я также мог бы использовать --one-shot true, чтобы точка останова выполнялась только один раз для каждого триггера.Наблюдайте за изменением переменнойМы можем добавить брейкпоинты при изменении переменной либо с помощью пользовательского интерфейса Xcode, либо с помощью команды lldb:watchpoint set variable self.homeViewControllerWatchpoint UIЗатем всякий раз, когда эта переменная изменяется, Xcode останавливает наш сеанс отладки и предоставляет нам такую информацию:Затем мы можем распечатать и взаимодействовать с этим значением:po value\n▿ Optional<NSViewController>\n  ▿ some : <HomeButton.HomeViewController: 0x13407cf3ac0>Какие ваши любимые?Дайте мне знать, какие у вас любимые советы или команды lldb!Follow @merowing_Оригинал статьиПодписывайся на наши соцсети: Telegram / VKontakteВступай в открытый чат для iOS-разработчиков: t.me/swiftbook_chatСмотри бесплатные уроки по iOS-разработке с нуля",
        "meta_tags": [
            "swift",
            "ios"
        ]
    },
    {
        "publish_datetime": 1669991654.0,
        "author": "Алексей",
        "title": "Делегаты в Swift на простом примере",
        "title_image_url": "https://habrastorage.org/getpro/habr/upload_files/85e/44b/504/85e44b5047c82dfe07c7fe15f81cd813.png",
        "raw_body": "<div xmlns=\"http://www.w3.org/1999/xhtml\"><h2>Эта статья для уровня trainee, а значит для совсем начинающих великолепных разработчиков</h2><p>Основная цель статьи - рассказать просто, на примере, как можно использовать паттерн делегирования в <code>Swift</code>. </p><p>Статья состоит из двух частей. Первая - удалим из проекта <code>Storyboard</code> и напишем кодом простой интерфейс. Вторая - разберем, как с помощью делегата передать данные на предыдущий контроллер. </p><h3>Часть 1</h3><p>Создаем новый проект, назовем его <code>DelegatePattern:</code></p><figure class=\"full-width \"><img src=\"https://habrastorage.org/r/w1560/getpro/habr/upload_files/85e/44b/504/85e44b5047c82dfe07c7fe15f81cd813.png\" alt=\"Галочки не понадобятся, Interface - Storyboard, Language - Swift. \" title=\"Галочки не понадобятся, Interface - Storyboard, Language - Swift. \" width=\"1474\" height=\"1068\" data-src=\"https://habrastorage.org/getpro/habr/upload_files/85e/44b/504/85e44b5047c82dfe07c7fe15f81cd813.png\"/><figcaption>Галочки не понадобятся, Interface - Storyboard, Language - Swift. </figcaption></figure><p>Размещать элементы будем кодом, поэтому удаляем <code>Storyboard</code> из проекта:</p><figure class=\"full-width \"><img src=\"https://habrastorage.org/r/w1560/getpro/habr/upload_files/eaa/af3/fd8/eaaaf3fd83df4faba16eb7986ab72752.png\" alt=\"Удаляем Main.storyboard\" title=\"Удаляем Main.storyboard\" width=\"554\" height=\"572\" data-src=\"https://habrastorage.org/getpro/habr/upload_files/eaa/af3/fd8/eaaaf3fd83df4faba16eb7986ab72752.png\"/><figcaption>Удаляем Main.storyboard</figcaption></figure><figure class=\"full-width \"><img src=\"https://habrastorage.org/r/w1560/getpro/habr/upload_files/944/1b2/91f/9441b291f8b458e6829175d9a93156ae.png\" alt=\"Выбираем Move to Trash - удалить в корзину\" title=\"Выбираем Move to Trash - удалить в корзину\" width=\"542\" height=\"652\" data-src=\"https://habrastorage.org/getpro/habr/upload_files/944/1b2/91f/9441b291f8b458e6829175d9a93156ae.png\"/><figcaption>Выбираем Move to Trash - удалить в корзину</figcaption></figure><p>Выбираем проект (стрелка 1), вкладка <code>General</code> и в разделе <code>Deployment Info</code> выделяем и удаляем <code>Main</code>(стрелка 2)</p><figure class=\"full-width \"><img src=\"https://habrastorage.org/r/w1560/getpro/habr/upload_files/3e4/058/c6f/3e4058c6fa10960aa82b1ca0d6939f83.png\" alt=\"Поле Main Interface должно остаться пустым\" title=\"Поле Main Interface должно остаться пустым\" width=\"2816\" height=\"1056\" data-src=\"https://habrastorage.org/getpro/habr/upload_files/3e4/058/c6f/3e4058c6fa10960aa82b1ca0d6939f83.png\"/><figcaption>Поле Main Interface должно остаться пустым</figcaption></figure><p>Переходим в файл <code>info.plist</code> (стрелка 1) и удаляем строку <code>Application Scene Manifest</code></p><figure class=\"full-width \"><img src=\"https://habrastorage.org/r/w1560/getpro/habr/upload_files/966/87b/e7a/96687be7aa57b9801cc07918ba70d84c.png\" alt=\"В итоге останется только строка Information Property List\" title=\"В итоге останется только строка Information Property List\" width=\"2388\" height=\"536\" data-src=\"https://habrastorage.org/getpro/habr/upload_files/966/87b/e7a/96687be7aa57b9801cc07918ba70d84c.png\"/><figcaption>В итоге останется только строка Information Property List</figcaption></figure><p>У нас не будет поддержки <code>IPad</code> - файл <code>SceneDelegate</code> можно тоже удалить:</p><figure class=\"full-width \"><img src=\"https://habrastorage.org/r/w1560/getpro/habr/upload_files/7c1/b6e/273/7c1b6e2735e06eac2fc74d205f44cccc.png\" alt=\"Вот так теперь выглядит проект\" title=\"Вот так теперь выглядит проект\" width=\"2384\" height=\"1636\" data-src=\"https://habrastorage.org/getpro/habr/upload_files/7c1/b6e/273/7c1b6e2735e06eac2fc74d205f44cccc.png\"/><figcaption>Вот так теперь выглядит проект</figcaption></figure><p>Так как<strong> </strong>мы удалили <code>Storyboard</code>, в файле <code>AppDelegate </code>объявим свойство <code>window</code>, а в методе <code>application didFinishLaunchingWithOptions</code>, нужно добавить код ниже, чтобы указать стартовый контороллер.  Остальные методы удалим, в нашем проекте они использоваться не будут.</p><pre><code class=\"swift\">var window: UIWindow?\n\nfunc application(_ application: UIApplication, didFinishLaunchingWithOptions launchOptions: [UIApplication.LaunchOptionsKey: Any]?) -> Bool {\n        \n        window = UIWindow(frame: UIScreen.main.bounds)\n        let rootVC = ViewController()\n        window?.rootViewController = rootVC\n        window?.makeKeyAndVisible()\n        \n        return true\n    }</code></pre><p>Теперь <code>AppDelegate</code> выглядит вот так: </p><figure class=\"full-width \"><img src=\"https://habrastorage.org/r/w1560/getpro/habr/upload_files/551/ead/2c6/551ead2c670f823083d10ed561bf9d69.png\" width=\"2848\" height=\"1166\" data-src=\"https://habrastorage.org/getpro/habr/upload_files/551/ead/2c6/551ead2c670f823083d10ed561bf9d69.png\"/><figcaption></figcaption></figure><p>Переходим во <code>ViewController</code>, в методе <code>viewDidLoad</code> добавляем фиолетовый цвет для  бэкграунда <code>view</code> контроллера: </p><figure class=\"full-width \"><img src=\"https://habrastorage.org/r/w1560/getpro/habr/upload_files/188/e85/f7a/188e85f7a25e707587bff509101d4185.png\" alt=\"view.backgroundColor = .purple\" title=\"view.backgroundColor = .purple\" width=\"2848\" height=\"1044\" data-src=\"https://habrastorage.org/getpro/habr/upload_files/188/e85/f7a/188e85f7a25e707587bff509101d4185.png\"/><figcaption>view.backgroundColor = .purple</figcaption></figure><p>Запускаем проект, и если все сделали верно, запустится симулятор с фиолетовым контроллером:</p><figure class=\"full-width \"><img src=\"https://habrastorage.org/r/w1560/getpro/habr/upload_files/7e8/3bf/037/7e83bf037ebf6637714b3380d759ebde.png\" width=\"2298\" height=\"1234\" data-src=\"https://habrastorage.org/getpro/habr/upload_files/7e8/3bf/037/7e83bf037ebf6637714b3380d759ebde.png\"/><figcaption></figcaption></figure><p>Отлично, теперь мы можем продолжать писать интерфейс в коде. Для начала создадим еще один <code>ViewController</code>. Нажимаем <code>Command + N</code> и выбираем <code>Cocoa Touch Class</code>:</p><figure class=\"full-width \"><img src=\"https://habrastorage.org/r/w1560/getpro/habr/upload_files/cdc/f34/242/cdcf342427613e6e92edda02002cf9c6.png\" width=\"1466\" height=\"1056\" data-src=\"https://habrastorage.org/getpro/habr/upload_files/cdc/f34/242/cdcf342427613e6e92edda02002cf9c6.png\"/><figcaption></figcaption></figure><p>Назовем его <code>SecondViewController:</code></p><figure class=\"full-width \"><img src=\"https://habrastorage.org/r/w1560/getpro/habr/upload_files/fdb/684/66d/fdb68466d3ef63864987bae366bd894b.png\" alt=\"После создания удалите весь закоментированый код из SecondViewController. \" title=\"После создания удалите весь закоментированый код из SecondViewController. \" width=\"1470\" height=\"1058\" data-src=\"https://habrastorage.org/getpro/habr/upload_files/fdb/684/66d/fdb68466d3ef63864987bae366bd894b.png\"/><figcaption>После создания удалите весь закоментированый код из SecondViewController. </figcaption></figure><p>Поработаем с <code>ViewController</code>, добавим на него кнопку перехода на <code>SecondViewController:</code></p><figure class=\"full-width \"><img src=\"https://habrastorage.org/r/w1560/getpro/habr/upload_files/f9f/9c9/2ff/f9f9c92ff664fb60daee0a9900233956.png\" alt=\"Строки 12 - 17\" title=\"Строки 12 - 17\" width=\"2294\" height=\"1200\" data-src=\"https://habrastorage.org/getpro/habr/upload_files/f9f/9c9/2ff/f9f9c92ff664fb60daee0a9900233956.png\"/><figcaption>Строки 12 - 17</figcaption></figure><p>Объявим новый метод <code>makeConstraints</code>, в нем добавим кнопку на <code>view</code> и создадим констрейнты. </p><pre><code class=\"swift\">    private func makeConstraints() {\n        \n        view.addSubview(toSecondViewControllerButton) // добавляем кнопку на view\n        NSLayoutConstraint.activate([\n            toSecondViewControllerButton.centerXAnchor.constraint(equalTo: view.centerXAnchor), // центр по оси Х\n            toSecondViewControllerButton.centerYAnchor.constraint(equalTo: view.centerYAnchor) // центр по оси Y\n        ])\n    }</code></pre><p>И обязательно, нужно установить значение свойства<code>button.translatesAutoresizingMaskIntoConstraints = false</code> в клоужере создания кнопки. Вот как теперь выглядит <code>ViewController</code>:</p><figure class=\"full-width \"><img src=\"https://habrastorage.org/r/w1560/getpro/habr/upload_files/964/c3a/aeb/964c3aaeb11ca107a4657a3d1b4c0e40.png\" alt=\"Что бы все заработало не забудьте добавить вызов makeConstraints() во viewDidLoad(). Строка 27. \" title=\"Что бы все заработало не забудьте добавить вызов makeConstraints() во viewDidLoad(). Строка 27. \" width=\"2302\" height=\"1632\" data-src=\"https://habrastorage.org/getpro/habr/upload_files/964/c3a/aeb/964c3aaeb11ca107a4657a3d1b4c0e40.png\"/><figcaption>Что бы все заработало не забудьте добавить вызов makeConstraints() во viewDidLoad(). Строка 27. </figcaption></figure><p>Проверим симулятор:</p><figure class=\"\"><img src=\"https://habrastorage.org/r/w1560/getpro/habr/upload_files/957/c26/09e/957c2609e03fe73d6987d6852a2ea7f4.png\" alt=\"Кнопка есть, все отлично. \" title=\"Кнопка есть, все отлично. \" width=\"410\" height=\"824\" data-src=\"https://habrastorage.org/getpro/habr/upload_files/957/c26/09e/957c2609e03fe73d6987d6852a2ea7f4.png\"/><figcaption>Кнопка есть, все отлично. </figcaption></figure><p>Теперь аналогично добавим UILabel, в нем в последующем и будем менять текст при возвращении из следующего контроллера. </p><details class=\"spoiler\"><summary>Можете сами потренироваться и создать лейбл. Если возникнут проблемы, подглядите здесь :)</summary><div class=\"spoiler__content\"><p>Первым делом добавим сам элемент UILabel:</p><figure class=\"full-width \"><img src=\"https://habrastorage.org/r/w1560/getpro/habr/upload_files/805/8f4/281/8058f4281a7737e40b5e3e3663e5e413.png\" alt=\"строка 21 - 26. Сразу зададим текст лейбла &quot;Standart text&quot;\" title=\"строка 21 - 26. Сразу зададим текст лейбла &quot;Standart text&quot;\" width=\"2300\" height=\"1144\" data-src=\"https://habrastorage.org/getpro/habr/upload_files/805/8f4/281/8058f4281a7737e40b5e3e3663e5e413.png\"/><figcaption>строка 21 - 26. Сразу зададим текст лейбла \"Standart text\"</figcaption></figure><p>Добавляем лейбл на <code>view</code> и, создадаем констрейнты, расширив метод <code>makeConstraints</code>:</p><pre><code class=\"swift\">    private func makeConstraints() {\n        \n        view.addSubview(toSecondViewControllerButton)\n        view.addSubview(someLabel)  // добавляем на экран\n        NSLayoutConstraint.activate([\n            toSecondViewControllerButton.centerXAnchor.constraint(equalTo: view.centerXAnchor),\n            toSecondViewControllerButton.centerYAnchor.constraint(equalTo: view.centerYAnchor),\n            \n            someLabel.centerXAnchor.constraint(equalTo: toSecondViewControllerButton.centerXAnchor), // центр по оси X\n            someLabel.centerYAnchor.constraint(equalTo: toSecondViewControllerButton.centerYAnchor, constant: 40) // центр по оси Y\n        ])\n    }</code></pre><p></p></div></details><p>Отлично, теперь на <code>view</code> есть кнопка и лейбл. Симулятор выглядят так:</p><figure class=\"full-width \"><img src=\"https://habrastorage.org/r/w1560/getpro/habr/upload_files/b39/711/c4e/b39711c4e481f21c825cc059d53891c1.png\" width=\"2306\" height=\"1750\" data-src=\"https://habrastorage.org/getpro/habr/upload_files/b39/711/c4e/b39711c4e481f21c825cc059d53891c1.png\"/><figcaption></figcaption></figure><p>Чтобы кнопка заработала и при ее нажатии открывался следующий экран, добавим ей свойство <code>button.addTarget():</code></p><figure class=\"full-width \"><img src=\"https://habrastorage.org/r/w1560/getpro/habr/upload_files/e8b/4a7/ea2/e8b4a7ea2c97a00d7f795bb57612cf3e.png\" alt=\"Строка 18\" title=\"Строка 18\" width=\"1438\" height=\"272\" data-src=\"https://habrastorage.org/getpro/habr/upload_files/e8b/4a7/ea2/e8b4a7ea2c97a00d7f795bb57612cf3e.png\"/><figcaption>Строка 18</figcaption></figure><p>Объявим метод<code>toSecondVCButtonPressed()</code>, который будет отрабатывать по нажатию на кнопку:</p><figure class=\"full-width \"><img src=\"https://habrastorage.org/r/w1560/getpro/habr/upload_files/7cc/de6/a3a/7ccde6a3ab54324cef8f9cff6e944e77.png\" width=\"1452\" height=\"290\" data-src=\"https://habrastorage.org/getpro/habr/upload_files/7cc/de6/a3a/7ccde6a3ab54324cef8f9cff6e944e77.png\"/><figcaption></figcaption></figure><p>Перейдем в <code>SecondViewController</code> и в методе <code>viewDidLoad()</code> добавим цвет бэкграунда <code>view</code> второго контроллера:</p><figure class=\"full-width \"><img src=\"https://habrastorage.org/r/w1560/getpro/habr/upload_files/6d9/73f/bd9/6d973fbd9bb890124b722a25d80a7c2c.png\" alt=\"Строка 15. \" title=\"Строка 15. \" width=\"2306\" height=\"836\" data-src=\"https://habrastorage.org/getpro/habr/upload_files/6d9/73f/bd9/6d973fbd9bb890124b722a25d80a7c2c.png\"/><figcaption>Строка 15. </figcaption></figure><p>Проверяем, что получилось, собираем проект. Если все сделано верно, по нажатию на кнопку <code>Go to second VC</code>, откроется второй контроллер с серым фоном. </p><figure class=\"\"><img src=\"https://habrastorage.org/getpro/habr/upload_files/dc7/f82/8ee/dc7f828ee0b1166de59be60b59f46dec.gif\" width=\"260\" height=\"598\" data-src=\"https://habrastorage.org/getpro/habr/upload_files/dc7/f82/8ee/dc7f828ee0b1166de59be60b59f46dec.gif\"/><figcaption></figcaption></figure><h3>Часть 2</h3><p>Пора приступать к передаче данных при закрытии \"серого\" контроллера. Как вы видели в названии статьи, будем использовать делегат :)</p><p>Объявим протокол <code>ViewControllerDelegate</code> в классе <code>ViewController</code> и обязательно укажем тип <code>AnyObject</code>. Это нужно для того, чтобы протокол работал с классами, а это, в свою очередь, позволит создавать слабые ссылки и избежать retain cycle между контроллерами. Наш протокол будет содержать только один метод - для замены текста в лейбле <code>ViewController</code>'a. </p><figure class=\"full-width \"><img src=\"https://habrastorage.org/r/w1560/getpro/habr/upload_files/22f/455/578/22f4555789f855240657af7c8d4000e2.png\" alt=\"Строки 10 - 12. \" title=\"Строки 10 - 12. \" width=\"1228\" height=\"312\" data-src=\"https://habrastorage.org/getpro/habr/upload_files/22f/455/578/22f4555789f855240657af7c8d4000e2.png\"/><figcaption>Строки 10 - 12. </figcaption></figure><p>Реализовывать метод протокола будет <code>ViewController</code>, подпишем его под протокол в <code>extension</code>'е и напишем логику для метода, которая будет менять текст:</p><figure class=\"full-width \"><img src=\"https://habrastorage.org/r/w1560/getpro/habr/upload_files/292/bcb/67b/292bcb67be617556cd50d6aee6e303ac.png\" width=\"1364\" height=\"264\" data-src=\"https://habrastorage.org/getpro/habr/upload_files/292/bcb/67b/292bcb67be617556cd50d6aee6e303ac.png\"/><figcaption></figcaption></figure><p>В аргумент <code>text</code>, находящийся на 68 строке, придет новый текст с другого контроллера, а на 69 строке мы заменим стандартный текст лейбла. </p><p>Если навести курсор на аргумент <code>text</code>, <code>Xcode</code> подсветит какой <code>text</code> к какому относится. </p><figure class=\"full-width \"><img src=\"https://habrastorage.org/r/w1560/getpro/habr/upload_files/5d1/119/dbc/5d1119dbc2a53ee58a09bdbfd98eee7c.png\" width=\"804\" height=\"248\" data-src=\"https://habrastorage.org/getpro/habr/upload_files/5d1/119/dbc/5d1119dbc2a53ee58a09bdbfd98eee7c.png\"/><figcaption></figcaption></figure><p>Переходим в <code>SecondViewController</code>. Помните мы создали протокол и объявили его <code>anyObject</code>? Теперь пора создать слабую ссылку, которая будет иметь тип делегата, она будет жить в <code>SecondViewController</code> и через нее мы сможем добраться до методов делегата. </p><figure class=\"full-width \"><img src=\"https://habrastorage.org/r/w1560/getpro/habr/upload_files/417/81e/20a/41781e20aee2cb5c95092b29c0a3d024.png\" alt=\"Строка 12\" title=\"Строка 12\" width=\"2296\" height=\"930\" data-src=\"https://habrastorage.org/getpro/habr/upload_files/417/81e/20a/41781e20aee2cb5c95092b29c0a3d024.png\"/><figcaption>Строка 12</figcaption></figure><p>Когда мы закрываем <code>SecondViewController</code>, смахивая его вниз, срабатывает метод <code>deinit</code>. В нашем примере это отличное место, чтобы передать новый текст в лейбл <code>ViewController</code>'a. Добираемся через переменную <code>delegate</code> до метода <code>newTextForLabel</code> и передаем в него новый текст для лейбла на первом контроллере <code>\"New text\"</code></p><figure class=\"full-width \"><img src=\"https://habrastorage.org/r/w1560/getpro/habr/upload_files/2e0/26a/785/2e026a785f4da81a6ea94193154dcac7.png\" alt=\"Строки 20 - 22\" title=\"Строки 20 - 22\" width=\"2310\" height=\"1010\" data-src=\"https://habrastorage.org/getpro/habr/upload_files/2e0/26a/785/2e026a785f4da81a6ea94193154dcac7.png\"/><figcaption>Строки 20 - 22</figcaption></figure><p>Как пример, если создать кнопку закрытия второго экрана, тогда <code>self.delegate?.newtextForLabel(text: \"New text\")</code> поселился бы в методе, срабатывающем по нажатию на кнопку закрытия. </p><p>Все почти готово, осталось дело за малой деталью, о которой лично я всегда забываю :) нужно сообщить нашему <code>SecondViewController</code>, кто будет его делегатом (то есть кто будет что-то делать с теми данными которые, он отправил). </p><p>Возвращаемся в <code>ViewController,</code> и там, где мы создавали для кнопки метод перехода на <code>SecondViewController</code> подпишемся под делегата:</p><figure class=\"full-width \"><img src=\"https://habrastorage.org/r/w1560/getpro/habr/upload_files/52b/c22/baf/52bc22baffb60f4dc9be339f5d3f6cd2.png\" alt=\"Строка 62. \" title=\"Строка 62. \" width=\"1308\" height=\"570\" data-src=\"https://habrastorage.org/getpro/habr/upload_files/52b/c22/baf/52bc22baffb60f4dc9be339f5d3f6cd2.png\"/><figcaption>Строка 62. </figcaption></figure><p>Собираем проект и проверяем:</p><figure class=\"\"><img src=\"https://habrastorage.org/getpro/habr/upload_files/6a5/750/13e/6a575013ed1e691da9c755605d5dd6b7.gif\" alt=\"\" title=\"\" width=\"260\" height=\"509\" data-src=\"https://habrastorage.org/getpro/habr/upload_files/6a5/750/13e/6a575013ed1e691da9c755605d5dd6b7.gif\"/><figcaption></figcaption></figure><p>PS: Почему текст обновляется с задержкой? Дело в том, что <code>deinit</code> выгружает контроллер из памяти, поэтому проходит какое-то количество времени, пока контроллер выгрузится и текст сменится. Если вы будете использовать делегат, например, в методе <code>UIViewController</code>'a - <code>dismiss()</code> или в вашем методе кнопки, то никаких задержек не будет. </p><p>GitHub с финальным проектом - <a href=\"https://github.com/ForestLamp/DelegatePattern\" rel=\"noopener noreferrer nofollow\">ссылка</a>. </p><p>Спасибо, что дочитали :)</p></div>",
        "clean_body": "Эта статья для уровня trainee, а значит для совсем начинающих великолепных разработчиковОсновная цель статьи - рассказать просто, на примере, как можно использовать паттерн делегирования в Swift. Статья состоит из двух частей. Первая - удалим из проекта Storyboard и напишем кодом простой интерфейс. Вторая - разберем, как с помощью делегата передать данные на предыдущий контроллер. Часть 1Создаем новый проект, назовем его DelegatePattern:Галочки не понадобятся, Interface - Storyboard, Language - Swift. Размещать элементы будем кодом, поэтому удаляем Storyboard из проекта:Удаляем Main.storyboardВыбираем Move to Trash - удалить в корзинуВыбираем проект (стрелка 1), вкладка General и в разделе Deployment Info выделяем и удаляем Main(стрелка 2)Поле Main Interface должно остаться пустымПереходим в файл info.plist (стрелка 1) и удаляем строку Application Scene ManifestВ итоге останется только строка Information Property ListУ нас не будет поддержки IPad - файл SceneDelegate можно тоже удалить:Вот так теперь выглядит проектТак как мы удалили Storyboard, в файле AppDelegate объявим свойство window, а в методе application didFinishLaunchingWithOptions, нужно добавить код ниже, чтобы указать стартовый контороллер.  Остальные методы удалим, в нашем проекте они использоваться не будут.var window: UIWindow?\n\nfunc application(_ application: UIApplication, didFinishLaunchingWithOptions launchOptions: [UIApplication.LaunchOptionsKey: Any]?) -> Bool {\n        \n        window = UIWindow(frame: UIScreen.main.bounds)\n        let rootVC = ViewController()\n        window?.rootViewController = rootVC\n        window?.makeKeyAndVisible()\n        \n        return true\n    }Теперь AppDelegate выглядит вот так: Переходим во ViewController, в методе viewDidLoad добавляем фиолетовый цвет для  бэкграунда view контроллера: view.backgroundColor = .purpleЗапускаем проект, и если все сделали верно, запустится симулятор с фиолетовым контроллером:Отлично, теперь мы можем продолжать писать интерфейс в коде. Для начала создадим еще один ViewController. Нажимаем Command + N и выбираем Cocoa Touch Class:Назовем его SecondViewController:После создания удалите весь закоментированый код из SecondViewController. Поработаем с ViewController, добавим на него кнопку перехода на SecondViewController:Строки 12 - 17Объявим новый метод makeConstraints, в нем добавим кнопку на view и создадим констрейнты.     private func makeConstraints() {\n        \n        view.addSubview(toSecondViewControllerButton) // добавляем кнопку на view\n        NSLayoutConstraint.activate([\n            toSecondViewControllerButton.centerXAnchor.constraint(equalTo: view.centerXAnchor), // центр по оси Х\n            toSecondViewControllerButton.centerYAnchor.constraint(equalTo: view.centerYAnchor) // центр по оси Y\n        ])\n    }И обязательно, нужно установить значение свойстваbutton.translatesAutoresizingMaskIntoConstraints = false в клоужере создания кнопки. Вот как теперь выглядит ViewController:Что бы все заработало не забудьте добавить вызов makeConstraints() во viewDidLoad(). Строка 27. Проверим симулятор:Кнопка есть, все отлично. Теперь аналогично добавим UILabel, в нем в последующем и будем менять текст при возвращении из следующего контроллера. Можете сами потренироваться и создать лейбл. Если возникнут проблемы, подглядите здесь :)Первым делом добавим сам элемент UILabel:строка 21 - 26. Сразу зададим текст лейбла \"Standart text\"Добавляем лейбл на view и, создадаем констрейнты, расширив метод makeConstraints:    private func makeConstraints() {\n        \n        view.addSubview(toSecondViewControllerButton)\n        view.addSubview(someLabel)  // добавляем на экран\n        NSLayoutConstraint.activate([\n            toSecondViewControllerButton.centerXAnchor.constraint(equalTo: view.centerXAnchor),\n            toSecondViewControllerButton.centerYAnchor.constraint(equalTo: view.centerYAnchor),\n            \n            someLabel.centerXAnchor.constraint(equalTo: toSecondViewControllerButton.centerXAnchor), // центр по оси X\n            someLabel.centerYAnchor.constraint(equalTo: toSecondViewControllerButton.centerYAnchor, constant: 40) // центр по оси Y\n        ])\n    }Отлично, теперь на view есть кнопка и лейбл. Симулятор выглядят так:Чтобы кнопка заработала и при ее нажатии открывался следующий экран, добавим ей свойство button.addTarget():Строка 18Объявим методtoSecondVCButtonPressed(), который будет отрабатывать по нажатию на кнопку:Перейдем в SecondViewController и в методе viewDidLoad() добавим цвет бэкграунда view второго контроллера:Строка 15. Проверяем, что получилось, собираем проект. Если все сделано верно, по нажатию на кнопку Go to second VC, откроется второй контроллер с серым фоном. Часть 2Пора приступать к передаче данных при закрытии \"серого\" контроллера. Как вы видели в названии статьи, будем использовать делегат :)Объявим протокол ViewControllerDelegate в классе ViewController и обязательно укажем тип AnyObject. Это нужно для того, чтобы протокол работал с классами, а это, в свою очередь, позволит создавать слабые ссылки и избежать retain cycle между контроллерами. Наш протокол будет содержать только один метод - для замены текста в лейбле ViewController'a. Строки 10 - 12. Реализовывать метод протокола будет ViewController, подпишем его под протокол в extension'е и напишем логику для метода, которая будет менять текст:В аргумент text, находящийся на 68 строке, придет новый текст с другого контроллера, а на 69 строке мы заменим стандартный текст лейбла. Если навести курсор на аргумент text, Xcode подсветит какой text к какому относится. Переходим в SecondViewController. Помните мы создали протокол и объявили его anyObject? Теперь пора создать слабую ссылку, которая будет иметь тип делегата, она будет жить в SecondViewController и через нее мы сможем добраться до методов делегата. Строка 12Когда мы закрываем SecondViewController, смахивая его вниз, срабатывает метод deinit. В нашем примере это отличное место, чтобы передать новый текст в лейбл ViewController'a. Добираемся через переменную delegate до метода newTextForLabel и передаем в него новый текст для лейбла на первом контроллере \"New text\"Строки 20 - 22Как пример, если создать кнопку закрытия второго экрана, тогда self.delegate?.newtextForLabel(text: \"New text\") поселился бы в методе, срабатывающем по нажатию на кнопку закрытия. Все почти готово, осталось дело за малой деталью, о которой лично я всегда забываю :) нужно сообщить нашему SecondViewController, кто будет его делегатом (то есть кто будет что-то делать с теми данными которые, он отправил). Возвращаемся в ViewController, и там, где мы создавали для кнопки метод перехода на SecondViewController подпишемся под делегата:Строка 62. Собираем проект и проверяем:PS: Почему текст обновляется с задержкой? Дело в том, что deinit выгружает контроллер из памяти, поэтому проходит какое-то количество времени, пока контроллер выгрузится и текст сменится. Если вы будете использовать делегат, например, в методе UIViewController'a - dismiss() или в вашем методе кнопки, то никаких задержек не будет. GitHub с финальным проектом - ссылка. Спасибо, что дочитали :)",
        "meta_tags": [
            "delegate",
            "Delegate pattern",
            "Просто о делегатах",
            "swift",
            "Swift delegate",
            "Верстка кодом",
            "удалить storyboard",
            "interface programmicaly swift",
            "делегаты swift пример"
        ]
    },
    {
        "publish_datetime": 1669997060.0,
        "author": "Андрей Германов",
        "title": "Эффективная работа со строками в JavaScript",
        "title_image_url": "https://habrastorage.org/getpro/habr/upload_files/401/c7e/b47/401c7eb47b49c0e3c3cd050aecd6113c.png",
        "raw_body": "<div xmlns=\"http://www.w3.org/1999/xhtml\"><p>Все что отображает браузер кроме картинок и видео это строки, поэтому грамотная работа с ними может значительно увеличить скорость работы веб-приложений как на стороне клиента так и на стороне сервера.</p><p>Что нужно знать о строках с позиции эффективности их использования? Во первых, строки относятся к примитивным типам данных. Во вторых, значения примитивных (простых) типов данных, в отличии от составных, таких как массивы и структуры не изменяемы. Это значит, что если вы присвоили значение переменной строкового типа один раз, то в дальнейшем эту строку изменить невозможно. Однако такое утверждение может удивить. Что это значит на практике? Если, например, выполнить этот код:</p><pre><code class=\"javascript\">let hello = \"Hello\";\nhello += \" world\";\nconsole.log(hello);</code></pre><p>то в консоли однозначно появится <strong>Hello world</strong>, то есть строковая переменная hello изменила свое значение. Как строковая переменная может быть неизменяемой и измениться одновременно?</p><p>Дело в том, что интерпретатор языка в случае со строками не добавляет одну строку к другой напрямую. Вместо этого, он создает третью строку в памяти, затем копирует обе строки \"Hello\" и \" world\" в эту новую строку и перенаправляет переменную \"hello\" чтобы она указывала на эту новую строку. Соответственно, значение новой строки устанавливается один раз, а значения первых двух не изменяются и таким образом правило неизменяемости строк выполняется.</p><p>Вот как процесс объединения строк выглядит полностью:</p><figure class=\"full-width \"><img src=\"https://habrastorage.org/r/w1560/getpro/habr/upload_files/343/7cc/245/3437cc2454accdfb7d76b1756c3871ab.png\" width=\"714\" height=\"463\" data-src=\"https://habrastorage.org/getpro/habr/upload_files/343/7cc/245/3437cc2454accdfb7d76b1756c3871ab.png\"/><figcaption></figcaption></figure><p>Как вы думаете, что в этом процессе плохого? Это крайне не эффективный алгоритм. Он выполняет больше действий чем необходимо и использует в два раза больше памяти чтобы хранить одну и ту же строку. Конечно это не является проблемой если нужно просто объединить две строки. Проблемы могут появиться при необходимости строить большие строки. Например, если нужно динамически создать HTML-текст страницы из массива данных, поступающих из внешнего источника используя цикл по этому массиву. В этом случае, вся создаваемая строка будет полностью копироваться в новую на каждой итерации цикла. Рассмотрим простой пример такого цикла:</p><pre><code class=\"javascript\">let str = \"Hello\";\n\nconsole.log(\"START\",new Date().toUTCString());\n\nfor (let index=0;index&lt;100000000;index++) {\n    str += \"!\";\n}\n\nconsole.log(\"END\",new Date().toUTCString());\nconsole.log(str.length);</code></pre><p>Этот код создает строку \"Hello\" и затем добавляет к ней строку \"!\" сто миллионов раз. В реальных приложениях вместо \"!\" могут быть реальные данные из внешнего массива. Также, этот код выводит текущее время до начала цикла и после него. Таким образом можно узнать сколько времени требуется на выполнение этого кода. В завершении он выводит длину итоговой строки. Когда я запустил это в Google Chrome, то получил следующий вывод в консоли:</p><figure class=\"\"><img src=\"https://habrastorage.org/r/w1560/getpro/habr/upload_files/104/dc1/1ff/104dc11ffa0f770005f1037f689c975c.png\" width=\"492\" height=\"112\" data-src=\"https://habrastorage.org/getpro/habr/upload_files/104/dc1/1ff/104dc11ffa0f770005f1037f689c975c.png\"/><figcaption></figcaption></figure><p>Данная операции выполнилась за 1 минуту 26 секунд и выдала корректную длину строки. Однако, когда я запустил это на другом компьютере, этот код убил текущую вкладку в браузере и вывел вот такое:</p><figure class=\"\"><img src=\"https://habrastorage.org/r/w1560/getpro/habr/upload_files/383/48b/c0b/38348bc0b2089d2b77fd3d80f983e3e6.png\" width=\"358\" height=\"182\" data-src=\"https://habrastorage.org/getpro/habr/upload_files/383/48b/c0b/38348bc0b2089d2b77fd3d80f983e3e6.png\"/><figcaption></figcaption></figure><p>После рассмотрения того как работает объединение строк несложно понять почему браузер мог рухнуть. Этот алгоритм совершенно не эффективен. Этот цикл создает новые строки размером от одного символа до ста миллионов символов на каждой итерации цикла сто миллионов раз. В этой ситуации даже сложно сразу представить, сколько для этого может потребоваться памяти. В одном случае операция может завершиться успешно, в другом случае нет. Это зависит от количества доступной памяти и от того как работает сборщик мусора в конкретной реализации движка JavaScript, на котором этот код запускается, то есть насколько быстро он успевает очищать временно созданные строки по ходу цикла.</p><p>Увидев все это возникает желание исправить ситуацию и добавлять строку к строке напрямую. В других языках программирования, в таких как Java или Go существуют вспомогательные объекты StringBuilder или StringBuffer, которые именно это и делают. Они позволяют конструировать строки через изменяемые типы данных, такие как массивы. Однако в JavaScript этого нет, но идею несложно реализовать самостоятельно, что и будет сделано далее.</p><p>Вернемся к началу и запишем строку \"hello\" следующим образом:</p><pre><code class=\"javascript\">let hello = [\"Hello\"];</code></pre><p>Переменная hello это не строка, а массив со строкой. Массивы изменяемы и если выполнить:</p><pre><code class=\"javascript\">hello.push(\" world\");</code></pre><p>то произойдет именно то что написано и больше ничего: строка \" world\" добавится в массив после строки \"Hello\" и массив будет содержать следующее:</p><pre><code class=\"json\">[\"Hello\",\" world\"]</code></pre><p>Таким образом можно добавлять любое количество строк и Javascript будет выполнять лишь одну операцию для каждого добавления. Однако в конце, чтобы получить строку, придется объединить массив с помощью операции join:</p><pre><code class=\"javascript\">hello = hello.join(\"\");\nconsole.log(hello);</code></pre><p>Этот код объединил массив в строку и вывел \"Hello world\" в консоль. Конечно в момент операции \"join\" происходит то же самое что и при объединении строк: создается новая строка, в нее копируются все элементы массива и затем эта строка присваивается переменной \"hello\". Однако это происходит всего один раз, а не каждый раз при добавлении новой строки. </p><p>Такой способ позволяет значительно ускорить конструирования строк в цикле. Перепишем  пример с циклом через массив:</p><pre><code class=\"javascript\">let str = [\"Hello\"];\n\nconsole.log(\"START\",new Date().toUTCString());\n\nfor (let index=0;index&lt;100000000;index++) {\n    str.push(\"!\");\n}\n\nstr = str.join(\"\");\n\nconsole.log(\"END\",new Date().toUTCString());\nconsole.log(str.length);</code></pre><p>Получилось на одну строчку больше. Когда я запустил этот код на том же компьютере, где рухнул браузер, то получил следующий вывод:</p><figure class=\"\"><img src=\"https://habrastorage.org/r/w1560/getpro/habr/upload_files/5e3/dca/e57/5e3dcae57c175b58a5dd0015ae276024.png\" width=\"489\" height=\"111\" data-src=\"https://habrastorage.org/getpro/habr/upload_files/5e3/dca/e57/5e3dcae57c175b58a5dd0015ae276024.png\"/><figcaption></figcaption></figure><p>Результат был достигнут за 8 секунд, что в 10 раз быстрее чем при обычном объединении строк.</p><p>Это является примером того, что иногда изменив три строки кода можно значительно увеличить производительность обработки данных. В реальной жизни, я столкнулся с ситуацией когда владелец web-сайта из-за медленной загрузки строки сначала кэшировал данные на CloudFlare, а потом на полном серьезе планировал переходить на AWS для увеличения пропускной способности и балансировки нагрузки. Однако нужно было просто провести code review для фронтенда. </p><p>Вы можете использовать этот метод для конструирования строк из массивов внешних данных, размер которых не известен. Просто добавляйте строки в массив, а в самом конце объединяйте этот массив в строку.</p><p>То что было сделано можно рассматривать как базовую реализацию StringBuilder для Javascript с одной лишь функцией - добавление подстроки. В качестве домашней работы можете оформить это в виде класса с разными функциями для работы с подстроками, такими как \"добавить\", \"изменить\", \"удалить\" и \"преобразовать в строку\". </p><p>При добавлении элементов в массив важно помнить о существующих ограничениях на количество элементов массива, так как если их не учитывать, то можно столкнуться с ошибкой \"RangeError: invalid array range\". Подробнее об ограничениях можно узнать здесь: <a href=\"https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Errors/Invalid_array_length\" rel=\"noopener noreferrer nofollow\">https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Errors/Invalid_array_length</a> . Поэтому если количество строк, которые нужно добавлять в цикле превышает эти ограничения, то придется периодически сбрасывать массив во временные строковые буферы и потом эти буферы объединять.</p><p>Приведенный в начале алгоритм объединения строк в Javascript не претендует на академическую точность по некоторым причинам. Разные реализации движков Javascript могут использовать различные оптимизации по работе со строками и механизмы работы с памятью могут отличаться. Однако не стоит расчитывать на то что ваш код всегда будет запускаться в таких движках. Например, в последней версии Google Chrome на момент написания этого текста объединение строк работало так, как показано на скриншотах выше. Поэтому целью данной статьи является показать как работать со строками эффективнее независимо от того, как это реализовано по умолчанию. </p><p>Существуют и более эффективные алгоритмы работы со строками, основанные не только на массивах. Наиболее быстрый из них построен на структуре данных Rope. Она используется для ускорения вставки и удаления подстрок в огромных строках. Подробнее о самой структуре можно прочитать в Википедии: <a href=\"https://en.wikipedia.org/wiki/Rope_(data_structure)\" rel=\"noopener noreferrer nofollow\">https://en.wikipedia.org/wiki/Rope_(data_structure)</a> . Также думаю не сложно будет найти описания на русском языке. Это несколько сложнее для понимания и использования чем метод описанный в этой статье, однако можно воспользоваться одной из готовых библиотек, которые реализуют Rope на JavaScript:</p><p><a href=\"https://github.com/component/rope\" rel=\"noopener noreferrer nofollow\"><u>https://github.com/component/rope</u></a><br/><a href=\"https://github.com/josephg/jumprope\" rel=\"noopener noreferrer nofollow\"><u>https://github.com/josephg/jumprope</u></a></p><p>Спасибо, надеюсь это поможет вам в работе. Если есть вопросы или дополнения, пишите в комментариях.</p><p></p></div>",
        "clean_body": "Все что отображает браузер кроме картинок и видео это строки, поэтому грамотная работа с ними может значительно увеличить скорость работы веб-приложений как на стороне клиента так и на стороне сервера.Что нужно знать о строках с позиции эффективности их использования? Во первых, строки относятся к примитивным типам данных. Во вторых, значения примитивных (простых) типов данных, в отличии от составных, таких как массивы и структуры не изменяемы. Это значит, что если вы присвоили значение переменной строкового типа один раз, то в дальнейшем эту строку изменить невозможно. Однако такое утверждение может удивить. Что это значит на практике? Если, например, выполнить этот код:let hello = \"Hello\";\nhello += \" world\";\nconsole.log(hello);то в консоли однозначно появится Hello world, то есть строковая переменная hello изменила свое значение. Как строковая переменная может быть неизменяемой и измениться одновременно?Дело в том, что интерпретатор языка в случае со строками не добавляет одну строку к другой напрямую. Вместо этого, он создает третью строку в памяти, затем копирует обе строки \"Hello\" и \" world\" в эту новую строку и перенаправляет переменную \"hello\" чтобы она указывала на эту новую строку. Соответственно, значение новой строки устанавливается один раз, а значения первых двух не изменяются и таким образом правило неизменяемости строк выполняется.Вот как процесс объединения строк выглядит полностью:Как вы думаете, что в этом процессе плохого? Это крайне не эффективный алгоритм. Он выполняет больше действий чем необходимо и использует в два раза больше памяти чтобы хранить одну и ту же строку. Конечно это не является проблемой если нужно просто объединить две строки. Проблемы могут появиться при необходимости строить большие строки. Например, если нужно динамически создать HTML-текст страницы из массива данных, поступающих из внешнего источника используя цикл по этому массиву. В этом случае, вся создаваемая строка будет полностью копироваться в новую на каждой итерации цикла. Рассмотрим простой пример такого цикла:let str = \"Hello\";\n\nconsole.log(\"START\",new Date().toUTCString());\n\nfor (let index=0;index<100000000;index++) {\n    str += \"!\";\n}\n\nconsole.log(\"END\",new Date().toUTCString());\nconsole.log(str.length);Этот код создает строку \"Hello\" и затем добавляет к ней строку \"!\" сто миллионов раз. В реальных приложениях вместо \"!\" могут быть реальные данные из внешнего массива. Также, этот код выводит текущее время до начала цикла и после него. Таким образом можно узнать сколько времени требуется на выполнение этого кода. В завершении он выводит длину итоговой строки. Когда я запустил это в Google Chrome, то получил следующий вывод в консоли:Данная операции выполнилась за 1 минуту 26 секунд и выдала корректную длину строки. Однако, когда я запустил это на другом компьютере, этот код убил текущую вкладку в браузере и вывел вот такое:После рассмотрения того как работает объединение строк несложно понять почему браузер мог рухнуть. Этот алгоритм совершенно не эффективен. Этот цикл создает новые строки размером от одного символа до ста миллионов символов на каждой итерации цикла сто миллионов раз. В этой ситуации даже сложно сразу представить, сколько для этого может потребоваться памяти. В одном случае операция может завершиться успешно, в другом случае нет. Это зависит от количества доступной памяти и от того как работает сборщик мусора в конкретной реализации движка JavaScript, на котором этот код запускается, то есть насколько быстро он успевает очищать временно созданные строки по ходу цикла.Увидев все это возникает желание исправить ситуацию и добавлять строку к строке напрямую. В других языках программирования, в таких как Java или Go существуют вспомогательные объекты StringBuilder или StringBuffer, которые именно это и делают. Они позволяют конструировать строки через изменяемые типы данных, такие как массивы. Однако в JavaScript этого нет, но идею несложно реализовать самостоятельно, что и будет сделано далее.Вернемся к началу и запишем строку \"hello\" следующим образом:let hello = [\"Hello\"];Переменная hello это не строка, а массив со строкой. Массивы изменяемы и если выполнить:hello.push(\" world\");то произойдет именно то что написано и больше ничего: строка \" world\" добавится в массив после строки \"Hello\" и массив будет содержать следующее:[\"Hello\",\" world\"]Таким образом можно добавлять любое количество строк и Javascript будет выполнять лишь одну операцию для каждого добавления. Однако в конце, чтобы получить строку, придется объединить массив с помощью операции join:hello = hello.join(\"\");\nconsole.log(hello);Этот код объединил массив в строку и вывел \"Hello world\" в консоль. Конечно в момент операции \"join\" происходит то же самое что и при объединении строк: создается новая строка, в нее копируются все элементы массива и затем эта строка присваивается переменной \"hello\". Однако это происходит всего один раз, а не каждый раз при добавлении новой строки. Такой способ позволяет значительно ускорить конструирования строк в цикле. Перепишем  пример с циклом через массив:let str = [\"Hello\"];\n\nconsole.log(\"START\",new Date().toUTCString());\n\nfor (let index=0;index<100000000;index++) {\n    str.push(\"!\");\n}\n\nstr = str.join(\"\");\n\nconsole.log(\"END\",new Date().toUTCString());\nconsole.log(str.length);Получилось на одну строчку больше. Когда я запустил этот код на том же компьютере, где рухнул браузер, то получил следующий вывод:Результат был достигнут за 8 секунд, что в 10 раз быстрее чем при обычном объединении строк.Это является примером того, что иногда изменив три строки кода можно значительно увеличить производительность обработки данных. В реальной жизни, я столкнулся с ситуацией когда владелец web-сайта из-за медленной загрузки строки сначала кэшировал данные на CloudFlare, а потом на полном серьезе планировал переходить на AWS для увеличения пропускной способности и балансировки нагрузки. Однако нужно было просто провести code review для фронтенда. Вы можете использовать этот метод для конструирования строк из массивов внешних данных, размер которых не известен. Просто добавляйте строки в массив, а в самом конце объединяйте этот массив в строку.То что было сделано можно рассматривать как базовую реализацию StringBuilder для Javascript с одной лишь функцией - добавление подстроки. В качестве домашней работы можете оформить это в виде класса с разными функциями для работы с подстроками, такими как \"добавить\", \"изменить\", \"удалить\" и \"преобразовать в строку\". При добавлении элементов в массив важно помнить о существующих ограничениях на количество элементов массива, так как если их не учитывать, то можно столкнуться с ошибкой \"RangeError: invalid array range\". Подробнее об ограничениях можно узнать здесь: https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Errors/Invalid_array_length . Поэтому если количество строк, которые нужно добавлять в цикле превышает эти ограничения, то придется периодически сбрасывать массив во временные строковые буферы и потом эти буферы объединять.Приведенный в начале алгоритм объединения строк в Javascript не претендует на академическую точность по некоторым причинам. Разные реализации движков Javascript могут использовать различные оптимизации по работе со строками и механизмы работы с памятью могут отличаться. Однако не стоит расчитывать на то что ваш код всегда будет запускаться в таких движках. Например, в последней версии Google Chrome на момент написания этого текста объединение строк работало так, как показано на скриншотах выше. Поэтому целью данной статьи является показать как работать со строками эффективнее независимо от того, как это реализовано по умолчанию. Существуют и более эффективные алгоритмы работы со строками, основанные не только на массивах. Наиболее быстрый из них построен на структуре данных Rope. Она используется для ускорения вставки и удаления подстрок в огромных строках. Подробнее о самой структуре можно прочитать в Википедии: https://en.wikipedia.org/wiki/Rope_(data_structure) . Также думаю не сложно будет найти описания на русском языке. Это несколько сложнее для понимания и использования чем метод описанный в этой статье, однако можно воспользоваться одной из готовых библиотек, которые реализуют Rope на JavaScript:https://github.com/component/ropehttps://github.com/josephg/jumpropeСпасибо, надеюсь это поможет вам в работе. Если есть вопросы или дополнения, пишите в комментариях.",
        "meta_tags": [
            "алгоритм",
            "ускорение кода",
            "строка",
            "javascript",
            "web разработка",
            "фронтенд",
            "оптимизация кода",
            "программирование"
        ]
    },
    {
        "publish_datetime": 1670001528.0,
        "author": "Вячеслав Любченко",
        "title": "О программных ошибках на примере MATLAB и SimInTech",
        "title_image_url": "https://habrastorage.org/getpro/habr/upload_files/7b0/c14/929/7b0c149294d87c7d581a78d5cb90d982.png",
        "raw_body": "<div xmlns=\"http://www.w3.org/1999/xhtml\"><p>Сила - в правде. На уровне программирования она выражается в том, что одни и те же программы при одних и тех же начальных условиях обязаны выдавать истинную правду, т.е. одинаковые результаты. И даже разные программы, реализующие одну и ту же задачу, должны вести себя одинаково. Действительно, было бы странно, если бы два калькулятора выдавали отличающиеся результаты на одной и той же операции.  Или, по-другому, все это своего рода «программистская аксиома».</p><p>И, вроде бы все так, да не всегда. Критично ли наличие ошибок в программах? Странный вопрос - конечно, критично. Но, тем не менее, найдутся и те, кто скажет – не беда. И даст этому свое объяснение. Здесь, правда,  можно вспомнить, как фирма Intel объясняла несущественность ошибки деления с плавающей точкой в процессоре Pentium (подробнее см. [1]). Но общественность и пользователи объяснили Intel, что она не права. И, понеся большие репутационные и финансовые потери,  ей пришлось с этим согласиться и исправить положение. </p><p>Далее, обсуждая конкретные программы, мы столкнемся с тем, что нужно считать ошибками. Отличие от ситуации с Intel только в том, что необходимо будет конкретизировать, кто ошибается и ошибается ли и где источник ошибок. Но то, что идет явно не по плану, подтверждают результаты нашего тестирования. Просто ситуация несколько сложнее проблемы одной операции деления FDIV.  </p><p>Итак. Выберем для экспериментов три среды: две известные – это MATLAB, SimInTech и одну, известную больше по статьям вашего покорного слуги, - среду параллельного автоматного программирования ВКПа. Для первых двух можно скачать ограниченные версии.  Их возможностей вполне будет достаточно для наших примеров. Ну, а в отношении третьей - придется довериться автору. </p><p>Соберем в рамках упомянутых сред простую схему, состоящую  из трех блоков -  генератора синусоидального сигнала,  интегратора и блока отображения. На рис. 1, 2, 3 представлены как подобные решения, так и результаты их работы. И пока ни что не вызывает беспокойства. </p><p> </p><figure class=\"full-width \"><img src=\"https://habrastorage.org/r/w1560/getpro/habr/upload_files/7b0/c14/929/7b0c149294d87c7d581a78d5cb90d982.png\" alt=\"        Рис.1. Интегрирование синусоидального сигнала в MATLAB                                         \" title=\"        Рис.1. Интегрирование синусоидального сигнала в MATLAB                                         \" width=\"729\" height=\"257\" data-src=\"https://habrastorage.org/getpro/habr/upload_files/7b0/c14/929/7b0c149294d87c7d581a78d5cb90d982.png\"/><figcaption>        Рис.1. Интегрирование синусоидального сигнала в MATLAB                                         </figcaption></figure><figure class=\"full-width \"><img src=\"https://habrastorage.org/r/w1560/getpro/habr/upload_files/19e/77a/a7d/19e77aa7d888527563d8a5a52e33a81b.png\" alt=\"Рис.2. Интегрирование синусоидального сигнала в SimInTech\" title=\"Рис.2. Интегрирование синусоидального сигнала в SimInTech\" width=\"737\" height=\"311\" data-src=\"https://habrastorage.org/getpro/habr/upload_files/19e/77a/a7d/19e77aa7d888527563d8a5a52e33a81b.png\"/><figcaption>Рис.2. Интегрирование синусоидального сигнала в SimInTech</figcaption></figure><figure class=\"full-width \"><img src=\"https://habrastorage.org/r/w1560/getpro/habr/upload_files/ab8/174/6d7/ab81746d725ce3a8a7aefae536374bb0.png\" alt=\"     Рис. 3. Интегрирование синусоидального сигнала в ВКПа \" title=\"     Рис. 3. Интегрирование синусоидального сигнала в ВКПа \" width=\"774\" height=\"280\" data-src=\"https://habrastorage.org/getpro/habr/upload_files/ab8/174/6d7/ab81746d725ce3a8a7aefae536374bb0.png\"/><figcaption>     Рис. 3. Интегрирование синусоидального сигнала в ВКПа </figcaption></figure><p>Для пущей уверенности мы собрали еще одну аналогичную схему, заменив только синусоидальный генератор на генератор импульсных сигналов. Но это в целом ситуацию не изменило. Хотя, что там греха таить, основная цель всех этих экспериментов была все же проверить «честность» блока интегрирования среды ВКПа и, если необходимо, доработать его функциональность. </p><p>Далее в рамках тестирования ВКПа на примерах все более сложных задач мы создали схемы аттракторов, описанных в статье на Хабре [2]. Это аттракторы Лоренца, Ресслера, Рикитаки и Нозе-Гувера. В статье они представлены схемами в МАТЛАБ. Аналогичные схемы мы собрали для SymInTech и ВКПа. Сравнительные результаты их тестирования оказались столь любопытны, что заслуживают того, чтобы с ними был ознакомлен и Хабр. </p><p>При этом отличия в результатах  тестирования аттракторов Лоренца проявились в наибольшей степени. Они приведены для МАТЛАБ на рис. 4, для SymInTech - на рис. 5 и для ВКПа на рис. 6. Глядя на результаты можно лишь сказать, что они похожи и не более того.  Поэтому, анализируя их, надо бы признать, что они фактически опровергают  сформулированную нами ранее  «программистскую аксиому». С таким положением мириться нельзя и это, безусловно, требует своего разбирательства и поиска причин случившегося.  </p><figure class=\"full-width \"><img src=\"https://habrastorage.org/r/w1560/getpro/habr/upload_files/e4e/757/ae6/e4e757ae69d5db88815447e7e224a764.png\" alt=\"Рис. 4. Тестирование аттрактора Лоренца в МАТЛАБ\" title=\"Рис. 4. Тестирование аттрактора Лоренца в МАТЛАБ\" width=\"955\" height=\"555\" data-src=\"https://habrastorage.org/getpro/habr/upload_files/e4e/757/ae6/e4e757ae69d5db88815447e7e224a764.png\"/><figcaption>Рис. 4. Тестирование аттрактора Лоренца в МАТЛАБ</figcaption></figure><p> </p><figure class=\"full-width \"><img src=\"https://habrastorage.org/r/w1560/getpro/habr/upload_files/618/587/0d5/6185870d5622d4a5aa5021c05c238482.png\" alt=\"Рис. 5. Тестирование аттрактора Лоренца в SymInTech\" title=\"Рис. 5. Тестирование аттрактора Лоренца в SymInTech\" width=\"943\" height=\"455\" data-src=\"https://habrastorage.org/getpro/habr/upload_files/618/587/0d5/6185870d5622d4a5aa5021c05c238482.png\"/><figcaption>Рис. 5. Тестирование аттрактора Лоренца в SymInTech</figcaption></figure><figure class=\"full-width \"><img src=\"https://habrastorage.org/r/w1560/getpro/habr/upload_files/e1a/d4f/a79/e1ad4fa797dd19df9ea9db4a41df24a6.png\" alt=\"Рис. 6. Тестирование аттрактора Лоренца в ВКПа\" title=\"Рис. 6. Тестирование аттрактора Лоренца в ВКПа\" width=\"932\" height=\"305\" data-src=\"https://habrastorage.org/getpro/habr/upload_files/e1a/d4f/a79/e1ad4fa797dd19df9ea9db4a41df24a6.png\"/><figcaption>Рис. 6. Тестирование аттрактора Лоренца в ВКПа</figcaption></figure><p>Почему сертифицированный SimInTech  выдает результаты, которые отличаются от, наверное, столь же сертифицированного пакета MATLAB? Может, можно все списать на хаос, который моделируют аттракторы? Однако, повторный перезапуск программ свидетельствует о его отсутствии. </p><p>Но автора обеспокоило совсем другое - достаточно сильное на фоне остальных программ отличие результатов, показанных  ВКПа. Отметим также, что перезапуск ВКПа порождал близкие, но все же отличающиеся результаты. Т.е. в какой-то мере они больше отвечали поставленной цели – моделированию хаоса. Но причины этого достаточно понятны. К хаосу они имеют мало отношения и это мы объясним позже. </p><p>И тут пришло время вспомнить про параллелизм. Уравнения каждого из аттракторов представляют собой систему из нескольких параллельных дифференциальных  уравнений. Но только у ВКПа можно выбрать один из двух режимов работы: использовать при расчетах теневую память (это стандартный режим, обеспечивающий параллельные свойства среды [3]) или работать в обычном режиме.  Напомним, что в режиме теневой памяти измененные на текущем такте данные помещаются в буфер, чтобы, когда выполнятся все действия, стать новыми значениями. В обычном режиме данные обновляются ровно в моменты их изменений. </p><figure class=\"full-width \"><img src=\"https://habrastorage.org/r/w1560/getpro/habr/upload_files/e1a/fb7/3e3/e1afb73e3bc7259057fee88755961da1.png\" alt=\"Рис. 7. Тестирование аттрактора Лоренца в ВКПа в режиме обычной памяти\" title=\"Рис. 7. Тестирование аттрактора Лоренца в ВКПа в режиме обычной памяти\" width=\"978\" height=\"552\" data-src=\"https://habrastorage.org/getpro/habr/upload_files/e1a/fb7/3e3/e1afb73e3bc7259057fee88755961da1.png\"/><figcaption>Рис. 7. Тестирование аттрактора Лоренца в ВКПа в режиме обычной памяти</figcaption></figure><p>После изменения режима расчета в ВКПа были получили графики, представленные на рис. 7. Сам режим работы при этом определяется состоянием переключателем shadow mode of variables (см. рис. 7), т.е. код вычислительных процессов ни как не затрагивается. Как можно видеть, полученные графики в большей степени походят на результаты конкурентов, чем на свой, но полученный в теневом режиме работы среды.  Из этого следует, что два других пакета, решая поставленную задачу, скорее всего, вычисления выполняют строго последовательно, искажая тем самым «правду». </p><p>С подобной проблемой параллельных расчетов автору уже приходилось сталкиваться. Тогда участником экспериментов был пакет LabVIEW и решалась проблема моделирования адаптивного ПИД-регулятора (об этом см. статью на Хабре [4]). Значения данных, рассчитанных пакетом, полностью совпадали со значениями, полученными в ВКПа, но были сдвинуты по времени.   Это говорило о последовательной работе созданных моделей объекта и регулятора. Доказано это было, как и выше, путем изменения режима работы среды. </p><p>Разные же результатов у ВКПа от запуска к запуску объясняются принципом работы ядра среды. Если первые два рассчитывают работу приложения, то ВКПа ее именно моделирует.  Это происходит в дискретном времени, длительность такта которого «плавающая». Эту разницу соответственно и «ловит» блок интегрирования. Отсюда и некий «хаос» в поведении аттрактора в ВКПа. Но, еще раз, он вполне объясним и потому даже ожидаем.</p><p> Основное вывод, который следует сделать, сводится к тому, что современное программирование, как ни крути, а «антипараллельно». А потому в его рамках сложно в полной мере доверяться даже достаточно известным программным пакетам. Но самое опасное в том, что они используются огромным числом специалистов, не подозревающих о тех последствиях, которые могут произойти, если им доверяться всецело и безоглядно.</p><p>В их оправдание можно лишь сказать, что ни MATLAB ни SimInTech лишь отчасти виноваты в том, что не учитывают параллельные свойства реальных систем. Они просто следуют тенденциям и понятиям современного программирования. А те «сертификации», которые они успешно проходят, похоже, столь же \"антипараллельны\", как и само современное программирование.  </p><p>По-хорошему  теперь нужно ждать разъяснений по поводу разницы в результатах «обычных» прогонов, а также по поводу учета параллелизма, как программных, так и вполне реальных систем. Это особенно важно, т.к. в перечень решаемых пакетами задач входят те, которые весьма критичны к ошибкам. Вдруг, не дай Бог,  что-то не так взлетит, не туда попадет, внезапно откажет или не вовремя утонет? Такой хаос нам не нужен!</p><p><strong>Приложение</strong>. </p><p><u>Схемы аттрактора Лоренца в MATLAB, SymInTech, ВКПа</u></p><figure class=\"full-width \"><img src=\"https://habrastorage.org/r/w1560/getpro/habr/upload_files/d39/30c/34d/d3930c34dce41391750eb14f246b9059.png\" width=\"862\" height=\"824\" data-src=\"https://habrastorage.org/getpro/habr/upload_files/d39/30c/34d/d3930c34dce41391750eb14f246b9059.png\"/><figcaption></figcaption></figure><figure class=\"full-width \"><img src=\"https://habrastorage.org/r/w1560/getpro/habr/upload_files/727/42d/339/72742d339493cd555af9d116fdaf47c3.png\" width=\"862\" height=\"566\" data-src=\"https://habrastorage.org/getpro/habr/upload_files/727/42d/339/72742d339493cd555af9d116fdaf47c3.png\"/><figcaption></figcaption></figure><figure class=\"full-width \"><img src=\"https://habrastorage.org/r/w1560/getpro/habr/upload_files/562/1c5/9b4/5621c59b48ffac9c73f35ee03c8f0b38.png\" width=\"887\" height=\"501\" data-src=\"https://habrastorage.org/getpro/habr/upload_files/562/1c5/9b4/5621c59b48ffac9c73f35ee03c8f0b38.png\"/><figcaption></figcaption></figure><p>Схемы остальных аттрактор аналогичны и результаты их тестирования достаточно похожи друг на друга. Даже в обоих режимах работы ВКПа.</p><p> </p><p><strong>Литература</strong></p><ol><li><p>Ошибка Pentium FDIV.  https://ru.wikipedia.org/wiki/Ошибка_Pentium_FDIV.</p></li><li><p>Генераторы хаоса на ПЛИС. <a href=\"https://habr.com/ru/post/273915/\" rel=\"noopener noreferrer nofollow\">https://habr.com/ru/post/273915/</a></p></li><li><p>Автоматное программирование: определение, модель, реализация. https://habr.com/ru/post/682422/</p></li><li><p>Параллелизм, корутины, событийные автоматы,…<br/> живая математика. <a href=\"https://habr.com/ru/post/499460/\" rel=\"noopener noreferrer nofollow\">https://habr.com/ru/post/499460/</a></p></li></ol><p></p></div>",
        "clean_body": "Сила - в правде. На уровне программирования она выражается в том, что одни и те же программы при одних и тех же начальных условиях обязаны выдавать истинную правду, т.е. одинаковые результаты. И даже разные программы, реализующие одну и ту же задачу, должны вести себя одинаково. Действительно, было бы странно, если бы два калькулятора выдавали отличающиеся результаты на одной и той же операции.  Или, по-другому, все это своего рода «программистская аксиома».И, вроде бы все так, да не всегда. Критично ли наличие ошибок в программах? Странный вопрос - конечно, критично. Но, тем не менее, найдутся и те, кто скажет – не беда. И даст этому свое объяснение. Здесь, правда,  можно вспомнить, как фирма Intel объясняла несущественность ошибки деления с плавающей точкой в процессоре Pentium (подробнее см. [1]). Но общественность и пользователи объяснили Intel, что она не права. И, понеся большие репутационные и финансовые потери,  ей пришлось с этим согласиться и исправить положение. Далее, обсуждая конкретные программы, мы столкнемся с тем, что нужно считать ошибками. Отличие от ситуации с Intel только в том, что необходимо будет конкретизировать, кто ошибается и ошибается ли и где источник ошибок. Но то, что идет явно не по плану, подтверждают результаты нашего тестирования. Просто ситуация несколько сложнее проблемы одной операции деления FDIV.  Итак. Выберем для экспериментов три среды: две известные – это MATLAB, SimInTech и одну, известную больше по статьям вашего покорного слуги, - среду параллельного автоматного программирования ВКПа. Для первых двух можно скачать ограниченные версии.  Их возможностей вполне будет достаточно для наших примеров. Ну, а в отношении третьей - придется довериться автору. Соберем в рамках упомянутых сред простую схему, состоящую  из трех блоков -  генератора синусоидального сигнала,  интегратора и блока отображения. На рис. 1, 2, 3 представлены как подобные решения, так и результаты их работы. И пока ни что не вызывает беспокойства.          Рис.1. Интегрирование синусоидального сигнала в MATLAB                                         Рис.2. Интегрирование синусоидального сигнала в SimInTech     Рис. 3. Интегрирование синусоидального сигнала в ВКПа Для пущей уверенности мы собрали еще одну аналогичную схему, заменив только синусоидальный генератор на генератор импульсных сигналов. Но это в целом ситуацию не изменило. Хотя, что там греха таить, основная цель всех этих экспериментов была все же проверить «честность» блока интегрирования среды ВКПа и, если необходимо, доработать его функциональность. Далее в рамках тестирования ВКПа на примерах все более сложных задач мы создали схемы аттракторов, описанных в статье на Хабре [2]. Это аттракторы Лоренца, Ресслера, Рикитаки и Нозе-Гувера. В статье они представлены схемами в МАТЛАБ. Аналогичные схемы мы собрали для SymInTech и ВКПа. Сравнительные результаты их тестирования оказались столь любопытны, что заслуживают того, чтобы с ними был ознакомлен и Хабр. При этом отличия в результатах  тестирования аттракторов Лоренца проявились в наибольшей степени. Они приведены для МАТЛАБ на рис. 4, для SymInTech - на рис. 5 и для ВКПа на рис. 6. Глядя на результаты можно лишь сказать, что они похожи и не более того.  Поэтому, анализируя их, надо бы признать, что они фактически опровергают  сформулированную нами ранее  «программистскую аксиому». С таким положением мириться нельзя и это, безусловно, требует своего разбирательства и поиска причин случившегося.  Рис. 4. Тестирование аттрактора Лоренца в МАТЛАБ Рис. 5. Тестирование аттрактора Лоренца в SymInTechРис. 6. Тестирование аттрактора Лоренца в ВКПаПочему сертифицированный SimInTech  выдает результаты, которые отличаются от, наверное, столь же сертифицированного пакета MATLAB? Может, можно все списать на хаос, который моделируют аттракторы? Однако, повторный перезапуск программ свидетельствует о его отсутствии. Но автора обеспокоило совсем другое - достаточно сильное на фоне остальных программ отличие результатов, показанных  ВКПа. Отметим также, что перезапуск ВКПа порождал близкие, но все же отличающиеся результаты. Т.е. в какой-то мере они больше отвечали поставленной цели – моделированию хаоса. Но причины этого достаточно понятны. К хаосу они имеют мало отношения и это мы объясним позже. И тут пришло время вспомнить про параллелизм. Уравнения каждого из аттракторов представляют собой систему из нескольких параллельных дифференциальных  уравнений. Но только у ВКПа можно выбрать один из двух режимов работы: использовать при расчетах теневую память (это стандартный режим, обеспечивающий параллельные свойства среды [3]) или работать в обычном режиме.  Напомним, что в режиме теневой памяти измененные на текущем такте данные помещаются в буфер, чтобы, когда выполнятся все действия, стать новыми значениями. В обычном режиме данные обновляются ровно в моменты их изменений. Рис. 7. Тестирование аттрактора Лоренца в ВКПа в режиме обычной памятиПосле изменения режима расчета в ВКПа были получили графики, представленные на рис. 7. Сам режим работы при этом определяется состоянием переключателем shadow mode of variables (см. рис. 7), т.е. код вычислительных процессов ни как не затрагивается. Как можно видеть, полученные графики в большей степени походят на результаты конкурентов, чем на свой, но полученный в теневом режиме работы среды.  Из этого следует, что два других пакета, решая поставленную задачу, скорее всего, вычисления выполняют строго последовательно, искажая тем самым «правду». С подобной проблемой параллельных расчетов автору уже приходилось сталкиваться. Тогда участником экспериментов был пакет LabVIEW и решалась проблема моделирования адаптивного ПИД-регулятора (об этом см. статью на Хабре [4]). Значения данных, рассчитанных пакетом, полностью совпадали со значениями, полученными в ВКПа, но были сдвинуты по времени.   Это говорило о последовательной работе созданных моделей объекта и регулятора. Доказано это было, как и выше, путем изменения режима работы среды. Разные же результатов у ВКПа от запуска к запуску объясняются принципом работы ядра среды. Если первые два рассчитывают работу приложения, то ВКПа ее именно моделирует.  Это происходит в дискретном времени, длительность такта которого «плавающая». Эту разницу соответственно и «ловит» блок интегрирования. Отсюда и некий «хаос» в поведении аттрактора в ВКПа. Но, еще раз, он вполне объясним и потому даже ожидаем. Основное вывод, который следует сделать, сводится к тому, что современное программирование, как ни крути, а «антипараллельно». А потому в его рамках сложно в полной мере доверяться даже достаточно известным программным пакетам. Но самое опасное в том, что они используются огромным числом специалистов, не подозревающих о тех последствиях, которые могут произойти, если им доверяться всецело и безоглядно.В их оправдание можно лишь сказать, что ни MATLAB ни SimInTech лишь отчасти виноваты в том, что не учитывают параллельные свойства реальных систем. Они просто следуют тенденциям и понятиям современного программирования. А те «сертификации», которые они успешно проходят, похоже, столь же \"антипараллельны\", как и само современное программирование.  По-хорошему  теперь нужно ждать разъяснений по поводу разницы в результатах «обычных» прогонов, а также по поводу учета параллелизма, как программных, так и вполне реальных систем. Это особенно важно, т.к. в перечень решаемых пакетами задач входят те, которые весьма критичны к ошибкам. Вдруг, не дай Бог,  что-то не так взлетит, не туда попадет, внезапно откажет или не вовремя утонет? Такой хаос нам не нужен!Приложение. Схемы аттрактора Лоренца в MATLAB, SymInTech, ВКПаСхемы остальных аттрактор аналогичны и результаты их тестирования достаточно похожи друг на друга. Даже в обоих режимах работы ВКПа. ЛитератураОшибка Pentium FDIV.  https://ru.wikipedia.org/wiki/Ошибка_Pentium_FDIV.Генераторы хаоса на ПЛИС. https://habr.com/ru/post/273915/Автоматное программирование: определение, модель, реализация. https://habr.com/ru/post/682422/Параллелизм, корутины, событийные автоматы,… живая математика. https://habr.com/ru/post/499460/",
        "meta_tags": [
            "МАТЛАБ",
            "SymInTech",
            "ВКПа",
            "Автоматное программирование"
        ]
    },
    {
        "publish_datetime": 1670007241.0,
        "author": "Вильмов Андрей",
        "title": "Прогнозирование продаж Python. Как находить и сглаживать выбросы с помощью фильтра Хэмплея",
        "title_image_url": "https://habrastorage.org/getpro/habr/upload_files/0ee/ed5/474/0eeed5474eaa3f7cfdec3d3d41756bbb.jpeg",
        "raw_body": "<div xmlns=\"http://www.w3.org/1999/xhtml\"><figure class=\"full-width \"><img src=\"https://habrastorage.org/r/w780q1/getpro/habr/upload_files/0ee/ed5/474/0eeed5474eaa3f7cfdec3d3d41756bbb.jpeg\" width=\"1200\" height=\"708\" data-src=\"https://habrastorage.org/getpro/habr/upload_files/0ee/ed5/474/0eeed5474eaa3f7cfdec3d3d41756bbb.jpeg\" data-blurred=\"true\"/><figcaption></figcaption></figure><p>Те, кто работает с временными рядами, часто сталкивается с двумя проблемами. Первая – нет полных данных. Вторая – битые данные, когда встречается много выбросов, шума и пропусков. Редко встречаются случаи, когда всё было бы идеально. И данных много, и можно легко найти нужные. Такое встретишь крайне редко или почти никогда. </p><p>Возникает вопрос - как решить эту проблему? Я нашёл решение. Давайте расскажу вам, как я решаю проблему битых данных, выбросов, пропусков. Какие я использовал методы, в чем их отличия, преимущества и какие я считаю самыми лучшими. </p><p>Начнём мы с первого метода – фильтра Хэмплея. В этой статье речь пойдёт именно о нём. Я постараюсь как можно проще рассказать о его особенностях и показать всё на наглядных примерах. Приступим.</p><h3>Как работает фильтр Хэмплея</h3><p>Для начала стоит понять, что такое фильтр Хэмплея. В интернете о нём вы мало что найдёте. По крайней мере, я встретил лишь скудную информацию. Хотя потратил много времени на поиски нужной информации о фильтре. </p><p>Главная цель Хэмплея – найти и заменить выбросы в заданном временном ряду. Для этого в своей основе он использует скользящее среднее с заданным окном. Для каждой итерации или окна фильтр вычисляет медиану и стандартное отклонение. Оно выражается в среднем абсолютном значении и обозначается как MAD.</p><figure class=\"\"><img src=\"https://habrastorage.org/r/w1560/getpro/habr/upload_files/31d/f3e/0fa/31df3e0fad7031696c3e3f02988ebe2c.png\" alt=\"Материал из вики: https://en.wikipedia.org/wiki/Median_absolute_deviation\" title=\"Материал из вики: https://en.wikipedia.org/wiki/Median_absolute_deviation\" width=\"195\" height=\"20\" data-src=\"https://habrastorage.org/getpro/habr/upload_files/31d/f3e/0fa/31df3e0fad7031696c3e3f02988ebe2c.png\"/><figcaption>Материал из вики: https://en.wikipedia.org/wiki/Median_absolute_deviation</figcaption></figure><p>Чтобы MAD стал последовательной оценкой стандартного отклонения надо умножить его на постоянный коэффициент k. Коэффициент зависит от распределения. Мы считаем, что данные подчиняются распределению Гаусса, поэтому берём коэффициент равным 1,4826.</p><figure class=\"\"><img src=\"https://habrastorage.org/getpro/habr/upload_files/3cc/a3b/ab5/3cca3bab576ed0eb067cf7bb15241c4b.PNG\" width=\"383\" height=\"41\"/><figcaption></figcaption></figure><p>Если значение медианы окна скользящего среднего больше чем <em>х</em> стандартных отклонений, то это – выброс.</p><p>Фильтр Хэмплея имеет 2 настраиваемых параметра:</p><p>·         размер раздвижного окна</p><p>·         количество стандартных отклонений, которые идентифицируют выброс</p><p>Для начала надо импортировать нужные библиотеки:</p><pre><code class=\"python\">import matplotlib.pyplot as plt\nimport warnings\nimport pandas as pd\nimport numpy as np</code></pre><p>Загрузить данные из csv файла:</p><pre><code class=\"python\">df = pd.read_csv('data.csv')</code></pre><p>Распечатать данные</p><pre><code class=\"python\">df.head()</code></pre><p></p><figure class=\"\"><img src=\"https://habrastorage.org/r/w1560/getpro/habr/upload_files/4b5/c17/e13/4b5c17e131b2f7f8f7c7e6dd2acf9962.png\" width=\"251\" height=\"242\" data-src=\"https://habrastorage.org/getpro/habr/upload_files/4b5/c17/e13/4b5c17e131b2f7f8f7c7e6dd2acf9962.png\"/><figcaption></figcaption></figure><p>Вы можете заметить, что выбросы в df уже помечены. Это делается для того, чтобы мы могли сравнить работу алгоритма с фактом. </p><p>Далее визуализируем наш df</p><pre><code class=\"python\">plt.plot(df.x, df.y)\nplt.scatter(df[df.outlier == 1].x, df[df.outlier == 1].y, c='r', label='outlier')</code></pre><p></p><figure class=\"\"><img src=\"https://habrastorage.org/r/w1560/getpro/habr/upload_files/0d4/e9c/3b9/0d4e9c3b922cfda4436436168461448d.png\" width=\"428\" height=\"291\" data-src=\"https://habrastorage.org/getpro/habr/upload_files/0d4/e9c/3b9/0d4e9c3b922cfda4436436168461448d.png\"/><figcaption></figcaption></figure><p>Теперь можно реализовывать фильтр Хэмпеля. Для этого используем 3 стандартных отклонения. Почему именно 3? Потому что этого с лихвой хватит для нашего временного ряда. </p><pre><code class=\"python\">def hampel(y, window_size, simg=3):    \n    n = len(y)\n    new_y = y.copy()\n    k = 1.4826\n    idx = []\n\n    for i in range((window_size),(n - window_size)):\n        r_median = np.median(y[(i - window_size):(i + window_size)]) #скользящая медиана \n        r_mad  = np.median(np.abs(y[(i - window_size):(i + window_size)] - r_median)) #скользящий MAD \n        if (np.abs(y[i] - r_median) > simg * r_mad):\n            new_y[i] = r_median #замена выброса\n            idx.append(i)\n    \n    return new_y, idx</code></pre><p>Вызываем фильтр Хэмплея с окном скользящего среднего равного 3, чтобы определить выброс. Этого будет достаточно для нашей задачи.</p><pre><code class=\"python\">new_y, outliers = hampel(df.y, 3)</code></pre><p>В переменной new_y лежит новый временный ряд без выбросов. В outliers - индексы выбросов во временном ряду.</p><p>Заливаем новый временный ряд в df вместе с признаками выбросов.</p><pre><code class=\"python\">df['new_y'] = new_y\ndf.loc[outliers, 'outlier_hampel'] = 1</code></pre><p>Осталось визуализировать данные.</p><pre><code class=\"python\">from matplotlib.pyplot import figure\nfigure(figsize=(15, 6), dpi=80)\nplt.plot(df.x, df.y)\nplt.plot(df.x, df.new_y)\nplt.scatter(df[df.outlier == 1].x, df[df.outlier == 1].y, c='r', label='outlier')\nplt.scatter(df[df.outlier_hampel == 1].x, df[df.outlier_hampel == 1].y, c='b', label='outlier')</code></pre><p>Выбросы, размеченные вручную, выделяются красным цветом. Синие выбросы – это определение модели. </p><p></p><figure class=\"full-width \"><img src=\"https://habrastorage.org/r/w1560/getpro/habr/upload_files/d42/cd9/e7d/d42cd9e7db8e15f8180c19911482585b.png\" width=\"991\" height=\"396\" data-src=\"https://habrastorage.org/getpro/habr/upload_files/d42/cd9/e7d/d42cd9e7db8e15f8180c19911482585b.png\"/><figcaption></figcaption></figure><p>На графике видно, что красного цвета нет. Вывод – алгоритм работает на отлично. </p><p>Для лучшего понимания возьмём другой временной ряд, чтобы снова проверить алгоритм. </p><p></p><figure class=\"full-width \"><img src=\"https://habrastorage.org/r/w1560/getpro/habr/upload_files/0d5/3c0/ca4/0d53c0ca4f87fa4bd2b379dded702e5c.png\" width=\"991\" height=\"396\" data-src=\"https://habrastorage.org/getpro/habr/upload_files/0d5/3c0/ca4/0d53c0ca4f87fa4bd2b379dded702e5c.png\"/><figcaption></figcaption></figure><p>Здесь заметим, что выбросов гораздо больше. </p><pre><code class=\"python\">new_y, outliers = hampel(df_new.y, 3)\ndf_new['new_y'] = res\ndf_new.loc[detected_outliers, 'outlier_hampel'] = 1\n\nfrom matplotlib.pyplot import figure\nfigure(figsize=(15, 6), dpi=80)\nplt.plot(df_new.x, df_new.y)\nplt.plot(df_new.x, df_new.new_y)\nplt.scatter(df_new[df_new.outlier == 1].x, df_new[df_new.outlier == 1].y, c='r', label='outlier')\nplt.scatter(df_new[df_new.outlier_hampel == 1].x, df_new[df_new.outlier_hampel == 1].y, c='b', label='outlier')</code></pre><p></p><figure class=\"full-width \"><img src=\"https://habrastorage.org/r/w1560/getpro/habr/upload_files/b8d/390/d3f/b8d390d3fbf5305fc446903da8e8937f.png\" width=\"991\" height=\"396\" data-src=\"https://habrastorage.org/getpro/habr/upload_files/b8d/390/d3f/b8d390d3fbf5305fc446903da8e8937f.png\"/><figcaption></figcaption></figure><p>Увеличим окно скользящего среднего.</p><pre><code class=\"python\">new_y, outliers = hampel(df_new.y, 5)\ndf_new['new_y'] = res\ndf_new.loc[detected_outliers, 'outlier_hampel'] = 1\n\nfrom matplotlib.pyplot import figure\nfigure(figsize=(15, 6), dpi=80)\nplt.plot(df_new.x, df_new.y)\nplt.plot(df_new.x, df_new.new_y)\nplt.scatter(df_new[df_new.outlier == 1].x, df_new[df_new.outlier == 1].y, c='r', label='outlier')\nplt.scatter(df_new[df_new.outlier_hampel == 1].x, df_new[df_new.outlier_hampel == 1].y, c='b', label='outlier')</code></pre><p></p><figure class=\"full-width \"><img src=\"https://habrastorage.org/r/w1560/getpro/habr/upload_files/1e7/70e/c36/1e770ec36a5468579df315b33a6aaf05.png\" width=\"991\" height=\"396\" data-src=\"https://habrastorage.org/getpro/habr/upload_files/1e7/70e/c36/1e770ec36a5468579df315b33a6aaf05.png\"/><figcaption></figcaption></figure><p>Видно, что стало гораздо лучше. </p><p>Что касается точности, то она равна 93.33333333333333 %. Я считаю, что это отличный процент. </p><pre><code class=\"python\"> (df_new[df_new.outlier_hampel == 1].shape[0]/df_new[df_new.outlier == 1].shape[0])*100</code></pre><h3>Что в итоге?</h3><p>Фильтр Хэмпеля прекрасно справляется со своей задачей. Его главным преимуществом стала простота реализации. Он может работать быстро как на малых, так и на больших объемах данных. Само собой, есть что улучшить, но в качестве простого и рабочего инструмента фильтр Хэмпеля показывает себя весьма неплохо.</p><p>Но так ли он хорош, если сравнивать его с другими алгоритмами? Например, с тестом Греббса, критерием выбора Рознера и рандомным лесом. Об этом я расскажу в следующих статьях, а в конце сравним результаты работы каждого алгоритма и вынесем окончательный вердикт, что же лучше.</p></div>",
        "clean_body": "Те, кто работает с временными рядами, часто сталкивается с двумя проблемами. Первая – нет полных данных. Вторая – битые данные, когда встречается много выбросов, шума и пропусков. Редко встречаются случаи, когда всё было бы идеально. И данных много, и можно легко найти нужные. Такое встретишь крайне редко или почти никогда. Возникает вопрос - как решить эту проблему? Я нашёл решение. Давайте расскажу вам, как я решаю проблему битых данных, выбросов, пропусков. Какие я использовал методы, в чем их отличия, преимущества и какие я считаю самыми лучшими. Начнём мы с первого метода – фильтра Хэмплея. В этой статье речь пойдёт именно о нём. Я постараюсь как можно проще рассказать о его особенностях и показать всё на наглядных примерах. Приступим.Как работает фильтр ХэмплеяДля начала стоит понять, что такое фильтр Хэмплея. В интернете о нём вы мало что найдёте. По крайней мере, я встретил лишь скудную информацию. Хотя потратил много времени на поиски нужной информации о фильтре. Главная цель Хэмплея – найти и заменить выбросы в заданном временном ряду. Для этого в своей основе он использует скользящее среднее с заданным окном. Для каждой итерации или окна фильтр вычисляет медиану и стандартное отклонение. Оно выражается в среднем абсолютном значении и обозначается как MAD.Материал из вики: https://en.wikipedia.org/wiki/Median_absolute_deviationЧтобы MAD стал последовательной оценкой стандартного отклонения надо умножить его на постоянный коэффициент k. Коэффициент зависит от распределения. Мы считаем, что данные подчиняются распределению Гаусса, поэтому берём коэффициент равным 1,4826.Если значение медианы окна скользящего среднего больше чем х стандартных отклонений, то это – выброс.Фильтр Хэмплея имеет 2 настраиваемых параметра:·         размер раздвижного окна·         количество стандартных отклонений, которые идентифицируют выбросДля начала надо импортировать нужные библиотеки:import matplotlib.pyplot as plt\nimport warnings\nimport pandas as pd\nimport numpy as npЗагрузить данные из csv файла:df = pd.read_csv('data.csv')Распечатать данныеdf.head()Вы можете заметить, что выбросы в df уже помечены. Это делается для того, чтобы мы могли сравнить работу алгоритма с фактом. Далее визуализируем наш dfplt.plot(df.x, df.y)\nplt.scatter(df[df.outlier == 1].x, df[df.outlier == 1].y, c='r', label='outlier')Теперь можно реализовывать фильтр Хэмпеля. Для этого используем 3 стандартных отклонения. Почему именно 3? Потому что этого с лихвой хватит для нашего временного ряда. def hampel(y, window_size, simg=3):    \n    n = len(y)\n    new_y = y.copy()\n    k = 1.4826\n    idx = []\n\n    for i in range((window_size),(n - window_size)):\n        r_median = np.median(y[(i - window_size):(i + window_size)]) #скользящая медиана \n        r_mad  = np.median(np.abs(y[(i - window_size):(i + window_size)] - r_median)) #скользящий MAD \n        if (np.abs(y[i] - r_median) > simg * r_mad):\n            new_y[i] = r_median #замена выброса\n            idx.append(i)\n    \n    return new_y, idxВызываем фильтр Хэмплея с окном скользящего среднего равного 3, чтобы определить выброс. Этого будет достаточно для нашей задачи.new_y, outliers = hampel(df.y, 3)В переменной new_y лежит новый временный ряд без выбросов. В outliers - индексы выбросов во временном ряду.Заливаем новый временный ряд в df вместе с признаками выбросов.df['new_y'] = new_y\ndf.loc[outliers, 'outlier_hampel'] = 1Осталось визуализировать данные.from matplotlib.pyplot import figure\nfigure(figsize=(15, 6), dpi=80)\nplt.plot(df.x, df.y)\nplt.plot(df.x, df.new_y)\nplt.scatter(df[df.outlier == 1].x, df[df.outlier == 1].y, c='r', label='outlier')\nplt.scatter(df[df.outlier_hampel == 1].x, df[df.outlier_hampel == 1].y, c='b', label='outlier')Выбросы, размеченные вручную, выделяются красным цветом. Синие выбросы – это определение модели. На графике видно, что красного цвета нет. Вывод – алгоритм работает на отлично. Для лучшего понимания возьмём другой временной ряд, чтобы снова проверить алгоритм. Здесь заметим, что выбросов гораздо больше. new_y, outliers = hampel(df_new.y, 3)\ndf_new['new_y'] = res\ndf_new.loc[detected_outliers, 'outlier_hampel'] = 1\n\nfrom matplotlib.pyplot import figure\nfigure(figsize=(15, 6), dpi=80)\nplt.plot(df_new.x, df_new.y)\nplt.plot(df_new.x, df_new.new_y)\nplt.scatter(df_new[df_new.outlier == 1].x, df_new[df_new.outlier == 1].y, c='r', label='outlier')\nplt.scatter(df_new[df_new.outlier_hampel == 1].x, df_new[df_new.outlier_hampel == 1].y, c='b', label='outlier')Увеличим окно скользящего среднего.new_y, outliers = hampel(df_new.y, 5)\ndf_new['new_y'] = res\ndf_new.loc[detected_outliers, 'outlier_hampel'] = 1\n\nfrom matplotlib.pyplot import figure\nfigure(figsize=(15, 6), dpi=80)\nplt.plot(df_new.x, df_new.y)\nplt.plot(df_new.x, df_new.new_y)\nplt.scatter(df_new[df_new.outlier == 1].x, df_new[df_new.outlier == 1].y, c='r', label='outlier')\nplt.scatter(df_new[df_new.outlier_hampel == 1].x, df_new[df_new.outlier_hampel == 1].y, c='b', label='outlier')Видно, что стало гораздо лучше. Что касается точности, то она равна 93.33333333333333 %. Я считаю, что это отличный процент.  (df_new[df_new.outlier_hampel == 1].shape[0]/df_new[df_new.outlier == 1].shape[0])*100Что в итоге?Фильтр Хэмпеля прекрасно справляется со своей задачей. Его главным преимуществом стала простота реализации. Он может работать быстро как на малых, так и на больших объемах данных. Само собой, есть что улучшить, но в качестве простого и рабочего инструмента фильтр Хэмпеля показывает себя весьма неплохо.Но так ли он хорош, если сравнивать его с другими алгоритмами? Например, с тестом Греббса, критерием выбора Рознера и рандомным лесом. Об этом я расскажу в следующих статьях, а в конце сравним результаты работы каждого алгоритма и вынесем окончательный вердикт, что же лучше.",
        "meta_tags": [
            "python",
            "фильтра Хэмплея",
            "выбросы",
            "Поиск выбросов",
            "временный ряд",
            "ml"
        ]
    },
    {
        "publish_datetime": 1670042527.0,
        "author": "Разномазов Валерий",
        "title": "К вопросу  о роли аналитика на современных банковских ИТ-проектах",
        "title_image_url": "https://habrastorage.org/getpro/habr/upload_files/8cf/7f0/6cb/8cf7f06cbd3e840c858c52641fe59e3c.png",
        "raw_body": "<div xmlns=\"http://www.w3.org/1999/xhtml\"><p>Имею опыт работы порядка 7 лет в банках уровня ТОП-5  и пришел к выводу, о том что до сих пор в разных командах нет единого понимания о том, какую же роль играют аналитики в командах и никто, включая самих аналитиков вам не скажет, какие обязанности должны ими выполняться. Ну кроме, пожалуй, единого мнения о том, что аналитик должен “писать документацию”. Хочется также отметить тот факт, что, само наличие аналитика в команде, которая работает по Agile, когда разработки по ТЗ в строгом смысле этого слова уже нет, уже само по себе проблема. И если банк у вас современный и вы работаете не по “водопаду”, а по какой-то более гибкой методологии, вам придется решать три проблемы анализа на банковских ИТ-проектах:</p><ol><li><p>Как сделать так, чтоб заказчик и разработчики не игнорировали присутствие аналитика?</p></li><li><p>Как сделать так, чтоб документацию, написанную аналитиком читали разработчики?</p></li><li><p>Как сохранить набранных аналитиков в команде, если вся остальная команда прекрасно справляется и без аналитика.</p></li></ol><p>Основная проблема аналитиков в том, что аналитики - специальность суррогатная. Суррогатность означает, что созданы аналитики были для того, чтобы сопровождать процесс производства программных средств и сами напрямую в этом процессе не участвуют. Часто ведь для обывателя, человек, работающий в ИТ это человек так или иначе связанный с языками программирования. И часто, люди очень удивлены, что есть в ИТ роли, которые и программировать-то толком не умеют. Аналитики в настоящий момент в большинстве случаев выполняют следующие функции:</p><ol><li><p>Обеспечивают перевод желаний заказчика на язык разработчиков.</p></li><li><p>Обеспечивают создание документации (технических заданий и базы знаний).</p></li><li><p>Являются центральным узлом коммуникации в команде. </p></li></ol><p>Интересная тенденция, наводящая на мысли о кризисе специальности - если проследить основные тезисы докладов на конференции аналитиков или статей на тему анализа за последнее время, то солидный перевес будет в сторону так называемых “soft-skils”. Складывается ощущение, что никакими техническими навыками аналитики не обладают - потому и поделиться вроде бы нечем. Или они попросту не должны ими обладать? А может все эти статьи и публикации лишь попытки доказать, что аналитик команде все же нужен.</p><p> <strong>“Кто мы?”</strong></p><p>А меж тем, как показывает личный опыт, роль аналитика на проекте чрезвычайно важна. Ведь, если убрать аналитика с его \"техническими заданиями\" и прочей \"документацией\", кто ж виноват-то во всем будет? Неужели архитектор или разработчик? А может быть сам заказчик? Нет же. Виноват будет всегда аналитик. Потому что, как многие думают, нужен он для написания документации, а разработку (не смотря на то, что всем говорим про Agile) мы ведем по согласованному техническому заданию по-старинке. И если появляется какое-то несоответствие или искажение изначальной сути, то разработчик делает круглые глаза и говорит “а так было в техническом задании”. </p><p><em>Решил попытаться самостоятельно разобраться в данной проблеме и сформулировать собственное видение проблем анализа.</em></p><p>Лично я выделяю три геологических эпохи в развитии ИТ. Может быть все глобально не так просто, так что три эпохи я буду выделять в ИТ только лишь банков. Эпохи эти называются так - монолитный мультифункционал, SOA и микросервисы. И поговорить бы хотелось о том, что во всех трех эпохах у аналитика были принципиально разные обязанности.</p><p>Давайте обратимся к истории вопроса. Зачем изначально появился анализ? Как только возникли средства автоматизации делового оборота, возникла потребность переводить на язык инженеров, которые пишут компьютерные программы пожелания заказчиков со стороны бизнеса.Начиная с 1990х годов на рынке производства программного обеспечения начало образовываться довольно большое количество игроков, занимавших разные его доли. Довольно часто происходила следующая вещь - разработчики сами предлагали заказчику техническое решение и вынуждали перекраивать устоявшиеся бизнес-процессы под свое решение, что не всегда устраивало заказчика. Иногда даже получалось так, что бизнес-модель компании складывалась из того ПО, которое оно использовало для автоматизации. 1С или SAP - разница была большая. </p><p>С другой стороны, при возникновении более-менее серьезного подхода к делу, возникла надобность в оформлении документации на разработку. Собственно, в банках, эта роль стала называться \"технологами\". По сути, эти люди были простыми \"техническими писателями\", которые описывали процесс и выдавали разработке то самое \"техническое задание\", по которому она велась. А дальше им в обязанности стали добавлять представлять интересы заказчика. И начали они ходить с книгами типа Карла Вигерса под мышками и устраивать интервью заказчику, пытаясь перенести его требование на бумагу. </p><figure class=\"full-width \"><img src=\"https://habrastorage.org/r/w1560/getpro/habr/upload_files/8cf/7f0/6cb/8cf7f06cbd3e840c858c52641fe59e3c.png\" width=\"960\" height=\"720\" data-src=\"https://habrastorage.org/getpro/habr/upload_files/8cf/7f0/6cb/8cf7f06cbd3e840c858c52641fe59e3c.png\"/><figcaption></figcaption></figure><p><strong>Как возник анализ в ИТ</strong></p><p>На моей памяти был один забавный процесс автоматизации стекольного завода в 2015 году. До поры до времени, инженеры завода при формировании задания на производство обходились электронной таблицей MS Office. В данную таблицу были защиты параметры расчета количества материала, цены и иногда количество единиц сырья на складе. Система прекрасно работала и сбоев не давала. Откуда возникла идея внедрить вендерное решение и кто привёл именно ту фирму, что в итоге занялась автоматизацией никто уже и не вспомнит. Как сейчас ( спустя 7 лет) становится понятно, ключевую роль в выборе технического решения сыграли личные связи владельца бизнеса. Только фирма та с устоявшимися процессами сильно не церемонилась. Система сопровождения производства была внедрена командно-административным подходом и разрушила все существующие к тому моменту на предприятии связи.</p><p>Что же произошло?</p><ul><li><p>Во-первых, внедряемая система была довольно монстрообразным монолитом и охватывала все процессы на заводе: от заведения заказов, до склада и ведения заготовки по цеху и ведения бухгалтерии. К чему это привело? Элементы интерфейса были написаны в единой семантической системе, рождённой вне данного завода. И если раньше, люди в бухгалтерии, на складе и в цеху не владея терминологией процессов друг друга договаривались ввиду наличия межличностных отношений, то теперь они коллективно не могли понять семантический смысл элементов интерфейса внедренной системы. </p></li><li><p>Второй момент, система была рассчитана на заранее определенное количество производственных участков и движение заготовки по цеху в соответствии с маршрутом, какой разработчики посчитали наиболее правильным в соответствии со своим предыдущим опытом. Внедрение \"программы\" было настолько агрессивным со стороны разработчика, что они покусились даже на гостовскую разметку цеха, приведя все технологические участки в соответствие с парадигмой своего программного детища. Естественно, данное обстоятельство заставляло пересматривать устоявшиеся годами и человеческие и инженерные коммуникации между цехами.</p></li></ul><p>Когда завод встал и не смог на какое-то время обрабатывать заказы от клиентов, а часть клиентских менеджеров предприятия  затеяла партизанскую войну и наиболее ценные заказы тайно от руководства продолжила вести в виде электронных таблиц MS Office, разработчики великодушно велели выделить им людей для выравнивания процессов. Собственно говоря, так на том заводе появились первые ИТ-аналитики.</p><p>Какую роль они выполняли?</p><p><strong>Технологи - прослойка между заказчиком и разработкой. Эпоха монолитных десктопных приложений.</strong></p><p>Так на рубеже 20-го и 21-го веков появилась первая суррогатная специальность в ИТ - технологи. Сначала они выполняли работу тех самых технических писателей и сопоставляли обработку данных в системе с технологическими процессами. Анализа, как такового было было. Зато появилась “прослойка” между заказчиком и ИТ. Прослойка эта занималась подготовкой того самого “ТЗ” (технического задания), которое утверждал заказчик и брал в работу разработчик. Причина возникновения этой роли в том, что приземленный заказчик не мог на доступном языке объяснить высокомерным разработчикам, чего же он от них хочет. </p><p>Была и другая причина. Разработка программных решений в энтерпрайс вышла на новый уровень и часто заказчика и разработку начали связывать договорные отношения. Начали возникаь первые конфликты, в том числе и доведенные до судебных инстанций. И для того, чтобы судья (как юрист) мог понять, кто тут прав, а кто виноват, ему нужен был документ - то самое техническое задание на разработку. Так как ни бизнес, ни разработка писать его не хотели, возникла надобность привлекать третью сторону - технолога.</p><p>Всем сразу же захотелось иметь штат таких технологов, особенно банкам. Почему банки, ну потому что именно они начали первыми сталкиваться с проблемами построения ИТ-систем в энтерпрайсе. Как правило, технологами становились технически подкованные специалисты со стороны бизнеса. Тут же вспомнили про ГОСТ 34 и начали требовать написания документации в соответствии с этим ГОСТом.</p><p>При этом, надо отметить, что очень быстро “технологи” перестали быть просто “техническими писателями”. Когда возникали явные несоответствия уровня ИТ бизнес-требованиям и требовались доработки, возникнувшая дискуссия с разработкой заставляла вносить изменения уже в программный код по инициативе технолога. Можно сказать, что таково было начало бизнес-анализа.</p><p>Если рассмотреть процессы в других областях, то можно проследить такую же тенденцию, что и на описанном мной заводе. Внедрение вендорных решений потребовало мобилизации со стороны заказчика специалистов для прописывания процессов, требующих автоматизации. Такие люди в банках стали называться \"технологами\". Основным артефактом их работы стали те самые \"технические задания\", по которым велась разработка. Ведущая роль же в процессе создания средств автоматизации оставалась по прежнему за разработчиками.</p><p><strong>Эпоха SOA. Возникновение бизнес-анализа и приход анализа системного</strong></p><p>Со временем ИТ-инфраструктура стала играть ведущую роль в обеспечении создания добавочной стоимости. И потребовались принципиально новые подходы в формировании требований к разработке. Компании, конкурирующие друг с другом, начали осознавать, что в борьбе за клиента нужно предлагать ему более удобное средство автоматизации процесса, чем у остальных игроков на рынке. И вот тут свою роль начали играть попытки разработчиков встраивать свое видение процесса. Чем сложнее становилась создаваемая система, тем чаще заказчик начинал получать не соответствующие исходному техническому заданию решения. Почему так выходило? Разработчики, вследствие своей ведущей роли в процессе, пользовались служебным положением и решали проблему так, как им было проще и так, как они считали нужным. Вот тогда, руководство компаний задумалось о привлечении сторонних разработчиков или консалтов с интеграторами, которые будут решать проблемы на концептуальном уровне. При этом, степень зрелости бизнеса в ИТ процессах росла и решить концептуально проблему самостоятельно заказчик был уже в состоянии сам. Таким образом возникло понятие \"архитектуры решения\", которое являлось продуктом труда полноценной команды аналитиков. Аналитиков со стороны бизнеса. Такие аналитики, уже приходили к разработчикам напрямую и разговаривали с ними с позиций клиента, требующим исполнения своих требований в соответствии с договором. А как только на предприятии возникала надобность связать две и более концепции понадобились архитекторы со стороны бизнеса. </p><p><strong>Разметка предметного поля и модель данных</strong></p><p>В чем особенность SOA? Разные ИТ-системы обслуживали одни и теже бизнес-сущности в рамках различных бизнес-процессов. Если процессы разные, а сущности теже, то возможно самым правильным станет выделение этих сущностей и установление связей между ними? Как раз в это время рождается идея пойти по пути Карла Линнея и построить для банка “классификацию видов” бизнес-сущностей. И вот тут, впервые возникла надобность составлять модели данных и размечать предметное поле. И никто кроме аналитиков размечать предметное поле не стал.</p><p><strong>Разъединение BA и SA.</strong></p><p>Базовое физико-математическое образование заставляет мыслить системно. Давайте в свете вышесказанного про модель  данных сформулируем то чем бизнес-аналитик отличается от системного аналитика.</p><p><em>Основная теорема бизнес-анализа:</em> любой бизнес-процесс можно представить как описание связей между однозначно определяемыми бизнес-субъектами и бизнес-объектами, которые также могут участвовать и в других бизнес-процессах.</p><p><em>Основная задача бизнес-анализа:</em> определять субъекты, объекты и связи между ними в рамках данного бизнес процесса.</p><p>Возникла еще одна проблема. Со временем в арсенале разработки появлялось все больше и больше инструментов выросших в своего рода \"зоопарк систем\". Разработчики же не могли самостоятельно выбирать способ, систему или методику, по которой будет решена та или иная задача. Возникла надобность в специалистах, которые бы перекладывали идеи бизнеса на ИТ системы предприятия. Так появились системные аналитики. В их обязанности стало входить выбирать решение и описывать его для разработчика. В той ситуации подобные аналитики находились на стороне вендера или интегратора. Со временем, они начали заводиться и внутри организаций заказчика. </p><p>На данном этапе начали возникать такие понятия как “маппинг” и “метчинг”, то есть артефакты в которых семантика в одной схеме (будь то XML, JSON или позиционная строка) сопоставляется семантике в другой схеме. И вот тут возникла проблема того самого “семантического безумия”, о котором я говорил в ряде своих докладов. Данное явление наблюдается в ИТ-системах, когда начинает работать множество различных команд - и все начинают одни и теже вещи называть по-разному. Или наоборот, одним и тем же словом называют принципиально разные сущности или явления.</p><p><em>Основная теорема системного анализа (теорема об унивокальности с бизнесом):</em> Любой бизнес-объект имеет одну и только одну  проекцию в пространствах классов языков программирования и таблиц баз данных.</p><p><em>Основная задача системного анализа:</em> Зная набор бизнес-объектов, определять классы языка программирования и таблицы баз данных соотвествующие им.</p><p><strong>Еще раз об архитектуре и анализе</strong></p><p>Чем дальше шло развитие ИТ-инфрастурктуры, тем больше задач требовалось решать на концептуальном уровне. С другой стороны, начали возникать задачи интеграции одного решения в другое, когда несколько концептуальных схем как со стороны бизнес-идеи, так и со стороны технических решений необходимо было объединять в единую общую картину. Так стала возникать “архитектура” как новая дисциплина. Причем, на том этапе (а это была эпоха SOA - сервис ориентированной архитектуры), как со стороны бизнес-идеи, так со стороны систем решения, так и стороны архитектуры (сервера и каналы связи). Наличие документов с концептуальной архитектурой, описание заданий на доработку и серверной части привело к возникновению документации разного уровня. Именно в эпоху SOA начали произносить слово (HLA - high level architecture - верхнеуровневое описание архитектуры). Да и популярная в то время модель OSI требовала описания процессов на разных уровнях.</p><p>У аналитиков появилась еще одна неожиданная функция. Они начали составлять документацию не только для разработки, но и формировать так называемые “базы знаний”. Для чего понадобилась в enterprise база знаний? Для последующих поколений и интеграции. Когда наступила эпоха SOA, возникла необходимость интегрировать “все-со-всем”. Системы стали “потребителями” (target system) и “поставщиками” (source system) друг друга. Естественно, в целях установления информационного обмена, для “поставщиков” понадобилась документация “потребителей”, а для “потребителей” возникла необходимость в документации “поставщиков”. И вот когда выяснилось, что из документации у всех только плохие ТЗ на разработку. КАзалось, бы надо опять нанимать технических писателей, или студентов-практикантов, которые бы денно и ношно сидели бы и описывали. Но.. к счастью, нашлось решение лучше. Решением этим стал Confluence. В процессе работы, множеству аналитиков и архитекторов (как бизнес, так и системных) стало возможным описывать свой маленький кусочек. И если все страницы связаны в единое целое, то получается вполне стройная техническая документация. </p><p>И архитектор и аналитик производили документацию, но различного уровня. В чем же разница между аналитиком и архитектором? </p><p>В предыдущем разделе я говорил об “унивокальности”. Термин “унивокальность” взят из религиозной литературы, а именно из трудов Блаженного Августина. Он говорил об “унивокальности со Всевышним”, рассуждая об одинаковом понимании вещей человеком и Богом. Я не Блаженный Августин, но часто также задаю вопрос, одинаково ли разработка и заказчик понимают суть вещей? Поэтому, как следствие теоремы об унивокальности, должна быть выстроена четкая связь между бизнес-сущностью и соответствующими ей ИТ-объектами (DataTransferObject, XSD, JSONSchema, таблицами баз данных и прочими). Задачей архитектора в этой парадигме является установление этого закона, обеспечения однозначности и понятности. Если такой закон есть, то у системного аналитика появляется инструмент для работы и все процесс (интеграции, разработка нового функционала) проводятся в соответствии с этим законом. Таким образом, <em>основной задачей архитектора</em> является - установление “унивокальности”, то есть четкого  закона по которому каждой бизнес сущности в рамках каждого бизнес-процесса ставятся в соответствие определенные, однозначно определяемые, ИТ-объекты.  </p><p>В эпоху SOA пришло осознание, что архитектуру нужно продумывать изначально. Изначально теперь начали возникать такие артефакты, как HLA (High-level Architecture). Кроме того, возникли проблемы с семантикой. Выяснилось, что “семантическое безумие” это не вымысел, а оно правда существует. В этот момент многие крупные банки начали приходить к концепции Общей Модели Данных для всех ИТ-систем, построенной на глобальных бизнес-объектах. Глобальные бизнес-объекты хранились изначально в XSD, а позже в JSONSchema. И маппинг, о котором говорилось выше, подразумевал совоставление одной схемы другой схеме, что существенно ускоряло процесс анализа. </p><p>Неоднократно в своих докладах приводил аналогии, доказывая, что в ИТ нужны инженерные знания и бекграунд. И вот тут такая история. Как многие помнят, в 1986 году случилась авария на Чернобыльской атомной электростанции. Одной из причин данной аварии, как выяснила комиссия, являлось несоответствие эксплуатационной документации различного уровня друг другу. Грубо говоря, верхеуровневая документация написанная академиками Александровым и Долежалем противоречила той, что главный инженер утверждал для смены на атомной электростанции. К счастью, последствия наших несоответствий не столь плачевны, но также могут привести к “перегреву”, но уже в ИТ-системе. </p><p><strong>И вот наступил Agile. Эпоха Микросервисов. Не документация, а артефакты.</strong></p><p>Как ИТ превратилось в сфере с наиболее динамично развитым маркетингом и накачкой деньгами никто не понял. Однако, на данный момент все больше и больше разных  людей начали работать в ИТ в неожиданно новых ролях. Если раньше промежуточным звеном между бизнесом и разработчиком были только  айтишники, то теперь появились целые гроздья новых специальностей, которые зна первый взгляд ( да и на второй тоже) добавочной стоимости в ИТ продукте не делают.</p><p>Во времена Agile земля под аналитиками затряслась больше, чем под другими ролями. Ибо сказано: работающий код важнее исчерпывающей документации. На первых порах, евангелисты Agile понимали эту фразу буквально и каленым железом жгли все попытки задокументировать что-то на проектах. Вот и прошлось брату-аналитику пытаться перестроиться. В эпоху Agile остался бизнес-аналитик вне продуктовой команды, а системный аналитик превратился в солюшн архитектора, то есть архитектора решения. Почему так произошло? Степень зрелости в ИТ за последнее время драматически возросла и да, есть конторы, которые подошли к Agile не в угоду моде, а осознанно. С другой стороны, в эпоху Agile основным артефактом стало не техническое задание, а карточка в трекере. И вектор полезности сместился от ТЗ, к карточкам в трекере. В хороших команадах по карточке в трекере можно было вытянуть и страницу в Confluence с архитектурой и соответствующий коммит в GIT. И всю цепочку исполнителей. В эту эпоху документация перестала называться “документацией” и стала называться “артефактами”.</p><p>С другой стороны, сопровождать традиционно построенное приложение (или как говорят у нас “монолит”) в условиях Agile становится проблематично. Возник архитектурный стиль, который стал называться “микросервисной архитектурой”. Парадигма микросервисов дала возможность бурно развиваться различным идеям. А значит количество артефактов, несущих какую-либо полезную информацию росло в геометрической прогрессии. Возникла необходимость наводить в этом хозяйстве порядок.</p><p><strong>Появление других суррогантных ролей в командах</strong></p><p>Agile быстро стал новой религией в ИТ и превратился в “вещь в себе”. Любой религии нужны “служители культа” и жрецы. Семейство суррогатных ролей, в котором до этого были только аналитики и архитекторы, начало пополняться новыми диковинными видами.</p><p>После того, как все задачи начали отображать в виде разноцветных карточек на доске, такой доске понадобилась хозяйка или хозяин. Возникла отдельная роль - менеджер проекта, которого иногда называли скрам-мастером. Данная роль получила власть над главнейшим артефактом - карточками в трекере. </p><p>Другая вещь, породившая новые роли,это DevOps и парадигма  CI/CD. Элементарная задача - составить релиз и спланировать поставку в условиях - оказалась продуктовой команде не под силу. Понадобилась новая роль - менеджер релизов. В их власти оказался GIT, система через которую ведется весь процесс движения “от дева в прод”. Можно сказать кровеносная система enterprice.</p><p>Так же появились такие роли как product owner и platform owner. Agile уничтожил все вертикали, сделав горизонтальным или матричным менеджмент. Если мы говорим о парадигме SOA, то понадобились специфические архитектурные роли. Произошло разделение на на продукт и платформу, которая её содержит. Эти роли писали документацию уже по-новому. Они писали её как архитектуру. По новым принципам.</p><p>В новой геологической эпохе тяжко стало аналитикам. Продуктовой команде, люди которые просто пишут документацию, оказались не нужны. Артефакты ведь сами собой получались. Уровень зрелости бизнеса в ИТ начинал расти, не нужен им стал бизнес анализ. Системный аналитик продуктовой команде также не нужен. Разработке со стороны заказчика спукают метрики и по хорошо разжеванным паттернам они стали работать. Да еще появился этот самый Swager - который позволял из их генерировать!  Казалось, надо бы начинать собираться мести улицы. Хотя осталось еще одно место, где документация сама по себе была нужна - это работа на государственные или полугосударственные компании. </p><p>И аналитики начали превращаться в архитекторов решений. С одной стороны они стали отвечать за разметку предметного поля и построение моделей данных, а с другой - они существенно повысив свой инженерный уровень начали проектировать решения в рамках одного микросервиса.</p><p><strong>А что если разработка ведется на государственную компанию?</strong></p><p>Да. Agile это хорошо. И можно привести много примеров, когда он работает. Да вот беда, что делать, если вы работаете на государственную компанию, в которой документация это основной артефакт. Там нет Agile, а есть “водопад”. Или есть Agile, но документация все же остается важнее работающего продукта. Почему? Ну потому что в государственных компаниях бывают проверки и аудиты и такая документация нужна нее столько для разработки, сколько для прокурора. Ну не будешь же ты прокурору и контролирующим органам показывать карточки в Jira? Таким командам нужен все же технический писатель, вместе с полноценными аналитиками, которые кропотливо пишут ТЗ, которые написаны строго по ГОСТу и утверждаются начальством как положено, а руководитель предприятия ставит подпись, которая скрепляется печатью.</p><p><strong>Заключение. И все-таки аналитики выжили во всех геологических эпохах.</strong></p><p>Если вы в ИТ давно, и имеете дело с командой, в которой есть аналитики, то попытайтесь вспомнить, что заставило команду искать аналитиков. Объективная ли это была надобность? Или это было потому что “так было у всех”?. Подумайте над тем, а что стало бы с вашими процессами, если бы аналитиков совсем не стало? Ухудшились бы они? Или может быть всем бы только полегчало?</p><p>Если вы аналитик, проанализируйте как менялись требования к вам и как менялась ваша компетенция за последние 2 года?</p><p>Ответы на вопросы и их анализ заставляет задуматься и делать прогнозы с выводами. </p><p>Стало совершенно понятно, что бизнес-анализ в enterprice в нынешнем объеме скоро перестанет быть востребован. Хороший менеджер направления уже прекрасно понимает, что такое ИТ-система и сам в состоянии сформулировать свою “хотелку”. Разработчики также ведут разработку по строго определенным паттернам, и если системный аналитик не превращается в архитектора решения, а хочет дальше только лишь писать техническую документацию, то ценность его для рынка труда в скором времени также застремится к нулю. Перевод с языка заказчика на язык разработчика скоро станет не нужен.</p><p>Документация. Техническое решение без документации и без общих средств её написания и модернизации, как цивилизация без письменности. Такое решение либо будет со временем уничтожено, либо будет поглощено другим более понятным окружающим решением. Agile, такие системы как Confluence (аналогичные в этом ряду) да и общий рост технических знаний приведет к тому, что в процессе создания документации и баз знаний будет задействована вся команда на разных уровнях. Единственным исключением станет ИТ в органах государственной власти, где как я писал выше у документации несколько иная роль, чем вести по ней разработку.</p><p>Коммуникация. Раньше, когда работали по “водопаду” было так, что аналитик был единой точкой входа для заданий заказчика. Он же собирал все вопросы разработки и добывал ответы, собирая и скрупулезно прорабатывая каждый пункт. Когда мы работаем по Agile, то создаем “продуктовую команду”. Предполагается, что эта команда живет в едином информационном пространстве и вся информация единовременно доходит до всех на дейли, ретро и прочих ритуалах команды. Зачем тут связующее звено? </p><p>Вспомнилась мне история. Год или полтора назад работал я в одном интеграторе. Интегратор много из себя строил, говорил что работает по SCRUM, а сам пропагандирорвал идеи Карла Вингерса и натравливал на заказчика девочек \"анализирующих\" бизнес-требования и рисующих в пейнте интерфейсики.  Каждое утро начиналось дейли, на котором муссировалась одна вечная тема - сроки. Заказчику обещаны были одни, а по факту уходили уже на 3-й или 4й спринт спустя обещанного. Ничего нового не было и на этом дейли, разработка разводила руками и говорила, что делала по ТЗ, что им не понятно, как из того что там написано следовало то, что ждет тестировщик. Тестировщик возводил глаза к небу и вспоминал архитектуру платформы. Архитектор перебивал всех и говорил, что эта проблема не его уровень и конкретными решениями он не занимается, а мыслит глобально. Проджект менеджер же сказал, что у любой проблемы есть “имя, фамилия и отчество”. И все дружно начинали тыкать пальцами на аналитика. Он утирался, говорил что все поправит. А скрам-мастер - добрый толстый бородач, слушая мытарства взятого на проект 5 месяцев назад парня сказал только - “Команда без аналитика, что деревня без дурачка” и хлопал его по плечу. Пожалуй, можно было бы взять эту фразу эпиграфом к данному повествованию. </p><p>Укрепился я в мыслях, что аналитики пишущие документацию и формализующие бизнес-требования, эта специальность, доживающая свой век. И что убери такого аналитика - всем только полегчает. </p><p>У аналитиков теперь иная роль - копить знания, быть хранителями этих знаний и систематизировать эти знания.</p><p></p></div>",
        "clean_body": "Имею опыт работы порядка 7 лет в банках уровня ТОП-5  и пришел к выводу, о том что до сих пор в разных командах нет единого понимания о том, какую же роль играют аналитики в командах и никто, включая самих аналитиков вам не скажет, какие обязанности должны ими выполняться. Ну кроме, пожалуй, единого мнения о том, что аналитик должен “писать документацию”. Хочется также отметить тот факт, что, само наличие аналитика в команде, которая работает по Agile, когда разработки по ТЗ в строгом смысле этого слова уже нет, уже само по себе проблема. И если банк у вас современный и вы работаете не по “водопаду”, а по какой-то более гибкой методологии, вам придется решать три проблемы анализа на банковских ИТ-проектах:Как сделать так, чтоб заказчик и разработчики не игнорировали присутствие аналитика?Как сделать так, чтоб документацию, написанную аналитиком читали разработчики?Как сохранить набранных аналитиков в команде, если вся остальная команда прекрасно справляется и без аналитика.Основная проблема аналитиков в том, что аналитики - специальность суррогатная. Суррогатность означает, что созданы аналитики были для того, чтобы сопровождать процесс производства программных средств и сами напрямую в этом процессе не участвуют. Часто ведь для обывателя, человек, работающий в ИТ это человек так или иначе связанный с языками программирования. И часто, люди очень удивлены, что есть в ИТ роли, которые и программировать-то толком не умеют. Аналитики в настоящий момент в большинстве случаев выполняют следующие функции:Обеспечивают перевод желаний заказчика на язык разработчиков.Обеспечивают создание документации (технических заданий и базы знаний).Являются центральным узлом коммуникации в команде. Интересная тенденция, наводящая на мысли о кризисе специальности - если проследить основные тезисы докладов на конференции аналитиков или статей на тему анализа за последнее время, то солидный перевес будет в сторону так называемых “soft-skils”. Складывается ощущение, что никакими техническими навыками аналитики не обладают - потому и поделиться вроде бы нечем. Или они попросту не должны ими обладать? А может все эти статьи и публикации лишь попытки доказать, что аналитик команде все же нужен. “Кто мы?”А меж тем, как показывает личный опыт, роль аналитика на проекте чрезвычайно важна. Ведь, если убрать аналитика с его \"техническими заданиями\" и прочей \"документацией\", кто ж виноват-то во всем будет? Неужели архитектор или разработчик? А может быть сам заказчик? Нет же. Виноват будет всегда аналитик. Потому что, как многие думают, нужен он для написания документации, а разработку (не смотря на то, что всем говорим про Agile) мы ведем по согласованному техническому заданию по-старинке. И если появляется какое-то несоответствие или искажение изначальной сути, то разработчик делает круглые глаза и говорит “а так было в техническом задании”. Решил попытаться самостоятельно разобраться в данной проблеме и сформулировать собственное видение проблем анализа.Лично я выделяю три геологических эпохи в развитии ИТ. Может быть все глобально не так просто, так что три эпохи я буду выделять в ИТ только лишь банков. Эпохи эти называются так - монолитный мультифункционал, SOA и микросервисы. И поговорить бы хотелось о том, что во всех трех эпохах у аналитика были принципиально разные обязанности.Давайте обратимся к истории вопроса. Зачем изначально появился анализ? Как только возникли средства автоматизации делового оборота, возникла потребность переводить на язык инженеров, которые пишут компьютерные программы пожелания заказчиков со стороны бизнеса.Начиная с 1990х годов на рынке производства программного обеспечения начало образовываться довольно большое количество игроков, занимавших разные его доли. Довольно часто происходила следующая вещь - разработчики сами предлагали заказчику техническое решение и вынуждали перекраивать устоявшиеся бизнес-процессы под свое решение, что не всегда устраивало заказчика. Иногда даже получалось так, что бизнес-модель компании складывалась из того ПО, которое оно использовало для автоматизации. 1С или SAP - разница была большая. С другой стороны, при возникновении более-менее серьезного подхода к делу, возникла надобность в оформлении документации на разработку. Собственно, в банках, эта роль стала называться \"технологами\". По сути, эти люди были простыми \"техническими писателями\", которые описывали процесс и выдавали разработке то самое \"техническое задание\", по которому она велась. А дальше им в обязанности стали добавлять представлять интересы заказчика. И начали они ходить с книгами типа Карла Вигерса под мышками и устраивать интервью заказчику, пытаясь перенести его требование на бумагу. Как возник анализ в ИТНа моей памяти был один забавный процесс автоматизации стекольного завода в 2015 году. До поры до времени, инженеры завода при формировании задания на производство обходились электронной таблицей MS Office. В данную таблицу были защиты параметры расчета количества материала, цены и иногда количество единиц сырья на складе. Система прекрасно работала и сбоев не давала. Откуда возникла идея внедрить вендерное решение и кто привёл именно ту фирму, что в итоге занялась автоматизацией никто уже и не вспомнит. Как сейчас ( спустя 7 лет) становится понятно, ключевую роль в выборе технического решения сыграли личные связи владельца бизнеса. Только фирма та с устоявшимися процессами сильно не церемонилась. Система сопровождения производства была внедрена командно-административным подходом и разрушила все существующие к тому моменту на предприятии связи.Что же произошло?Во-первых, внедряемая система была довольно монстрообразным монолитом и охватывала все процессы на заводе: от заведения заказов, до склада и ведения заготовки по цеху и ведения бухгалтерии. К чему это привело? Элементы интерфейса были написаны в единой семантической системе, рождённой вне данного завода. И если раньше, люди в бухгалтерии, на складе и в цеху не владея терминологией процессов друг друга договаривались ввиду наличия межличностных отношений, то теперь они коллективно не могли понять семантический смысл элементов интерфейса внедренной системы. Второй момент, система была рассчитана на заранее определенное количество производственных участков и движение заготовки по цеху в соответствии с маршрутом, какой разработчики посчитали наиболее правильным в соответствии со своим предыдущим опытом. Внедрение \"программы\" было настолько агрессивным со стороны разработчика, что они покусились даже на гостовскую разметку цеха, приведя все технологические участки в соответствие с парадигмой своего программного детища. Естественно, данное обстоятельство заставляло пересматривать устоявшиеся годами и человеческие и инженерные коммуникации между цехами.Когда завод встал и не смог на какое-то время обрабатывать заказы от клиентов, а часть клиентских менеджеров предприятия  затеяла партизанскую войну и наиболее ценные заказы тайно от руководства продолжила вести в виде электронных таблиц MS Office, разработчики великодушно велели выделить им людей для выравнивания процессов. Собственно говоря, так на том заводе появились первые ИТ-аналитики.Какую роль они выполняли?Технологи - прослойка между заказчиком и разработкой. Эпоха монолитных десктопных приложений.Так на рубеже 20-го и 21-го веков появилась первая суррогатная специальность в ИТ - технологи. Сначала они выполняли работу тех самых технических писателей и сопоставляли обработку данных в системе с технологическими процессами. Анализа, как такового было было. Зато появилась “прослойка” между заказчиком и ИТ. Прослойка эта занималась подготовкой того самого “ТЗ” (технического задания), которое утверждал заказчик и брал в работу разработчик. Причина возникновения этой роли в том, что приземленный заказчик не мог на доступном языке объяснить высокомерным разработчикам, чего же он от них хочет. Была и другая причина. Разработка программных решений в энтерпрайс вышла на новый уровень и часто заказчика и разработку начали связывать договорные отношения. Начали возникаь первые конфликты, в том числе и доведенные до судебных инстанций. И для того, чтобы судья (как юрист) мог понять, кто тут прав, а кто виноват, ему нужен был документ - то самое техническое задание на разработку. Так как ни бизнес, ни разработка писать его не хотели, возникла надобность привлекать третью сторону - технолога.Всем сразу же захотелось иметь штат таких технологов, особенно банкам. Почему банки, ну потому что именно они начали первыми сталкиваться с проблемами построения ИТ-систем в энтерпрайсе. Как правило, технологами становились технически подкованные специалисты со стороны бизнеса. Тут же вспомнили про ГОСТ 34 и начали требовать написания документации в соответствии с этим ГОСТом.При этом, надо отметить, что очень быстро “технологи” перестали быть просто “техническими писателями”. Когда возникали явные несоответствия уровня ИТ бизнес-требованиям и требовались доработки, возникнувшая дискуссия с разработкой заставляла вносить изменения уже в программный код по инициативе технолога. Можно сказать, что таково было начало бизнес-анализа.Если рассмотреть процессы в других областях, то можно проследить такую же тенденцию, что и на описанном мной заводе. Внедрение вендорных решений потребовало мобилизации со стороны заказчика специалистов для прописывания процессов, требующих автоматизации. Такие люди в банках стали называться \"технологами\". Основным артефактом их работы стали те самые \"технические задания\", по которым велась разработка. Ведущая роль же в процессе создания средств автоматизации оставалась по прежнему за разработчиками.Эпоха SOA. Возникновение бизнес-анализа и приход анализа системногоСо временем ИТ-инфраструктура стала играть ведущую роль в обеспечении создания добавочной стоимости. И потребовались принципиально новые подходы в формировании требований к разработке. Компании, конкурирующие друг с другом, начали осознавать, что в борьбе за клиента нужно предлагать ему более удобное средство автоматизации процесса, чем у остальных игроков на рынке. И вот тут свою роль начали играть попытки разработчиков встраивать свое видение процесса. Чем сложнее становилась создаваемая система, тем чаще заказчик начинал получать не соответствующие исходному техническому заданию решения. Почему так выходило? Разработчики, вследствие своей ведущей роли в процессе, пользовались служебным положением и решали проблему так, как им было проще и так, как они считали нужным. Вот тогда, руководство компаний задумалось о привлечении сторонних разработчиков или консалтов с интеграторами, которые будут решать проблемы на концептуальном уровне. При этом, степень зрелости бизнеса в ИТ процессах росла и решить концептуально проблему самостоятельно заказчик был уже в состоянии сам. Таким образом возникло понятие \"архитектуры решения\", которое являлось продуктом труда полноценной команды аналитиков. Аналитиков со стороны бизнеса. Такие аналитики, уже приходили к разработчикам напрямую и разговаривали с ними с позиций клиента, требующим исполнения своих требований в соответствии с договором. А как только на предприятии возникала надобность связать две и более концепции понадобились архитекторы со стороны бизнеса. Разметка предметного поля и модель данныхВ чем особенность SOA? Разные ИТ-системы обслуживали одни и теже бизнес-сущности в рамках различных бизнес-процессов. Если процессы разные, а сущности теже, то возможно самым правильным станет выделение этих сущностей и установление связей между ними? Как раз в это время рождается идея пойти по пути Карла Линнея и построить для банка “классификацию видов” бизнес-сущностей. И вот тут, впервые возникла надобность составлять модели данных и размечать предметное поле. И никто кроме аналитиков размечать предметное поле не стал.Разъединение BA и SA.Базовое физико-математическое образование заставляет мыслить системно. Давайте в свете вышесказанного про модель  данных сформулируем то чем бизнес-аналитик отличается от системного аналитика.Основная теорема бизнес-анализа: любой бизнес-процесс можно представить как описание связей между однозначно определяемыми бизнес-субъектами и бизнес-объектами, которые также могут участвовать и в других бизнес-процессах.Основная задача бизнес-анализа: определять субъекты, объекты и связи между ними в рамках данного бизнес процесса.Возникла еще одна проблема. Со временем в арсенале разработки появлялось все больше и больше инструментов выросших в своего рода \"зоопарк систем\". Разработчики же не могли самостоятельно выбирать способ, систему или методику, по которой будет решена та или иная задача. Возникла надобность в специалистах, которые бы перекладывали идеи бизнеса на ИТ системы предприятия. Так появились системные аналитики. В их обязанности стало входить выбирать решение и описывать его для разработчика. В той ситуации подобные аналитики находились на стороне вендера или интегратора. Со временем, они начали заводиться и внутри организаций заказчика. На данном этапе начали возникать такие понятия как “маппинг” и “метчинг”, то есть артефакты в которых семантика в одной схеме (будь то XML, JSON или позиционная строка) сопоставляется семантике в другой схеме. И вот тут возникла проблема того самого “семантического безумия”, о котором я говорил в ряде своих докладов. Данное явление наблюдается в ИТ-системах, когда начинает работать множество различных команд - и все начинают одни и теже вещи называть по-разному. Или наоборот, одним и тем же словом называют принципиально разные сущности или явления.Основная теорема системного анализа (теорема об унивокальности с бизнесом): Любой бизнес-объект имеет одну и только одну  проекцию в пространствах классов языков программирования и таблиц баз данных.Основная задача системного анализа: Зная набор бизнес-объектов, определять классы языка программирования и таблицы баз данных соотвествующие им.Еще раз об архитектуре и анализеЧем дальше шло развитие ИТ-инфрастурктуры, тем больше задач требовалось решать на концептуальном уровне. С другой стороны, начали возникать задачи интеграции одного решения в другое, когда несколько концептуальных схем как со стороны бизнес-идеи, так и со стороны технических решений необходимо было объединять в единую общую картину. Так стала возникать “архитектура” как новая дисциплина. Причем, на том этапе (а это была эпоха SOA - сервис ориентированной архитектуры), как со стороны бизнес-идеи, так со стороны систем решения, так и стороны архитектуры (сервера и каналы связи). Наличие документов с концептуальной архитектурой, описание заданий на доработку и серверной части привело к возникновению документации разного уровня. Именно в эпоху SOA начали произносить слово (HLA - high level architecture - верхнеуровневое описание архитектуры). Да и популярная в то время модель OSI требовала описания процессов на разных уровнях.У аналитиков появилась еще одна неожиданная функция. Они начали составлять документацию не только для разработки, но и формировать так называемые “базы знаний”. Для чего понадобилась в enterprise база знаний? Для последующих поколений и интеграции. Когда наступила эпоха SOA, возникла необходимость интегрировать “все-со-всем”. Системы стали “потребителями” (target system) и “поставщиками” (source system) друг друга. Естественно, в целях установления информационного обмена, для “поставщиков” понадобилась документация “потребителей”, а для “потребителей” возникла необходимость в документации “поставщиков”. И вот когда выяснилось, что из документации у всех только плохие ТЗ на разработку. КАзалось, бы надо опять нанимать технических писателей, или студентов-практикантов, которые бы денно и ношно сидели бы и описывали. Но.. к счастью, нашлось решение лучше. Решением этим стал Confluence. В процессе работы, множеству аналитиков и архитекторов (как бизнес, так и системных) стало возможным описывать свой маленький кусочек. И если все страницы связаны в единое целое, то получается вполне стройная техническая документация. И архитектор и аналитик производили документацию, но различного уровня. В чем же разница между аналитиком и архитектором? В предыдущем разделе я говорил об “унивокальности”. Термин “унивокальность” взят из религиозной литературы, а именно из трудов Блаженного Августина. Он говорил об “унивокальности со Всевышним”, рассуждая об одинаковом понимании вещей человеком и Богом. Я не Блаженный Августин, но часто также задаю вопрос, одинаково ли разработка и заказчик понимают суть вещей? Поэтому, как следствие теоремы об унивокальности, должна быть выстроена четкая связь между бизнес-сущностью и соответствующими ей ИТ-объектами (DataTransferObject, XSD, JSONSchema, таблицами баз данных и прочими). Задачей архитектора в этой парадигме является установление этого закона, обеспечения однозначности и понятности. Если такой закон есть, то у системного аналитика появляется инструмент для работы и все процесс (интеграции, разработка нового функционала) проводятся в соответствии с этим законом. Таким образом, основной задачей архитектора является - установление “унивокальности”, то есть четкого  закона по которому каждой бизнес сущности в рамках каждого бизнес-процесса ставятся в соответствие определенные, однозначно определяемые, ИТ-объекты.  В эпоху SOA пришло осознание, что архитектуру нужно продумывать изначально. Изначально теперь начали возникать такие артефакты, как HLA (High-level Architecture). Кроме того, возникли проблемы с семантикой. Выяснилось, что “семантическое безумие” это не вымысел, а оно правда существует. В этот момент многие крупные банки начали приходить к концепции Общей Модели Данных для всех ИТ-систем, построенной на глобальных бизнес-объектах. Глобальные бизнес-объекты хранились изначально в XSD, а позже в JSONSchema. И маппинг, о котором говорилось выше, подразумевал совоставление одной схемы другой схеме, что существенно ускоряло процесс анализа. Неоднократно в своих докладах приводил аналогии, доказывая, что в ИТ нужны инженерные знания и бекграунд. И вот тут такая история. Как многие помнят, в 1986 году случилась авария на Чернобыльской атомной электростанции. Одной из причин данной аварии, как выяснила комиссия, являлось несоответствие эксплуатационной документации различного уровня друг другу. Грубо говоря, верхеуровневая документация написанная академиками Александровым и Долежалем противоречила той, что главный инженер утверждал для смены на атомной электростанции. К счастью, последствия наших несоответствий не столь плачевны, но также могут привести к “перегреву”, но уже в ИТ-системе. И вот наступил Agile. Эпоха Микросервисов. Не документация, а артефакты.Как ИТ превратилось в сфере с наиболее динамично развитым маркетингом и накачкой деньгами никто не понял. Однако, на данный момент все больше и больше разных  людей начали работать в ИТ в неожиданно новых ролях. Если раньше промежуточным звеном между бизнесом и разработчиком были только  айтишники, то теперь появились целые гроздья новых специальностей, которые зна первый взгляд ( да и на второй тоже) добавочной стоимости в ИТ продукте не делают.Во времена Agile земля под аналитиками затряслась больше, чем под другими ролями. Ибо сказано: работающий код важнее исчерпывающей документации. На первых порах, евангелисты Agile понимали эту фразу буквально и каленым железом жгли все попытки задокументировать что-то на проектах. Вот и прошлось брату-аналитику пытаться перестроиться. В эпоху Agile остался бизнес-аналитик вне продуктовой команды, а системный аналитик превратился в солюшн архитектора, то есть архитектора решения. Почему так произошло? Степень зрелости в ИТ за последнее время драматически возросла и да, есть конторы, которые подошли к Agile не в угоду моде, а осознанно. С другой стороны, в эпоху Agile основным артефактом стало не техническое задание, а карточка в трекере. И вектор полезности сместился от ТЗ, к карточкам в трекере. В хороших команадах по карточке в трекере можно было вытянуть и страницу в Confluence с архитектурой и соответствующий коммит в GIT. И всю цепочку исполнителей. В эту эпоху документация перестала называться “документацией” и стала называться “артефактами”.С другой стороны, сопровождать традиционно построенное приложение (или как говорят у нас “монолит”) в условиях Agile становится проблематично. Возник архитектурный стиль, который стал называться “микросервисной архитектурой”. Парадигма микросервисов дала возможность бурно развиваться различным идеям. А значит количество артефактов, несущих какую-либо полезную информацию росло в геометрической прогрессии. Возникла необходимость наводить в этом хозяйстве порядок.Появление других суррогантных ролей в командахAgile быстро стал новой религией в ИТ и превратился в “вещь в себе”. Любой религии нужны “служители культа” и жрецы. Семейство суррогатных ролей, в котором до этого были только аналитики и архитекторы, начало пополняться новыми диковинными видами.После того, как все задачи начали отображать в виде разноцветных карточек на доске, такой доске понадобилась хозяйка или хозяин. Возникла отдельная роль - менеджер проекта, которого иногда называли скрам-мастером. Данная роль получила власть над главнейшим артефактом - карточками в трекере. Другая вещь, породившая новые роли,это DevOps и парадигма  CI/CD. Элементарная задача - составить релиз и спланировать поставку в условиях - оказалась продуктовой команде не под силу. Понадобилась новая роль - менеджер релизов. В их власти оказался GIT, система через которую ведется весь процесс движения “от дева в прод”. Можно сказать кровеносная система enterprice.Так же появились такие роли как product owner и platform owner. Agile уничтожил все вертикали, сделав горизонтальным или матричным менеджмент. Если мы говорим о парадигме SOA, то понадобились специфические архитектурные роли. Произошло разделение на на продукт и платформу, которая её содержит. Эти роли писали документацию уже по-новому. Они писали её как архитектуру. По новым принципам.В новой геологической эпохе тяжко стало аналитикам. Продуктовой команде, люди которые просто пишут документацию, оказались не нужны. Артефакты ведь сами собой получались. Уровень зрелости бизнеса в ИТ начинал расти, не нужен им стал бизнес анализ. Системный аналитик продуктовой команде также не нужен. Разработке со стороны заказчика спукают метрики и по хорошо разжеванным паттернам они стали работать. Да еще появился этот самый Swager - который позволял из их генерировать!  Казалось, надо бы начинать собираться мести улицы. Хотя осталось еще одно место, где документация сама по себе была нужна - это работа на государственные или полугосударственные компании. И аналитики начали превращаться в архитекторов решений. С одной стороны они стали отвечать за разметку предметного поля и построение моделей данных, а с другой - они существенно повысив свой инженерный уровень начали проектировать решения в рамках одного микросервиса.А что если разработка ведется на государственную компанию?Да. Agile это хорошо. И можно привести много примеров, когда он работает. Да вот беда, что делать, если вы работаете на государственную компанию, в которой документация это основной артефакт. Там нет Agile, а есть “водопад”. Или есть Agile, но документация все же остается важнее работающего продукта. Почему? Ну потому что в государственных компаниях бывают проверки и аудиты и такая документация нужна нее столько для разработки, сколько для прокурора. Ну не будешь же ты прокурору и контролирующим органам показывать карточки в Jira? Таким командам нужен все же технический писатель, вместе с полноценными аналитиками, которые кропотливо пишут ТЗ, которые написаны строго по ГОСТу и утверждаются начальством как положено, а руководитель предприятия ставит подпись, которая скрепляется печатью.Заключение. И все-таки аналитики выжили во всех геологических эпохах.Если вы в ИТ давно, и имеете дело с командой, в которой есть аналитики, то попытайтесь вспомнить, что заставило команду искать аналитиков. Объективная ли это была надобность? Или это было потому что “так было у всех”?. Подумайте над тем, а что стало бы с вашими процессами, если бы аналитиков совсем не стало? Ухудшились бы они? Или может быть всем бы только полегчало?Если вы аналитик, проанализируйте как менялись требования к вам и как менялась ваша компетенция за последние 2 года?Ответы на вопросы и их анализ заставляет задуматься и делать прогнозы с выводами. Стало совершенно понятно, что бизнес-анализ в enterprice в нынешнем объеме скоро перестанет быть востребован. Хороший менеджер направления уже прекрасно понимает, что такое ИТ-система и сам в состоянии сформулировать свою “хотелку”. Разработчики также ведут разработку по строго определенным паттернам, и если системный аналитик не превращается в архитектора решения, а хочет дальше только лишь писать техническую документацию, то ценность его для рынка труда в скором времени также застремится к нулю. Перевод с языка заказчика на язык разработчика скоро станет не нужен.Документация. Техническое решение без документации и без общих средств её написания и модернизации, как цивилизация без письменности. Такое решение либо будет со временем уничтожено, либо будет поглощено другим более понятным окружающим решением. Agile, такие системы как Confluence (аналогичные в этом ряду) да и общий рост технических знаний приведет к тому, что в процессе создания документации и баз знаний будет задействована вся команда на разных уровнях. Единственным исключением станет ИТ в органах государственной власти, где как я писал выше у документации несколько иная роль, чем вести по ней разработку.Коммуникация. Раньше, когда работали по “водопаду” было так, что аналитик был единой точкой входа для заданий заказчика. Он же собирал все вопросы разработки и добывал ответы, собирая и скрупулезно прорабатывая каждый пункт. Когда мы работаем по Agile, то создаем “продуктовую команду”. Предполагается, что эта команда живет в едином информационном пространстве и вся информация единовременно доходит до всех на дейли, ретро и прочих ритуалах команды. Зачем тут связующее звено? Вспомнилась мне история. Год или полтора назад работал я в одном интеграторе. Интегратор много из себя строил, говорил что работает по SCRUM, а сам пропагандирорвал идеи Карла Вингерса и натравливал на заказчика девочек \"анализирующих\" бизнес-требования и рисующих в пейнте интерфейсики.  Каждое утро начиналось дейли, на котором муссировалась одна вечная тема - сроки. Заказчику обещаны были одни, а по факту уходили уже на 3-й или 4й спринт спустя обещанного. Ничего нового не было и на этом дейли, разработка разводила руками и говорила, что делала по ТЗ, что им не понятно, как из того что там написано следовало то, что ждет тестировщик. Тестировщик возводил глаза к небу и вспоминал архитектуру платформы. Архитектор перебивал всех и говорил, что эта проблема не его уровень и конкретными решениями он не занимается, а мыслит глобально. Проджект менеджер же сказал, что у любой проблемы есть “имя, фамилия и отчество”. И все дружно начинали тыкать пальцами на аналитика. Он утирался, говорил что все поправит. А скрам-мастер - добрый толстый бородач, слушая мытарства взятого на проект 5 месяцев назад парня сказал только - “Команда без аналитика, что деревня без дурачка” и хлопал его по плечу. Пожалуй, можно было бы взять эту фразу эпиграфом к данному повествованию. Укрепился я в мыслях, что аналитики пишущие документацию и формализующие бизнес-требования, эта специальность, доживающая свой век. И что убери такого аналитика - всем только полегчает. У аналитиков теперь иная роль - копить знания, быть хранителями этих знаний и систематизировать эти знания.",
        "meta_tags": [
            "Аналитик",
            "банкинг",
            "энтерпрайз"
        ]
    }
]